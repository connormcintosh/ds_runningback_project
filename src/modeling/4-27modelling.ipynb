{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../../data/processed/oline_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.year >= df.draft_yr+4]\n",
    "df =df[df.year != 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>draft_yr</th>\n",
       "      <th>draft_pos</th>\n",
       "      <th>attempts</th>\n",
       "      <th>yards_run</th>\n",
       "      <th>tds_run</th>\n",
       "      <th>longgain_run</th>\n",
       "      <th>...</th>\n",
       "      <th>tds_rec</th>\n",
       "      <th>firstdowns</th>\n",
       "      <th>longgain_rec</th>\n",
       "      <th>yardspertarget</th>\n",
       "      <th>recpergame</th>\n",
       "      <th>yardspergame_rec</th>\n",
       "      <th>fumbles</th>\n",
       "      <th>team_adjusted_line_yards</th>\n",
       "      <th>team_running_back_yards</th>\n",
       "      <th>team_stuffed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.00000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>297.437811</td>\n",
       "      <td>297.437811</td>\n",
       "      <td>2014.20398</td>\n",
       "      <td>28.144279</td>\n",
       "      <td>2008.139303</td>\n",
       "      <td>102.965174</td>\n",
       "      <td>154.144279</td>\n",
       "      <td>644.920398</td>\n",
       "      <td>4.472637</td>\n",
       "      <td>38.407960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>9.885572</td>\n",
       "      <td>29.313433</td>\n",
       "      <td>5.755224</td>\n",
       "      <td>2.128358</td>\n",
       "      <td>16.544279</td>\n",
       "      <td>1.751244</td>\n",
       "      <td>17.706468</td>\n",
       "      <td>18.194030</td>\n",
       "      <td>16.074627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>161.656603</td>\n",
       "      <td>161.656603</td>\n",
       "      <td>3.13260</td>\n",
       "      <td>2.241446</td>\n",
       "      <td>3.538432</td>\n",
       "      <td>96.390683</td>\n",
       "      <td>94.378091</td>\n",
       "      <td>429.600772</td>\n",
       "      <td>4.149759</td>\n",
       "      <td>20.517376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.208058</td>\n",
       "      <td>6.742540</td>\n",
       "      <td>15.788802</td>\n",
       "      <td>1.667059</td>\n",
       "      <td>1.125985</td>\n",
       "      <td>9.628493</td>\n",
       "      <td>1.515853</td>\n",
       "      <td>9.154147</td>\n",
       "      <td>9.247549</td>\n",
       "      <td>9.175478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2005.00000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2013.00000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>2014.00000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>2017.00000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>2019.00000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>2097.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1        year         age     draft_yr  \\\n",
       "count  201.000000    201.000000   201.00000  201.000000   201.000000   \n",
       "mean   297.437811    297.437811  2014.20398   28.144279  2008.139303   \n",
       "std    161.656603    161.656603     3.13260    2.241446     3.538432   \n",
       "min      5.000000      5.000000  2005.00000   22.000000  1999.000000   \n",
       "25%    179.000000    179.000000  2013.00000   26.000000  2006.000000   \n",
       "50%    289.000000    289.000000  2014.00000   28.000000  2008.000000   \n",
       "75%    441.000000    441.000000  2017.00000   29.000000  2011.000000   \n",
       "max    599.000000    599.000000  2019.00000   36.000000  2015.000000   \n",
       "\n",
       "        draft_pos    attempts    yards_run     tds_run  longgain_run  ...  \\\n",
       "count  201.000000  201.000000   201.000000  201.000000    201.000000  ...   \n",
       "mean   102.965174  154.144279   644.920398    4.472637     38.407960  ...   \n",
       "std     96.390683   94.378091   429.600772    4.149759     20.517376  ...   \n",
       "min      2.000000    6.000000    -3.000000    0.000000      5.000000  ...   \n",
       "25%     24.000000   69.000000   283.000000    1.000000     21.000000  ...   \n",
       "50%     65.000000  154.000000   599.000000    4.000000     36.000000  ...   \n",
       "75%    199.000000  227.000000   986.000000    6.000000     51.000000  ...   \n",
       "max    257.000000  360.000000  2097.000000   28.000000     97.000000  ...   \n",
       "\n",
       "          tds_rec  firstdowns  longgain_rec  yardspertarget  recpergame  \\\n",
       "count  201.000000  201.000000    201.000000      201.000000  201.000000   \n",
       "mean     0.925373    9.885572     29.313433        5.755224    2.128358   \n",
       "std      1.208058    6.742540     15.788802        1.667059    1.125985   \n",
       "min      0.000000    0.000000      3.000000       -0.400000    0.200000   \n",
       "25%      0.000000    5.000000     18.000000        4.800000    1.300000   \n",
       "50%      1.000000    9.000000     25.000000        5.800000    2.000000   \n",
       "75%      1.000000   14.000000     36.000000        6.400000    2.900000   \n",
       "max      7.000000   32.000000     80.000000       11.200000    5.700000   \n",
       "\n",
       "       yardspergame_rec     fumbles  team_adjusted_line_yards  \\\n",
       "count        201.000000  201.000000                201.000000   \n",
       "mean          16.544279    1.751244                 17.706468   \n",
       "std            9.628493    1.515853                  9.154147   \n",
       "min           -0.300000    0.000000                  1.000000   \n",
       "25%            9.500000    1.000000                 11.000000   \n",
       "50%           15.300000    1.000000                 18.000000   \n",
       "75%           22.300000    3.000000                 26.000000   \n",
       "max           55.400000    7.000000                 32.000000   \n",
       "\n",
       "       team_running_back_yards  team_stuffed_rate  \n",
       "count               201.000000         201.000000  \n",
       "mean                 18.194030          16.074627  \n",
       "std                   9.247549           9.175478  \n",
       "min                   1.000000           1.000000  \n",
       "25%                  11.000000           7.000000  \n",
       "50%                  19.000000          17.000000  \n",
       "75%                  26.000000          24.000000  \n",
       "max                  32.000000          32.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('year',axis=1)\n",
    "df = df.drop('playername',axis=1)\n",
    "df = df.drop('team',axis=1)\n",
    "df = df.drop('basesalarycap (10^8)',axis=1)\n",
    "df = df.drop('cashspent (M)',axis=1)\n",
    "df = df.drop('caphit (M)',axis=1)\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df = df.drop('Unnamed: 0.1',axis=1)\n",
    "df = df.drop('catchpercent',axis=1)\n",
    "df = df.drop('draft_yr',axis=1)\n",
    "\n",
    "df = df.drop('yardspergame_run',axis=1)\n",
    "df = df.drop('yardsperatt',axis=1)\n",
    "df = df.drop('yardspertarget',axis=1)\n",
    "df = df.drop('yardsperrec',axis=1)\n",
    "df = df.drop('recpergame',axis=1)\n",
    "df = df.drop('yardspergame_rec',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Percenthit (%)',axis=1).values\n",
    "y = df['Percenthit (%)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F32BE11438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "MSE:  2.735906130222005\n",
      "RMSE:  1.6540574748847168\n",
      "MAE:  1.249584093130343\n",
      "ESV:  0.518537618315993\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('./savedmodels/norookiednn/')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \",mean_squared_error(y_test,predictions) )\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)) )\n",
    "print(\"MAE: \",mean_absolute_error(y_test,predictions) )\n",
    "print(\"ESV: \", explained_variance_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.2258 - val_loss: 8.9042\n",
      "Epoch 2/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.9000 - val_loss: 6.0500\n",
      "Epoch 3/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4019 - val_loss: 6.7898\n",
      "Epoch 4/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0150 - val_loss: 5.9367\n",
      "Epoch 5/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8057 - val_loss: 5.9052\n",
      "Epoch 6/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6456 - val_loss: 5.9902\n",
      "Epoch 7/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4298 - val_loss: 5.8109\n",
      "Epoch 8/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1670 - val_loss: 5.8342\n",
      "Epoch 9/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1213 - val_loss: 6.1871\n",
      "Epoch 10/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0501 - val_loss: 7.6927\n",
      "Epoch 11/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9303 - val_loss: 5.8314\n",
      "Epoch 12/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6267 - val_loss: 7.6725\n",
      "Epoch 13/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9188 - val_loss: 6.8918\n",
      "Epoch 14/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7737 - val_loss: 6.3471\n",
      "Epoch 15/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3206 - val_loss: 6.1284\n",
      "Epoch 16/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0624 - val_loss: 5.5745\n",
      "Epoch 17/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1786 - val_loss: 5.9386\n",
      "Epoch 18/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3247 - val_loss: 5.5631\n",
      "Epoch 19/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9238 - val_loss: 5.5772\n",
      "Epoch 20/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9139 - val_loss: 5.6268\n",
      "Epoch 21/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3235 - val_loss: 5.3884\n",
      "Epoch 22/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.3166 - val_loss: 5.5661\n",
      "Epoch 23/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9953 - val_loss: 5.7612\n",
      "Epoch 24/65\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.2412 - val_loss: 5.2077\n",
      "Epoch 25/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4044 - val_loss: 9.7387\n",
      "Epoch 26/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1794 - val_loss: 5.2334\n",
      "Epoch 27/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5221 - val_loss: 5.2134\n",
      "Epoch 28/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8664 - val_loss: 5.4518\n",
      "Epoch 29/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.2004 - val_loss: 5.6825\n",
      "Epoch 30/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7184 - val_loss: 5.1754\n",
      "Epoch 31/65\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.2329 - val_loss: 6.0352\n",
      "Epoch 32/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.9569 - val_loss: 5.1053\n",
      "Epoch 33/65\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.8596 - val_loss: 5.0641\n",
      "Epoch 34/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8932 - val_loss: 5.0641\n",
      "Epoch 35/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6276 - val_loss: 6.2205\n",
      "Epoch 36/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8068 - val_loss: 5.2888\n",
      "Epoch 37/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2154 - val_loss: 4.9008\n",
      "Epoch 38/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3934 - val_loss: 5.7890\n",
      "Epoch 39/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8028 - val_loss: 6.3899\n",
      "Epoch 40/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7529 - val_loss: 5.7786\n",
      "Epoch 41/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6151 - val_loss: 4.9914\n",
      "Epoch 42/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5194 - val_loss: 5.4529\n",
      "Epoch 43/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4326 - val_loss: 4.8352\n",
      "Epoch 44/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5009 - val_loss: 5.0038\n",
      "Epoch 45/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1322 - val_loss: 5.4309\n",
      "Epoch 46/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.6023 - val_loss: 5.8657\n",
      "Epoch 47/65\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.7964 - val_loss: 4.7209\n",
      "Epoch 48/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5692 - val_loss: 5.2292\n",
      "Epoch 49/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5586 - val_loss: 5.4053\n",
      "Epoch 50/65\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.5450 - val_loss: 4.7965\n",
      "Epoch 51/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7115 - val_loss: 6.5567\n",
      "Epoch 52/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.3709 - val_loss: 5.1219\n",
      "Epoch 53/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3819 - val_loss: 7.0044\n",
      "Epoch 54/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5826 - val_loss: 5.5985\n",
      "Epoch 55/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3330 - val_loss: 7.2203\n",
      "Epoch 56/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6217 - val_loss: 6.9809\n",
      "Epoch 57/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4114 - val_loss: 5.3575\n",
      "Epoch 58/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4386 - val_loss: 5.9270\n",
      "Epoch 59/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9517 - val_loss: 4.8145\n",
      "Epoch 60/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2623 - val_loss: 5.4553\n",
      "Epoch 61/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2616 - val_loss: 4.5163\n",
      "Epoch 62/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1185 - val_loss: 5.4452\n",
      "Epoch 63/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2669 - val_loss: 5.0055\n",
      "Epoch 64/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.1599 - val_loss: 6.0938\n",
      "Epoch 65/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9283 - val_loss: 4.9620\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F32BFBCEE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.0778721930613191\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/65\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.0199 - val_loss: 5.9713\n",
      "Epoch 2/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.9032 - val_loss: 5.8453\n",
      "Epoch 3/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.8472 - val_loss: 6.1972\n",
      "Epoch 4/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6142 - val_loss: 6.1305\n",
      "Epoch 5/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0205 - val_loss: 5.5709\n",
      "Epoch 6/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7224 - val_loss: 5.4272\n",
      "Epoch 7/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4735 - val_loss: 5.6035\n",
      "Epoch 8/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3192 - val_loss: 5.6242\n",
      "Epoch 9/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7851 - val_loss: 5.5560\n",
      "Epoch 10/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5556 - val_loss: 7.1585\n",
      "Epoch 11/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5601 - val_loss: 5.5766\n",
      "Epoch 12/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2530 - val_loss: 5.9485\n",
      "Epoch 13/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3422 - val_loss: 8.5410\n",
      "Epoch 14/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.3103 - val_loss: 7.7106\n",
      "Epoch 15/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2183 - val_loss: 5.0884\n",
      "Epoch 16/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9769 - val_loss: 5.7752\n",
      "Epoch 17/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9543 - val_loss: 5.2085\n",
      "Epoch 18/65\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.636 - 0s 6ms/step - loss: 3.1800 - val_loss: 5.2126\n",
      "Epoch 19/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1854 - val_loss: 4.9452\n",
      "Epoch 20/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2685 - val_loss: 15.9829\n",
      "Epoch 21/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.2187 - val_loss: 5.2595\n",
      "Epoch 22/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9932 - val_loss: 6.7454\n",
      "Epoch 23/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8703 - val_loss: 4.9001\n",
      "Epoch 24/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9084 - val_loss: 5.3104\n",
      "Epoch 25/65\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 3.1105 - val_loss: 4.7221\n",
      "Epoch 26/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6484 - val_loss: 4.7621\n",
      "Epoch 27/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8292 - val_loss: 5.4385\n",
      "Epoch 28/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7287 - val_loss: 4.6180\n",
      "Epoch 29/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8976 - val_loss: 5.4625\n",
      "Epoch 30/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4146 - val_loss: 7.1227\n",
      "Epoch 31/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5755 - val_loss: 5.4857\n",
      "Epoch 32/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6538 - val_loss: 4.5312\n",
      "Epoch 33/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6696 - val_loss: 4.5585\n",
      "Epoch 34/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0499 - val_loss: 6.1514\n",
      "Epoch 35/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8780 - val_loss: 5.6001\n",
      "Epoch 36/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6630 - val_loss: 4.7818\n",
      "Epoch 37/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6518 - val_loss: 4.9112\n",
      "Epoch 38/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4317 - val_loss: 4.4821\n",
      "Epoch 39/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5801 - val_loss: 6.8066\n",
      "Epoch 40/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5365 - val_loss: 5.4021\n",
      "Epoch 41/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9769 - val_loss: 4.4949\n",
      "Epoch 42/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4203 - val_loss: 7.3722\n",
      "Epoch 43/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0787 - val_loss: 4.5286\n",
      "Epoch 44/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4287 - val_loss: 5.1067\n",
      "Epoch 45/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3574 - val_loss: 4.7926\n",
      "Epoch 46/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2968 - val_loss: 4.6628\n",
      "Epoch 47/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4407 - val_loss: 4.8278\n",
      "Epoch 48/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3476 - val_loss: 6.1589\n",
      "Epoch 49/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3735 - val_loss: 4.5604\n",
      "Epoch 50/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6826 - val_loss: 5.2989\n",
      "Epoch 51/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3603 - val_loss: 5.9582\n",
      "Epoch 52/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8717 - val_loss: 4.5466\n",
      "Epoch 53/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8714 - val_loss: 4.6152\n",
      "Epoch 54/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3507 - val_loss: 4.9819\n",
      "Epoch 55/65\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.5529 - val_loss: 4.3837\n",
      "Epoch 56/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6298 - val_loss: 5.8418\n",
      "Epoch 57/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4586 - val_loss: 4.3581\n",
      "Epoch 58/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0859 - val_loss: 5.4420\n",
      "Epoch 59/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7479 - val_loss: 4.3362\n",
      "Epoch 60/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7575 - val_loss: 4.7091\n",
      "Epoch 61/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5128 - val_loss: 7.4197\n",
      "Epoch 62/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1110 - val_loss: 4.4593\n",
      "Epoch 63/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1180 - val_loss: 4.3864\n",
      "Epoch 64/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4296 - val_loss: 8.3676\n",
      "Epoch 65/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4463 - val_loss: 4.4513\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F32BDED9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.25788735506638005\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/65\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.5738 - val_loss: 9.3761\n",
      "Epoch 2/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.7716 - val_loss: 5.5017\n",
      "Epoch 3/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2404 - val_loss: 5.0921\n",
      "Epoch 4/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6858 - val_loss: 5.0770\n",
      "Epoch 5/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4924 - val_loss: 5.1368\n",
      "Epoch 6/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1906 - val_loss: 5.0010\n",
      "Epoch 7/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0561 - val_loss: 5.0084\n",
      "Epoch 8/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7593 - val_loss: 5.0798\n",
      "Epoch 9/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6327 - val_loss: 5.0513\n",
      "Epoch 10/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3813 - val_loss: 5.3632\n",
      "Epoch 11/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5340 - val_loss: 5.1459\n",
      "Epoch 12/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1487 - val_loss: 6.0777\n",
      "Epoch 13/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3863 - val_loss: 5.0346\n",
      "Epoch 14/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0885 - val_loss: 5.7045\n",
      "Epoch 15/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1207 - val_loss: 5.5597\n",
      "Epoch 16/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0465 - val_loss: 5.2510\n",
      "Epoch 17/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1132 - val_loss: 5.5021\n",
      "Epoch 18/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0101 - val_loss: 6.1524\n",
      "Epoch 19/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5984 - val_loss: 5.2747\n",
      "Epoch 20/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8661 - val_loss: 4.9608\n",
      "Epoch 21/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0397 - val_loss: 4.9179\n",
      "Epoch 22/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7626 - val_loss: 4.8912\n",
      "Epoch 23/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2367 - val_loss: 5.0840\n",
      "Epoch 24/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9681 - val_loss: 8.0563\n",
      "Epoch 25/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1014 - val_loss: 4.9676\n",
      "Epoch 26/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7072 - val_loss: 4.9642\n",
      "Epoch 27/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8351 - val_loss: 5.1786\n",
      "Epoch 28/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8197 - val_loss: 5.6215\n",
      "Epoch 29/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1671 - val_loss: 4.8875\n",
      "Epoch 30/65\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.939 - 0s 5ms/step - loss: 3.1348 - val_loss: 5.3893\n",
      "Epoch 31/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8241 - val_loss: 4.7935\n",
      "Epoch 32/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5660 - val_loss: 4.8548\n",
      "Epoch 33/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6221 - val_loss: 4.7652\n",
      "Epoch 34/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.5781 - val_loss: 5.4560\n",
      "Epoch 35/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3597 - val_loss: 4.7985\n",
      "Epoch 36/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6026 - val_loss: 4.7777\n",
      "Epoch 37/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7971 - val_loss: 4.7815\n",
      "Epoch 38/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9394 - val_loss: 4.9168\n",
      "Epoch 39/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5753 - val_loss: 9.4642\n",
      "Epoch 40/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6069 - val_loss: 5.5470\n",
      "Epoch 41/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5133 - val_loss: 5.1612\n",
      "Epoch 42/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4101 - val_loss: 8.9945\n",
      "Epoch 43/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2006 - val_loss: 4.7491\n",
      "Epoch 44/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9099 - val_loss: 5.4645\n",
      "Epoch 45/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6899 - val_loss: 5.0853\n",
      "Epoch 46/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8874 - val_loss: 4.5575\n",
      "Epoch 47/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4841 - val_loss: 5.9474\n",
      "Epoch 48/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2416 - val_loss: 4.7117\n",
      "Epoch 49/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4002 - val_loss: 7.9322\n",
      "Epoch 50/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7657 - val_loss: 6.1707\n",
      "Epoch 51/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4702 - val_loss: 9.9201\n",
      "Epoch 52/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7061 - val_loss: 4.6700\n",
      "Epoch 53/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2906 - val_loss: 6.7202\n",
      "Epoch 54/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6743 - val_loss: 5.3107\n",
      "Epoch 55/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2334 - val_loss: 4.7390\n",
      "Epoch 56/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1953 - val_loss: 4.9538\n",
      "Epoch 57/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5046 - val_loss: 4.7374\n",
      "Epoch 58/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7330 - val_loss: 5.9046\n",
      "Epoch 59/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0923 - val_loss: 4.7236\n",
      "Epoch 60/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0816 - val_loss: 4.9376\n",
      "Epoch 61/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2652 - val_loss: 4.7161\n",
      "Epoch 62/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2223 - val_loss: 4.9623\n",
      "Epoch 63/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1266 - val_loss: 4.9273\n",
      "Epoch 64/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1349 - val_loss: 5.0799\n",
      "Epoch 65/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1089 - val_loss: 4.8622\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F329991828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.17250556185426646\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/65\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3172 - val_loss: 10.8880\n",
      "Epoch 2/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.8576 - val_loss: 7.2530\n",
      "Epoch 3/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.6265 - val_loss: 5.1731\n",
      "Epoch 4/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3864 - val_loss: 5.0167\n",
      "Epoch 5/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7422 - val_loss: 5.1751\n",
      "Epoch 6/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4733 - val_loss: 4.8547\n",
      "Epoch 7/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0109 - val_loss: 5.6692\n",
      "Epoch 8/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4986 - val_loss: 4.9780\n",
      "Epoch 9/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8126 - val_loss: 5.0080\n",
      "Epoch 10/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3438 - val_loss: 4.9918\n",
      "Epoch 11/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1660 - val_loss: 7.2187\n",
      "Epoch 12/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9540 - val_loss: 5.0951\n",
      "Epoch 13/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4749 - val_loss: 5.6518\n",
      "Epoch 14/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3059 - val_loss: 6.7546\n",
      "Epoch 15/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9102 - val_loss: 5.3227\n",
      "Epoch 16/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9141 - val_loss: 5.2164\n",
      "Epoch 17/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8491 - val_loss: 6.0840\n",
      "Epoch 18/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0290 - val_loss: 5.3812\n",
      "Epoch 19/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9572 - val_loss: 5.7328\n",
      "Epoch 20/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8063 - val_loss: 5.7430\n",
      "Epoch 21/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7065 - val_loss: 5.2402\n",
      "Epoch 22/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7834 - val_loss: 5.1642\n",
      "Epoch 23/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9244 - val_loss: 5.1487\n",
      "Epoch 24/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6698 - val_loss: 5.1061\n",
      "Epoch 25/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7771 - val_loss: 6.4197\n",
      "Epoch 26/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7207 - val_loss: 6.8999\n",
      "Epoch 27/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7231 - val_loss: 5.3350\n",
      "Epoch 28/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7100 - val_loss: 5.8341\n",
      "Epoch 29/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8541 - val_loss: 6.4359\n",
      "Epoch 30/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2434 - val_loss: 4.9828\n",
      "Epoch 31/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5243 - val_loss: 8.4942\n",
      "Epoch 32/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4639 - val_loss: 5.0071\n",
      "Epoch 33/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6128 - val_loss: 4.9373\n",
      "Epoch 34/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8050 - val_loss: 5.1906\n",
      "Epoch 35/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4610 - val_loss: 5.1156\n",
      "Epoch 36/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7750 - val_loss: 5.0151\n",
      "Epoch 37/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6683 - val_loss: 4.9338\n",
      "Epoch 38/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3557 - val_loss: 5.5634\n",
      "Epoch 39/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5380 - val_loss: 6.0426\n",
      "Epoch 40/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3793 - val_loss: 5.2390\n",
      "Epoch 41/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3451 - val_loss: 5.4244\n",
      "Epoch 42/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4304 - val_loss: 5.1217\n",
      "Epoch 43/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3513 - val_loss: 5.2258\n",
      "Epoch 44/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4086 - val_loss: 5.2313\n",
      "Epoch 45/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9531 - val_loss: 5.1759\n",
      "Epoch 46/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5164 - val_loss: 5.0552\n",
      "Epoch 47/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3965 - val_loss: 4.9374\n",
      "Epoch 48/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3242 - val_loss: 5.3478\n",
      "Epoch 49/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3861 - val_loss: 6.3498\n",
      "Epoch 50/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3601 - val_loss: 7.6785\n",
      "Epoch 51/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6339 - val_loss: 5.0819\n",
      "Epoch 52/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6195 - val_loss: 5.7506\n",
      "Epoch 53/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1975 - val_loss: 6.1234\n",
      "Epoch 54/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8686 - val_loss: 4.8869\n",
      "Epoch 55/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4405 - val_loss: 5.6190\n",
      "Epoch 56/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9801 - val_loss: 5.3100\n",
      "Epoch 57/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2734 - val_loss: 5.3570\n",
      "Epoch 58/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4641 - val_loss: 5.7889\n",
      "Epoch 59/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3264 - val_loss: 5.8294\n",
      "Epoch 60/65\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.4282 - val_loss: 6.6344\n",
      "Epoch 61/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4624 - val_loss: 5.6487\n",
      "Epoch 62/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2635 - val_loss: 7.1615\n",
      "Epoch 63/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2179 - val_loss: 6.8627\n",
      "Epoch 64/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1053 - val_loss: 5.7256\n",
      "Epoch 65/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1783 - val_loss: 8.7185\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F32D1724C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: -0.207604291298215\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/65\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.4558 - val_loss: 9.0595\n",
      "Epoch 2/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.4672 - val_loss: 5.2774\n",
      "Epoch 3/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1987 - val_loss: 5.6019\n",
      "Epoch 4/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7948 - val_loss: 5.2636\n",
      "Epoch 5/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4689 - val_loss: 5.3445\n",
      "Epoch 6/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2987 - val_loss: 5.3624\n",
      "Epoch 7/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9689 - val_loss: 5.5899\n",
      "Epoch 8/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6394 - val_loss: 6.4122\n",
      "Epoch 9/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5320 - val_loss: 6.0010\n",
      "Epoch 10/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3720 - val_loss: 5.6550\n",
      "Epoch 11/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3244 - val_loss: 6.1535\n",
      "Epoch 12/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1334 - val_loss: 5.6539\n",
      "Epoch 13/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1206 - val_loss: 8.8908\n",
      "Epoch 14/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0555 - val_loss: 5.6163\n",
      "Epoch 15/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1555 - val_loss: 5.4976\n",
      "Epoch 16/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0096 - val_loss: 6.6491\n",
      "Epoch 17/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9101 - val_loss: 5.9162\n",
      "Epoch 18/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8538 - val_loss: 5.3061\n",
      "Epoch 19/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1407 - val_loss: 6.6386\n",
      "Epoch 20/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9295 - val_loss: 5.8083\n",
      "Epoch 21/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6385 - val_loss: 5.2332\n",
      "Epoch 22/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8457 - val_loss: 5.5654\n",
      "Epoch 23/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5935 - val_loss: 5.5678\n",
      "Epoch 24/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9393 - val_loss: 6.1313\n",
      "Epoch 25/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8488 - val_loss: 5.1861\n",
      "Epoch 26/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5383 - val_loss: 5.8193\n",
      "Epoch 27/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9156 - val_loss: 6.3244\n",
      "Epoch 28/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4421 - val_loss: 9.7576\n",
      "Epoch 29/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1284 - val_loss: 5.4069\n",
      "Epoch 30/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1418 - val_loss: 5.7405\n",
      "Epoch 31/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4156 - val_loss: 4.8842\n",
      "Epoch 32/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7110 - val_loss: 7.3845\n",
      "Epoch 33/65\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.8776 - val_loss: 4.9965\n",
      "Epoch 34/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4237 - val_loss: 5.5675\n",
      "Epoch 35/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3466 - val_loss: 7.6733\n",
      "Epoch 36/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.2987 - val_loss: 7.4964\n",
      "Epoch 37/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9176 - val_loss: 6.0542\n",
      "Epoch 38/65\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.4767 - val_loss: 5.1586\n",
      "Epoch 39/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5657 - val_loss: 5.0334\n",
      "Epoch 40/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5930 - val_loss: 4.8521\n",
      "Epoch 41/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4002 - val_loss: 7.0077\n",
      "Epoch 42/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2735 - val_loss: 7.2898\n",
      "Epoch 43/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0578 - val_loss: 4.9170\n",
      "Epoch 44/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2991 - val_loss: 4.8529\n",
      "Epoch 45/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0999 - val_loss: 5.9893\n",
      "Epoch 46/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3276 - val_loss: 4.8655\n",
      "Epoch 47/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7183 - val_loss: 5.7308\n",
      "Epoch 48/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6054 - val_loss: 7.6046\n",
      "Epoch 49/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.4349 - val_loss: 7.9989\n",
      "Epoch 50/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3512 - val_loss: 5.7368\n",
      "Epoch 51/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1716 - val_loss: 5.1100\n",
      "Epoch 52/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3606 - val_loss: 6.6186\n",
      "Epoch 53/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2036 - val_loss: 6.5193\n",
      "Epoch 54/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7330 - val_loss: 4.8957\n",
      "Epoch 55/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0848 - val_loss: 5.4728\n",
      "Epoch 56/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2278 - val_loss: 5.6776\n",
      "Epoch 57/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.2604 - val_loss: 5.0994\n",
      "Epoch 58/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.1054 - val_loss: 4.8558\n",
      "Epoch 59/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2097 - val_loss: 5.2761\n",
      "Epoch 60/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9778 - val_loss: 4.6440\n",
      "Epoch 61/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1612 - val_loss: 6.6808\n",
      "Epoch 62/65\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.0837 - val_loss: 4.6472\n",
      "Epoch 63/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.3414 - val_loss: 4.9109\n",
      "Epoch 64/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5303 - val_loss: 4.9707\n",
      "Epoch 65/65\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.0048 - val_loss: 5.2619\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F32D2631F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.02593797895269767\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MAX: 0.25788735506638005\n",
      "\n",
      "\n",
      "[0.25788735506638005, 0.17250556185426646, 0.0778721930613191, 0.02593797895269767, -0.207604291298215]\n"
     ]
    }
   ],
   "source": [
    "esv = []\n",
    "# while True: \n",
    "for i in range(5):\n",
    "    \n",
    "    X_train.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(18, activation=\"relu\"))\n",
    "    model.add(Dense(40, activation=\"relu\"))\n",
    "    model.add(Dense(40, activation=\"relu\"))\n",
    "    model.add(Dense(40, activation=\"relu\"))\n",
    "    \n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
    "    model.fit(x=X_train, y= y_train, validation_data=(X_test,y_test),batch_size=32,epochs=65)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    esv.append(explained_variance_score(y_test,predictions))\n",
    "    print('\\n'+'\\n'+\"ESV: \" + str(explained_variance_score(y_test,predictions))+ '\\n'+'\\n'+'\\n')\n",
    "    if(explained_variance_score(y_test,predictions) > .625):\n",
    "        winsound.Beep(1047, 750)\n",
    "        winsound.Beep(1047, 750)\n",
    "        break\n",
    "#     winsound.Beep(1397,250)\n",
    "\n",
    "esv.sort(reverse=True)\n",
    "print(\"\\n\")\n",
    "print(\"MAX: \" + str(max(esv)))\n",
    "print(\"\\n\")\n",
    "print(esv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  4.3297266305924715\n",
      "RMSE:  2.080799517154998\n",
      "MAE:  1.7135126789280875\n",
      "ESV:  0.18797883736699417\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \",mean_squared_error(y_test,predictions) )\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)) )\n",
    "print(\"MAE: \",mean_absolute_error(y_test,predictions) )\n",
    "print(\"ESV: \", explained_variance_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 114       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 547\n",
      "Trainable params: 547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'real')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_scl = scaler.fit_transform(X)\n",
    "predTotal = model.predict(X_scl)\n",
    "plt.scatter(predTotal,y)\n",
    "plt.scatter(y,y)\n",
    "plt.xlabel(\"PredTotal\")\n",
    "plt.ylabel('real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predTotal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5d1f5a0561d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbigpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredTotal\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbigpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predTotal' is not defined"
     ]
    }
   ],
   "source": [
    "bigpred = [i for i in predTotal if i >= 5] \n",
    "bigpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs =pd.read_csv(\"../../data/rbs_to_predict.csv\")\n",
    "names = rbs['playername'].values\n",
    "rbs = rbs.drop('tm',axis=1)\n",
    "rbs = rbs.drop('playername',axis=1)\n",
    "for i in range(len(names)):\n",
    "    print(names[i])\n",
    "    print(rbs.iloc[i].to_numpy())\n",
    "    print(model.predict(scaler.transform(rbs.iloc[i].to_numpy().reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./savedmodels/April27-norookie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  4.500784850833322\n",
      "RMSE:  2.1215053266096984\n",
      "MAE:  1.5205602826493432\n",
      "ESV:  -0.46056120636169307\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('./savedmodels/norookiednn/')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \",mean_squared_error(y_test,predictions) )\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)) )\n",
    "print(\"MAE: \",mean_absolute_error(y_test,predictions) )\n",
    "print(\"ESV: \", explained_variance_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9596240325094597\n",
      "MSE: 1.525682738916666\n",
      "RMSE: 1.235185305497384\n",
      "ESV:  0.28225617919754986\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2de5hdZXnof+9MtjDhNljSFgZCsNVglZLAVNEcPRAtIAimiAXqpbaeptXevMXGlnMAHytpUy/1tD02VU+xIoJcpgHEeNpg1dSgEwINSGi1XAePRCGIZAyT5O0fa+1kz551+dbe6/Kttd/f8+TJ7L3XXuudb9Z6v/d7b5+oKoZhGEZzGapaAMMwDKNYTNEbhmE0HFP0hmEYDccUvWEYRsMxRW8YhtFw5lUtQCdHHXWULlq0qGoxDMMwasOWLVt+oKoLko7xStEvWrSIycnJqsUwDMOoDSLyUNox5roxDMNoOKboDcMwGo4pesMwjIZjit4wDKPhFKroRWRURK4Xke0icp+IvKzI6xmGYRhzKTrr5i+BL6nqhSLyHGB+wdczDMMwuihM0YvI4cArgbcCqOqzwLNFXc8wDH+Z2DrF2g3389jOaY4ZHWHVWYtZsXSsarEGhiJdN88DdgD/V0S2isgnReSQ7oNEZKWITIrI5I4dOwoUxzCMKpjYOsX7b9zG1M5pFJjaOc37b9zGxNapqkUbGIpU9POAU4D/o6pLgWeA1d0Hqeo6VR1X1fEFCxKLuwzDqCFrN9zP9MzeWe9Nz+xl7Yb7K5Jo8ChS0T8KPKqqd4SvrydQ/IZhDBCP7ZzO9L6RP4X56FX1/4vIIyKyWFXvB14FfLuo6xlGGuYnroZjRkeYilDqx4yOVCDNYFJ01s3vA1eHGTf/CfxGwdczjEjafuK2C6HtJwZM2RfMqrMWzxp7gJHWMKvOWpzbNWwST6ZQRa+qdwHjRV7DMFxI8hObQiiW9vgWpYhtEk/Hq+6VhlEU5ieulhVLxwpTujaJp2MtEIyBIM4fbH7i+mOTeDqm6I2BYNVZixlpDc96L28/sVENNomnY4reqBUTW6dYtmYjJ6y+lWVrNjoX3axYOsaVF5zE2OgIAoyNjnDlBSfZ0r4B2CSejvnojdrQb9CtSD+xUR1FB3ubgCl6w3vaqXNRudgWdDPAJvE0TNEPMHXIPe624qOwoJthJGOKfkCpS+5xVOpcN00JutVh4jXqiSn6AaUuucdp1npn0K3OirIuE69RTyzrZkCpS+5xkrXemTlT91a41uHRKBJT9ANKXXKP41LnPnbREjatXj4r46LOirIuE69RT0zRDyh1yT12zX+vu6Ksy8Rr1BPz0Q8odco9dkmdq3sr3DI6PBqDiyn6AaZJucd1V5R1mniN+mGK3mgERSnKMjN5mjTxGn5hit5oDHkrSkt5NJqCKXrDiKEutQaDQp3rJKrGFL1hxFD3TJ4mYaur/rD0Sk/ptR2vkR+W8ugPda+TqBpT9B5S9yrPplCXWoNBwFZX/WGK3kPMevED26zEH2x11R/mo/cQs178wVIe/aDudRJVYxa9h5j1YhizsdVVf5hF7yFmvbhh6XbNJe5va3/f3ihU0YvIg8DTwF5gj6qOF3m9pmDl8OlYul2z6FTsB7eGmJ7Zt/8z+9v2j6hqcScPFP24qv7A5fjx8XGdnJwsTB6jOSxbszGyidnY6AibVi+P/I6tAPzEZbtISP7b5i1Pne4TEdmSZkSb68aoJVkD1rYC6J2iFZ/LdpFQTjJCU++TooOxCnxZRLaIyMqoA0RkpYhMisjkjh07ChbHaApZA9aWstobZdR0uCrwMpIRmnqfFK3ol6nqKcBrgN8VkVd2H6Cq61R1XFXHFyxYULA4RlPIWsxkKavZmdg6xXuuu7twxeeiwAVKSUZo6n1SqKJX1cfC/x8HbgJeUuT1jMEha7qdpaxmo23J742J4eWp+KIm7U4EeONpC0txnTT1PinMRy8ihwBDqvp0+POZwAeKup5RP/r1/WZJt7OU1Wyk+c3zVHzdWWZHjLQQgZ27ZkoPhjb1PikyGPszwE0i0r7O51T1SwVez6gRZQe9LGU1G0kWexGKz5cc+abeJ4WmV2bF0isHh17SI4ugbql0ZRH39xkW4cO/erKNkUe4pFdaCwSjEnwIelmX0Hjigt2m5OuJKXqjEnwIejU1lS4PrLdMs7CCKaMSfAh6FbGqaJIryBe/udE/puiNSvAh6HXM6EikH7rXVUVTqyqN+mOK3qiMqi3GvFcVtpm44Sum6I2BJe9VhQ8BZsOIwhS9MdDkuarI2xVkGHlhWTeGkRO2mbjhK2bRGwNJEdkxPgSYDSMKU/TGwFFkdkzVAWbDiMIUvTFw1CU7pkk5+Ua1mKI3Bo46ZMdYTr6RJxaMNQYOH9ovpGHtGYw8SVX0IvLTIvJ7InKtiHxNRL4sIh8RkVeVIaBh5E0dsmPqsOow6kOi60ZEPgGcCHwR+FvgceBg4AXAxSLyAWCVqv5r0YIaRl7UITvGcvKNPEnz0f+dqm6JeH8S+JyIzAcW5i+WYRSL79kxPjR9M5pDoqKPUvIicihwjKr+u6ruArYXJZxhNJW0jJo6rDqM+uCUdSMiXwYuJPDp3w08LSK3qOrqIoUzjCbimlHj+6rDqA+uWTcLVPVHwAXAPwAnAecUJpVhNBjLqDHKxlXRt0TkSAKr/mb1aaNZw6gZllFjlI1rwdSVwGZgk6reISLPAx4uTizD6B3XitKqKk8to8YoG/HJOB8fH9fJycmqxTC6qFMpfrf/G4Jsle79TqOOaw0Jhx48j527Zgr9PV1lNAwXRGSLqo4nHePkuhGR54nIrSKyJXx9koi8Lw8hDb9pK6WpndMoBwKHE1unqhYtElf/d9RxM/uUJ3fNlPJ7Htw68OiNjrRMyRuF4uqj/yTwZx3H3wO8pRCJDK8oInA4sXWKZWs2csLqW1m2ZmOuytTV/+3iDy8iQNqeOJ/cNbP/vd179uV6DcPoxlXRH6aqX22/CIOxe4oRyfCJvAOHRa8QXPvYuPrD8w6QVpVxU+TkaviPq6J/QkQWAgogIucB33f5oogMi8hWEbmlRxmNCsm7AVjRis61j03UcVHkHSCtIuPGN/ebTTrl46rofw/4DLBYRL4LXAa8w/G7fwjc14Nshgfk3QCsaEW3YukYV15wEmOjIwgwNjoS6f/uPm50pEVrWGYdU0TLgSo6Z/qUt+/bpDMoOKVXqup/AKeLyE8RZOr8wOV7InIscC7wp8C7e5bSqIy8S/HLSC10rSjtPq6M7KIqetj4lLdfl01fmoZrC4T3db0GQFX/POWrHwPeBxyWcO6VwEqAhQutP5qP5FmK73OzrjJaDlTRw8anvH2fJp1BwrVgqtXx88EE7Q/uSfqCiLwWeFxVt4jI6XHHqeo6YB0EefSO8gwsdcppj8KadZXfw8anydWnSWeQcHXd/GnnaxH5EHBjyteWAeeLyDkEk8PhIvJZVX1TT5LmTB0VZlO2l7NmXXMp8n70aXL1adIZJHqqjBWRw4A7VfX5jsefDrxXVV+bdFxZlbF1rUxctmZjpDU0NjrCptXLK5DIcCVJkdf1fuyVOhpZPuNSGevqo/8WYWolMAwcC6T5572lrgEh82/Wk7SVWNn3Y9WK1lZ05ePqo+90t+wBvhduOuKEqn4F+Iq7WMVSV4Vp/s16kqbIy7wfm+L+M7KRmEcvIvPD7QIf6fj3vfZnxYtXDHGK8YiRVk+FHGUVgNRhU2tjLmmKvMzcep9y6o3ySCuY+i7wnfD/7n/fKVa04ohSmK0h4Zln92Qu5CizAMS1GMjwizRFXuYEXtVq1qphqyVtz9ijyxKkTKKyEHY9u2dWoylw85Nm9a/26x81/2b9SMs0KTMrpgr3n7mLqsfVR9/eFPx5BKmSAKjqN4sQqgy6FeYJq2+NPC7N0sliIdkNXxxVBxiTcFHknfdj+3d517V35f67VJHeWNfkhybhmnXz68AfAWPAt4FTgG8CryhOtHLp1dLJ8j274YuhDhOo60qs6N+lipz6uiY/NAnXpmbvBcaBB1T1ZeHPjxQmVQVE+u2HhWd270n0K2bxr9oNXwxNCjCW8busWDrGptXLeWDNuWxavbzwybCKRm7GbFwV/U/a6ZQi0lLVbcALixOrfLoDnUfOb4HCzunkHYeyBEjthi+GJk2gTfpd2li2WPW4+ugfF5FR4FbgNhH5IbCjOLGqoXN5vWzNRufgrOuy3Mq/i6HIAGNW338/sYKJrVMMibA3olq9zsaATy0YBhXXXjfnhj/+iYicBRwB3FyYVB5QhGVlN3wxnHHiAq7e/DCd6jGPCTSrv7wf/3r7u1FKvgnGgGWLVUuioheR64FrgFtUdTeAqm4oQ7CqKcpKtBs+Xya2TnHDlqlZSl6A15/a/zhnDZ73E2yP+i7AsIjVShh9k+aj/wJB+4OHReQqETlbRNL3X2sAvfgVrSikfKIUpAK3b+/fs5h1VdfPKjDumH2qjVPy9pyUT6KiV9VrVfVXgOcDGwm2BXxERP5GRBqTWhlF1irUOmyR1sQHrMjgZdbgeT/B9kEJ1NfhOWkiTlk3qvojVb1KVV8DnAm8DI+alBVFljQ031P8mvqAFakgs67q+skuaVJmSpJB4ftz0lScFL2IHCkivyUi/wzcBnyVYGMRI8T3tLimPmBFKsisq7p+ehE1pY9RmkHh+3PSVNKCsW8GLiGohL0Z+BBwu6ruK0G2WuF7C+GmPmBFZzJlDZ73E2xvQqA+LSDt+3PSVNLSK88BPgHcpqozKccONL7nyDf5AWuCgmwKaQaF789JU0kLxl6iqutNyafj+9K7ST5gw1/SYia+PydNpac9Y4uirD1jq8CH7oo+yGA0m0Hb/9YHctsz1ugPX7ormoujeAZ9MrXqbz/J0o9+HHiBqn5ORJ4LzFfVR4sTrTlYe+Ls1FFh+jKhV40ZFP7h2o9+NbAcWAR8Djgk/L/RRVN50dSMl6LwXWHGTUJl7zZmGK64WvQXE6RYbgFQ1UdE5IjCpGoYTc54yYqLcvN5BZQ0CdluY/4y6JOqaz/6Z8PceQUQkcHTUH1gGS8BrtW5Pq+AkiahLFW6TS1g85GmVoVnwVXRT4jIx4HDwyKqLwFXFSdWfXDpH2MpZQGuys3nvi9Jk5DtNuYnNqm696P/kIicR9AB9qXAX6hqo/vRu5Bl+W0BKnfl5nNRTZIbLkvGSRXuvEF1X9ikmiHrJlTszspdRA4m6IlzUHid61X1sswSekwZvuR+dyzy6cF2VW4+p+ilTUK+7jY2yDEBi5G5Z908Dfv3dhgisOz3qurhCV/bDSxX1R+LSAv4uojcpqqb+5LYI/q1FNIUcR47Fvn0YGdRbr6ugPKahMqezHwOcBeNzyvEsnB13RzW/jlU2q8HTkz5jgI/Dl+2wn+VluHmbeH2Yym4KOK8dyyq+sH22VLPQl6TUJmT2SC7L5py3/VD5srYsO/N50VkM3B50rHhblRbgJ8H/lpV74g4ZiWwEmDhwoVZxXGmCAu3H0shThG/57q798tUxI5FVT/YvlrqTWfQ3ReDft+5um7O6Xg5BIzjkLGjqnuBJSIyCtwkIi9W1Xu6jlkHrIOg142r4K60rfiom7xfC7cfSyFO4e5V3T8B9fNwDvqDbczG3BeDjatF/+aOn/cADwIrXC+iqjtF5CvA2cA9KYfnRlSDpW76tXB7tRTiFDEcmID6eTjtwXbHxaXnW2A7K+a+GGxSFX3ofvm6qv51lhOLyAJgJlTyI8CrgT/rTczeiHKPdFOmhdupLI4YadEaFmb2Ri9iHts53dfDaQ+2Gy4uPR8D270w6O6LQSZV0avqXhF5A5BJ0QNHA1eFE8UQcJ2q3tKDjD2TZq2XaeF2K4ud0zO0hgQRiOoU3dm/O+vD2W19fvSiJfaAx+AStPYxsF0VPq9sfJatalxdN18TkQ8Dnweeab+pqt+O+4Kq/huwtD/x+iPJPTJW8o0QpSxm9ilHzm/xk5l9kS6WXm7cplifZeEStPY1sF02Pt9bPsvmA64tEF4NvBz4OPCp8N8nixIqL+JK0j920RI2rV5e6g0QpxR27pqJbI8A9NSfw8q9s+HSbiHumCGRxNYXLu0x6oTP95bPsvlA2ubgr1PVf1TVl5UlUJ745KdOK53vlmnZmo09uQvSrE9b3s7GJWgddQwEGVLQbL9+Jz6vbHyWzQfSXDeXAf9YhiBF4UsAKmsWTK83btKE0kTl0y8uxkD3MUMi+5V8m0Hw6/ucsuuzbD4wUFsJlmHNxl0j6+qi1xs3aUJpovLJAxdjoPOYE1bfGnlM0/36PqfsrjprMau+cDcz+w5MwK0h8UI2H0hT9CeKyJ0R7wtBl4NTCpCpEMqwZtOukWV10etDlTShvOvauyK/U2flUwUuk3ATLUyfXKGRSMrrASZN0T8AvKEMQYqmDGs2z2v0m0NfZWvcphcg9erX98X67QdfXKHdrN1w/5yalJm9OvCr1TZpiv5ZVf1uKZIUTBlL6byvkfdDVYbyGYQCpF78+nWbzOpGE11leZKm6BvTUjjNms3DwvR9uV6G8hmUAqSsfn2jWHx/9qomLY/+X0Qk1tMlIotE5OU5y1QISdu85bWn5KqzFtManj1crWG/AkIrlo6xafVyHlhzbiG1BFaAZFSB7cucTJpFPwZsFZFvErQb3gEcTNB2+HTgR8AfFSlgXkRZs2ecuCD/zpbd7QxK7sBfte/b50Bl1WNjFIe5ypJJVPSq+mER+Uvgl4FlwEuAaeA+4G2q+kDxIvZH3MNdRGfLtRvun5XeBUGbA9cJo19F5IPv29dApQ9jYxSLucricWlqtge4LfxXK5Ie7iI6W7q6JKIUOjBH1nddexeTDz3BB1ec5HR9H3zfvgYqfRgbw6iKRhdMJT3cRXS2dHFJxE0+B80bmiOrAldvfpjx45/b12YmZfu+fQxU+jI2ZWFuKqMT16ZmtSTp4U6y1tuNxbI+GFEBISFQ5u2mVnGTz87pmchzKnDFzfc6NcdyadDVK3Vv0FXk2PhGXskFRnNwUvQiMmcz16j3fCPp4S6is+WKpWP7O1FCWD4cftZ+2OLaJifx5K4Zp4e2qMyDJiiOQcrKKLOTY90NgEHB1aKfcHzPK5Ie7k6l3Nke2KXfe9KN3U5fHBsdmZNwMz2zl+GYbNUj57ecK7bjHtpef6c0mtACtqix8ZGy3FRNMAAGhbQ2xS8AXggcISLnd3x0OEGapdekBf2y+onj/OuTDz3B7dt3zLpG0ubfI63hORknl533IiYfeoKrNz/slJEZd/4ifN9N8W8PSlZGWemrFuCuD2nB2BcBFwCjzO558zTw20UJlSd5PtxxN3ancm4r/9H5LZ7cNdfv3t7ZKq7D5fjxz5312TO790T677sDvHkE3uLOY1WH9aKs9NWmGACDQFoe/U3ATSLy31T16yXJ5C1xN3CUi+ageUORlnu7SCsp9bDz9aUT2+ZY+QKcceICIL/88KTzNLVBV5umZaiUlb5qBkB9cPXRnysih4vIPBHZICLfF5FfK1QyD8lyAz81PXeLwNefOsYNW6acfZoTW6e4YctUZLHtDVumErN4svrP085zcOvArTI60mqMf7upfuaiW13AYAW4646ron+Nqv4IeC3wOPBiatL6IE/i0iejaG8RuOqsxRwzOsJjO6e55o5HMinlpKKutHqArMvnuOPbiq/TDbV7z75M5/aZJgSaq2KQAtx1x7VgqhX+fw5wjaruEJGSu7hUT1y/nBu2TM1RFrue3cOlE9tmfda9/VybXpV1W4Y8ls9x5xkWKS3gVoULxfzM/TEoAe6646rovygi9wB7gd8VkaOA3cWJ5S9RN/b48c/l8vX3zgqaPrlrxjmDJinfPynvvq0M8/Cfx50nbkVRVKpe2b1ozM9sDAJOrhtVXQUsB05V1RngJwTZOLUk7yKPFUvHOOSguXOm65KnM7DaKdcZJy6Y4ypq0w7I5rV8jjvPWMIklCdVuVB68TNbkZBRN5wsehEZAX4TOB54O/CzwPOB2DtcRI4DPhMeuw9Yp6p/2a/A/ZKn5djpaujHj3X79h2Rct2wZYrXnzrG7dt3zLE62wHZdh+cPKzeuPN0W/qtYeGZ3Xs4YfWtublYqnKhZM1QsS6YRh1xDcZ+Ojz2FeHrx4APpXxnD/AeVX0hcBqBy+cXepIyR/KyHLuzNeJwqXZ9bOd0rFy3b9+xv9K2mzIs3m5L/8j5LVDYOT2Ta5ZKlb1osmSoWPDWqCOuiv75qvohYAZAVXeRosNU9Xuqemf489MEPewrN3n6tRzby/Z3XntXapvjkdYwbzxt4X4lGdf+oJ2VkyRXlUHDTkU4/znz5vTcz0PR1SVVr+y/g7mJjDxwDcY+KyIHE7qdReQE4FnXi4jIImApcEdG+XKnn+Cby2YlnRw0b4jx45+7v5981Pfbyixup6tjRkeY2DrFkEhk1k7ZQcOiFF3ZPep7zfApM3hrbiIjL1wV/QeALwHHishVwH8H3ubyRRE5FLgBeGeYi9/9+UpgJcDChcU3xOwnS8Vls5JOdk7PzHow05RZlFxnnLiA99+4LVLJV2HxFqnoykrV60eBllklbL1kjLxIa2q2UFUfVtUvicgW4OUELptVqvp42slFpEWg5K9W1RujjlHVdcA6gPHx8cJz8/uxHHuxWqdn9nL5+ntTrxcnV9zkMixSSXFKE9oh9KNAy1x5WI6/kRdpFv0EcAqAqu4A/tH1xCIiwKeA+1T1Iz1LWAC9Wo5pee1x7Jye2Z9jn2Q9Rsn1rmvvijznPtVKrLombMLcrwIta+VhOf5GXqQpetcW6VEsA94MbBORtrb6Y1X9Yh/nLI0oH26UNdsLWZbfeT7seVWe1r0asi4KtAmrJ8MP0hT9mIh8PO5DVf2DhM++Tn8TRal0KsEjRlo88+weZvYGnqS2FX7lBSdx5QUnccXN90a2IM6Cq/WY18Nugb0DxE3Yz+zew8TWKW/Gw2X11LTOm0YxpCn6aWBLGYJUSbcSjOr/3rbCN61eztoN9zsr+iGBfRGRh7b1mPag5uUqscDeAdq/b/eE3R0894Gk1ZNN3oYraYr+h6p6VSmSVIhrNk1aTns3I63h/a2Jo7Jpllzx5VmTStyDmoerxAJ7s1mxdCxywq7T5GeTt+FKWsGUc658nXFVdm0rPM6XOzrSmtMr5oMrTortS5+0csibMipP61bcU/fJr+7yG+WRtsPUaWUJUgaXTmzjmjseYa8qwyJc8tLj+OCKk5yyaTr94ot+Kvr415589P7iqE66LfJlazYmriB6yexJI8ovnWfPmjq6EeoSlI2j7vIb5eHaAqH2XDqxjc9ufnh/4dFeVT67+WEundgWWX7fGhKOnN+a0xFyYusU//rdJyKvcfv2HU6ypFlcArlbw0X3rKljD5hVZy2mNTw7X6A1LKVmtfSzCqpL2wijetIKpr4IvENVHyxHnOK45o5HYt9vW+EuAc+1G+6PbWKWxQWUZLVreJ28LeHOlcWyNRtz9U/n4UaoJIMkap/Gkuh3FdSEmgajHNKCsX8PfDlse/DnYS/6WhK3u1P7fdeAZ5Licl0yu+TjJ10nD4WYt3+3XzdCVqWXxxis3XD/nAZtM/u0tGBmHsHUutc0GOWQ6LpR1esImpEdDkyKyHtF5N3tf6VImJG4pfBQQkZ/lmVznOIScF4yd7pRsl4nr82s8w7O9utGyOL6yWsMqg5mVn19Y3Bw8dHPAM8ABwGHdf3ziiQFcNC8+F81i7KI2yD8jactdLasOq3RI+e3aHXNQkkKMi9feN7+3X53usqi9PIagyp74PtwfWNwSPPRnw18BFgPnBL2ofeWJAXwk5l9qd93WTavWDrG5ENPRGbvuNDtonhy1wytYWF0pMVT0zOpboi8rMAi/Lv9uBGyuH7yGoOqWwxUfX1jcEjz0f8J8AZVvbcMYfolSQG4NiRLUxYTW6e4YcvUrOydzi39Oo+LUqJRk9HMXuWQg+Zx12VnpsqXZ0qdT/7dLEovrzGoOphZ9fWNwSEtj/4VSZ/7RpICcG1IlqYsXAJoSYHFfq3RplqBWZRenmNQ9WRX9fWNwcB145FakKQAuhVJd+OyNlGNrVw2AW8r6omtU7znurvnZPm0J4Ms1mhSZklVVmCRKZCuSq+fMbAmYLOx8RgMRGPSDqtgfHxcJycn+zpHlht3YutUZCfKkdbwrAIpl5XAmMOqoR20/ezmh+d89qbTFs7y88dtO1jFZiM+y5SFusufNzYezUBEtqjqeNIxjauM7dzIetPq5amB1fnPmbuo6czgcGl41rnva9Kxx4yOxFbPdr/vY6WpjzJloe7y542Nx+DQKNdNL6T5zJN85wKzVg1xu0HBgckg7pju6/iYY+2jTHFErezqJH8ZFDEe5gryk8ZZ9FlJy2WO+3xsdGTOqiHu2M79XV1zp33MsfZRpiji6ilG57cij/dN/rLI+++ZVyGbkT8Dr+jTCoeyFBbFHfvhXz15/2Tgej4fG1b5KFMUcS4JVWohf1nk/fc0V5C/DLzrJi2DI0uGh8uxruerOrsmCh9liiLO9fDU9AwfvWiJ9/KXRd5/zzJdY+YiysZAZ90Udf6oY8B/BdkUlq3ZGJnCOjY6wqbVyyuQaDAoa9wtW2g2Llk3jbLo+237mqbEk84PgSKf2jmNcKDb7dTOad7ZFYCNkssslN7pHrszTlwQuX3joLpoyqKsYj7bQjE7jbLos1oUnQpidH6LH/9kz6y2td359O+69q7IgqnRkRa79+xz2nc2Sq6JrVOsuv7uWcVbrWFh7YUn242bQpx19/pTx7h9+w6bOEumDIPlhNW3xhYudmfCDQIDYdG7VK1GKf+o5mLddAaSVn3h7tjzR+396kLbd3nFzffOqdCd2au867pgJTAoN2wvxFl3t2/fYW6aCiijpUNS36rObJ+2PEbNFb1r1Wrn8e1JYUgkdjOSTqZ2Tke2NMiDdhpb1CQDoBpMMFfcfC87d6V3thxELDd+8HDpW2WunNnUOr3SpWq1TXeObxbFnXbsIc8ZTvw8CteNSmb2KU/uymdf1yZSl9x+Iz+69z6Iwyb7AxSm6EXk0yLyuIjcU9Q1XCjrTZwAAA9nSURBVP+QwyKZJoWstIaH5uQjJ9G9UcnoSHQhTxSWlzwb11zwfjbhNnqnqHHvbHUSt1ObTfYHKNKi/3vg7ALP7/yHvOSlxxU6uz81PTNnd6U3nbZw/+sj57cYHWnt/+yjFy2Z1cDs8vNfNGeXqSTMUjmAy85WVrFZDWWNe10K+aqkMB+9qn5VRBYVdX6I9tUNAQjsU2bt/nT79h2RAZyh8Nh+OGZ0pK8gVPt7UZ00465nHCBt7JuQjlfH9Nuyxr0uhXxVUnkwVkRWAisBFi5cmOm7eWxWceUFJzkp2M7c+O7387Ac2sqq84GO6plvlkp26h6w7bc+pCrKHHfbwCWZyhW9qq4D1kGQR5/1+3lsVpHUdRICd0BSOle3gu7Houj+fepoyflGntsvVkFdVyR1H/cmUbmiLxoXRZmUlzsswmM7pxmOScccGx0p1OIyS6V/6r79Yl1XJHUf9ybRaEXvqoBXnbV4TmVqm85NwLtJ2nDE1eJqT0RTHZPJmFnuuVJ3H25dLeO6j3uTKKwFgohcA5wOHAV8H7hMVT+V9J08mpp1kqUlQve2giJBwVI3wyLsU51108aVZAvwwJpzY+VLKvga5CZNPlKlC82aeBlJVNoCQVUvKercrmRZ8q5YOsbkQ09wzR2PsFc1UskD7FOdo7x7tbiScvvr4IMdFKoOhpplbPRLo103rgp4YusUf3zjv7FrZp/TObvp1ReZ5mP13QfbRKIs9zjX3OXr7y1N2VqsxuiHRit6FwV8wFpLV/JCYM0tW7Ox581JOkkKArc/rzsuMYgy3SJJ14qz3ONWXTunZ5jYOmUK2PCeRrUpjiJK0XQqnGd27+mp+2RrSFj7hv7aCDfdR+/y+wGl+Z/TfN1xMZ24jCuwzUyM6nHx0de6qZkLK5aOseqsxbSGZU4GzdTO6VQlPywS2YtmZp9y+fp7+5atXb7fvhZEl/HXEZcYRK/7jPbSQyXtWnGusqSmduZeM+pAo103baL6vbuyVzV2Muh+vxcXhIvv1YftEXuhnxhE0me9BkfTgvNxrrSx0RF2Pbsnsnq6Ce41o/k03qKH+H7veVJUA6eiG0MVef40JXjM6EhPbYZ7XQWkXSupOdZl573IGmcZtWUgFH1RHDn/gEunV+WTRlHnTTv/e667u+/WslGKs01bSfbSebDXStG0ayV1wnTpkmkYvjIQrpvRkVbP2/3F0RoWLjvvRftfF1WmXnT5e5pfup+c8c5spLTK3yyuo17rFlyyo5JcaZbiaNSVgVD0rz35aD67+WGnY+O6VHYyLHM37k5SPpdObNtfiNXZOtmFosvf01I8ob/iLRflmFWB9tNDxZS1MYg0QtF3ty8YHWlx+fmBtX35+nszWfMuIdvTnnfkHGURpXzaefedk8xe1f2vXZR90Y2hXPbfBL+yS6xS1DCyUfs8+omtU5ENyYYksLxn+t1VJIZlP/dcHvzh9CxFAwfcFC4rg49dtMSpaKisrJsky97yxQ3DT1zy6Guv6OOKXMrGpfAm7jtQXtEQxE8ccXIL8NGOSckwDH8YCEUf1zmyCtqdLbPI0y6Wcu2y2S9J1aEwd8IBmN8aYnpmn/cuEtukxRhEKu1eWRYuwcSySKqgjKPXoqFeSUrXbE8q3VsZtpu9+byFXdUdJg0jK2UaJrXPo2+3N+hmaO5bXtJr0VCvpKVrrlg6xqbVy3lgzbkcctC8ObGPPHP486ToegPDyJOiCyG7qb2iX7F0jLUXnjyreGl0pMVHfnVJhVK50U/RUK9kmVTqtIVdnWQ1jLINk9q7biA+NzotkySOdkZNUS4hgcilWhnLuCzpmnXawq5OshpG2YZJIxR9HK454m3a+fdx/cmzEJdeGRdgLauQJ0sOep02d66TrIZRtmHSaEXf3h7w6s0PO2XC3HXZmXO+D/Ce6+52CrS2wwLHjI5wxokLuGHLlJeKx3VSqVNhUp1kNYyyDZPap1em4ZrTnpQr7pLCGbURiaX7xWNjYww6eT0DA5FemYarz0shtp9L3DKrnTcf90eyvirRWCqkYZSrHxqv6LPk2cdNCnHLLGtT2xtJGQc2noaRP7VPr0wjqSd6N6Pz524ZCMl9yo3sWCqkYZRL4y36qCDdk8/s3l/t2UlSuMLcMPlhqZCGUS6NV/QwV0mfsPrWyOOeynlzEiMaS4U0jHIp1HUjImeLyP0i8h0RWV3ktbJQZssBYy7mCjOMcinMoheRYeCvgV8GHgW+JSLrVfXbRV3TFbMoq8dcYYZRHkW6bl4CfEdV/xNARD4PvA6oXNFbcY1hGINEkYp+DHik4/WjwEu7DxKRlcBKgIULFxYozmzMojQMY1Ao0kcf1Sh4Tl6Lqq5T1XFVHV+wYEGB4hiGYQwmRSr6R4HjOl4fCzxW4PUMwzCMCIpU9N8Cni8iJ4jIc4CLgfUFXs8wDMOIoDAfvaruEZHfAzYAw8CnVfXeoq5nGIZhRFNowZSqfhH4YpHXMAzDMJJpfK8bwzCMQcerfvQisgN4KKfTHQX8IKdz5YmvcoHJ1iu+yuarXGCy9UKcXMeramLKoleKPk9EZDKtGX8V+CoXmGy94qtsvsoFJlsv9COXuW4MwzAajil6wzCMhtNkRb+uagFi8FUuMNl6xVfZfJULTLZe6FmuxvroDcMwjIAmW/SGYRgGpugNwzAaT60VvYh8WkQeF5F7Yj4XEfl4uMPVv4nIKR7JdrqIPCUid4X//ldJch0nIreLyH0icq+I/GHEMZWMm6NspY+biBwsIt8UkbtDua6IOOYgEbk2HLM7RGRR0XJlkO2tIrKjY8z+RxmydVx/WES2isgtEZ9VMm4OclU2ZiLyoIhsC687GfF59udTVWv7D3glcApwT8zn5wC3EbRMPg24wyPZTgduqWDMjgZOCX8+DPh34Bd8GDdH2Uoft3AcDg1/bgF3AKd1HfMO4BPhzxcD13ok21uBvyr7Xuu4/ruBz0X93aoaNwe5Khsz4EHgqITPMz+ftbboVfWrwBMJh7wO+IwGbAZGReRoT2SrBFX9nqreGf78NHAfwSYxnVQybo6ylU44Dj8OX7bCf91ZDK8Drgp/vh54lYhE7clQhWyVISLHAucCn4w5pJJxc5DLZzI/n7VW9A5E7XJVueLo4GXhkvs2EXlR2RcPl8lLCazATioftwTZoIJxC5f5dwGPA/9PVWPHTFX3AE8BP+WJbACvD5f514vIcRGfF8XHgPcB+2I+r2rc0uSC6sZMgS+LyBYJduDrJvPz2XRF77TLVUXcSdCj4mTgfwMTZV5cRA4FbgDeqao/6v444iuljVuKbJWMm6ruVdUlBBvovEREXtx1SGVj5iDbzcAiVf1F4J84YEEXioi8FnhcVbckHRbxXqHj5ihXJWMWskxVTwFeA/yuiLyy6/PMY9Z0Re/tLleq+qP2kluDds4tETmqjGuLSItAkV6tqjdGHFLZuKXJVuW4hdfcCXwFOLvro/1jJiLzgCMo2XUXJ5uq/lBVd4cv/w44tSSRlgHni8iDwOeB5SLy2a5jqhi3VLkqHDNU9bHw/8eBm4CXdB2S+flsuqJfD7wljFKfBjylqt+rWigAEfnZti9SRF5C8Lf4YQnXFeBTwH2q+pGYwyoZNxfZqhg3EVkgIqPhzyPAq4HtXYetB349/PlCYKOGkbOqZevy355PEPsoHFV9v6oeq6qLCAKtG1X1TV2HlT5uLnJVNWYicoiIHNb+GTgT6M7cy/x8FrrxSNGIyDUEWRhHicijwGUEwShU9RMEm56cA3wH2AX8hkeyXQi8XUT2ANPAxWUoBgJr5s3AttCvC/DHwMIO2aoaNxfZqhi3o4GrRGSYYGK5TlVvEZEPAJOqup5ggvoHEfkOgUV6ccEyZZHtD0TkfGBPKNtbS5ItEk/GLU2uqsbsZ4CbQltmHvA5Vf2SiPwO9P58WgsEwzCMhtN0141hGMbAY4reMAyj4ZiiNwzDaDim6A3DMBqOKXrDMIyGY4reqBwR2Rt26rtHRL4gIvP7ONfpEnYjFJHzRWR1wrGjIvKOHq5xuYi8N+K63+h6b56IfD+pD0nUuQwjb0zRGz4wrapLVPXFwLPA73R+GBaGZL5XVXW9qq5JOGSUoHtiHnwVOFZmt9l9NUH3Ui+K9IzBxRS94RtfA35eRBZJ0Jf+bwj62xwnImeKyDdE5M7Q8j8UQETOFpHtIvJ14IL2iSToKf5X4c8/IyI3SdAM7W4ReTmwBvi5cDWxNjxulYh8S4JmVld0nOtPROR+EfknYHG30Kq6D/gCcFHH2xcD14Tf/63wvHeLyA1RqxYR+YqIjIc/HxWW6Leblq3tkOu3w/ePFpGvdqyGXtHroBvNxhS94Q0S9Dp5DbAtfGsxQTvWpcAzwKXAq8OGT5PAu0XkYIJeJOcBrwB+Nub0Hwf+JWyGdgpwL7Aa+G64mlglImcCzyfoLbIEOFVEXikipxIo7aUEE8kvxVzjmvA4ROQggurFG8LPblTVXwqvfx/wtgxD8zaCMvdfCq/9WyJyAvBrwIawodnJwF0J5zAGmFq3QDAaw0hHy4OvEZTFHwM8FPbbhmCDhV8ANoXl4c8BvgGcCDygqv8BIEFzqqjWrsuBt0DQ7RF4SkSO7DrmzPDf1vD1oQSK/zDgJlXdFV5jfdQvoarfEpFDRWQx8EJgs6o+GX78YhH5IIG76FBgQ+qozJbrF0XkwvD1EaFc3wI+LUEjuAlVNUVvRGKK3vCB6dAq3U+ozJ/pfIug1/olXcctIb+2tgJcqap/23WNd2a4xucJrPoXErptQv4eWKGqd4vIWwn6IHWzhwOr7IO75Pp9VZ0zOUjQwvZcgn4xa1X1M45yGgOEuW6MurAZWCYiPw8gIvNF5AUEnRpPEJGfC4+7JOb7/wy8PfzusIgcDjxNYK232QD8Zofvf0xEfpog0PorIjIiQWfB8xLkvAZ4E8EKotPyPwz4Xmh9vzHmuw9yoB3uhR3vbyBo5NYK5XqBBF0Ojyfoq/53BKug0vZENuqFWfRGLVDVHaElfE3o/wa4VFX/XYJdeG4VkR8AXwe6N94A+ENgnYi8DdgLvF1VvyEimyTYwP220E//QuAb4Yrix8CbVPVOEbmWwAf+EIF7KU7Ob4vILmCLqnauSP4nwW5ZDxHEIA6L+PpfANeJyJuBjR3vfxJYBNwpgWA7gBUEq4JVIjITyvqWOLmMwca6VxqGYTQcc90YhmE0HFP0hmEYDccUvWEYRsMxRW8YhtFwTNEbhmE0HFP0hmEYDccUvWEYRsP5LzKR5+oCMBcXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "X_scl = scaler.fit_transform(X)\n",
    "predictions = loaded_model.predict(X_scl)\n",
    "plt.scatter(predictions,y)\n",
    "plt.ylabel(\"Y Test (True Values)\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "print('MAE:', metrics.mean_absolute_error(y, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y, predictions)))\n",
    "\n",
    "print(\"ESV: \", explained_variance_score(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,x_vars=['age','draft_pos','attempts','yards_run','tds_run','longgain_run','g','gs','tgt','rec','yards_rec','tds_rec','firstdowns','longgain_rec','fumbles','team_adjusted_line_yards','team_running_back_yards','team_stuffed_rate'],y_vars=['Percenthit (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
