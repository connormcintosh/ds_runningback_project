{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../../data/processed/oline_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"../../data/processed/oline_merge.csv\")\n",
    "df = df[df.year >= df.draft_yr+3]\n",
    "# df =df[df.year != 2020]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>year</th>\n",
       "      <th>age</th>\n",
       "      <th>draft_yr</th>\n",
       "      <th>draft_pos</th>\n",
       "      <th>attempts</th>\n",
       "      <th>yards_run</th>\n",
       "      <th>tds_run</th>\n",
       "      <th>longgain_run</th>\n",
       "      <th>...</th>\n",
       "      <th>tds_rec</th>\n",
       "      <th>firstdowns</th>\n",
       "      <th>longgain_rec</th>\n",
       "      <th>yardspertarget</th>\n",
       "      <th>recpergame</th>\n",
       "      <th>yardspergame_rec</th>\n",
       "      <th>fumbles</th>\n",
       "      <th>team_adjusted_line_yards</th>\n",
       "      <th>team_running_back_yards</th>\n",
       "      <th>team_stuffed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>299.397306</td>\n",
       "      <td>299.397306</td>\n",
       "      <td>2014.754209</td>\n",
       "      <td>27.457912</td>\n",
       "      <td>2009.441077</td>\n",
       "      <td>62.659933</td>\n",
       "      <td>143.498316</td>\n",
       "      <td>604.922559</td>\n",
       "      <td>4.323232</td>\n",
       "      <td>37.451178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>9.696970</td>\n",
       "      <td>28.629630</td>\n",
       "      <td>5.773064</td>\n",
       "      <td>2.154545</td>\n",
       "      <td>16.813131</td>\n",
       "      <td>1.686869</td>\n",
       "      <td>16.932660</td>\n",
       "      <td>17.340067</td>\n",
       "      <td>16.104377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>164.758086</td>\n",
       "      <td>164.758086</td>\n",
       "      <td>3.545580</td>\n",
       "      <td>2.443776</td>\n",
       "      <td>4.088224</td>\n",
       "      <td>70.662565</td>\n",
       "      <td>96.268176</td>\n",
       "      <td>431.800165</td>\n",
       "      <td>4.129234</td>\n",
       "      <td>20.634000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247848</td>\n",
       "      <td>7.107459</td>\n",
       "      <td>15.392309</td>\n",
       "      <td>1.758190</td>\n",
       "      <td>1.206257</td>\n",
       "      <td>10.588606</td>\n",
       "      <td>1.561659</td>\n",
       "      <td>9.245279</td>\n",
       "      <td>9.176323</td>\n",
       "      <td>9.157733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>2097.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>58.700000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1         year         age     draft_yr  \\\n",
       "count  297.000000    297.000000   297.000000  297.000000   297.000000   \n",
       "mean   299.397306    299.397306  2014.754209   27.457912  2009.441077   \n",
       "std    164.758086    164.758086     3.545580    2.443776     4.088224   \n",
       "min      0.000000      0.000000  2004.000000   22.000000  1999.000000   \n",
       "25%    172.000000    172.000000  2013.000000   26.000000  2007.000000   \n",
       "50%    291.000000    291.000000  2015.000000   27.000000  2009.000000   \n",
       "75%    446.000000    446.000000  2018.000000   29.000000  2013.000000   \n",
       "max    599.000000    599.000000  2020.000000   37.000000  2017.000000   \n",
       "\n",
       "        draft_pos    attempts    yards_run     tds_run  longgain_run  ...  \\\n",
       "count  297.000000  297.000000   297.000000  297.000000    297.000000  ...   \n",
       "mean    62.659933  143.498316   604.922559    4.323232     37.451178  ...   \n",
       "std     70.662565   96.268176   431.800165    4.129234     20.634000  ...   \n",
       "min     -1.000000    2.000000    -3.000000    0.000000      3.000000  ...   \n",
       "25%      5.000000   56.000000   240.000000    1.000000     20.000000  ...   \n",
       "50%     48.000000  134.000000   525.000000    3.000000     34.000000  ...   \n",
       "75%     77.000000  220.000000   934.000000    6.000000     51.000000  ...   \n",
       "max    250.000000  392.000000  2097.000000   28.000000     97.000000  ...   \n",
       "\n",
       "          tds_rec  firstdowns  longgain_rec  yardspertarget  recpergame  \\\n",
       "count  297.000000  297.000000    297.000000      297.000000  297.000000   \n",
       "mean     0.939394    9.696970     28.629630        5.773064    2.154545   \n",
       "std      1.247848    7.107459     15.392309        1.758190    1.206257   \n",
       "min      0.000000    0.000000      3.000000       -0.400000    0.100000   \n",
       "25%      0.000000    4.000000     18.000000        4.700000    1.200000   \n",
       "50%      1.000000    8.000000     25.000000        5.800000    2.000000   \n",
       "75%      1.000000   14.000000     35.000000        6.500000    2.900000   \n",
       "max      7.000000   32.000000     80.000000       12.200000    6.300000   \n",
       "\n",
       "       yardspergame_rec     fumbles  team_adjusted_line_yards  \\\n",
       "count        297.000000  297.000000                297.000000   \n",
       "mean          16.813131    1.686869                 16.932660   \n",
       "std           10.588606    1.561659                  9.245279   \n",
       "min           -0.300000    0.000000                  1.000000   \n",
       "25%            8.800000    0.000000                  9.000000   \n",
       "50%           14.600000    1.000000                 17.000000   \n",
       "75%           23.400000    3.000000                 25.000000   \n",
       "max           58.700000    7.000000                 32.000000   \n",
       "\n",
       "       team_running_back_yards  team_stuffed_rate  \n",
       "count               297.000000         297.000000  \n",
       "mean                 17.340067          16.104377  \n",
       "std                   9.176323           9.157733  \n",
       "min                   1.000000           1.000000  \n",
       "25%                  10.000000           8.000000  \n",
       "50%                  18.000000          17.000000  \n",
       "75%                  25.000000          24.000000  \n",
       "max                  32.000000          32.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>draft_pos</th>\n",
       "      <th>tds_run</th>\n",
       "      <th>longgain_run</th>\n",
       "      <th>yardsperatt</th>\n",
       "      <th>Percenthit (%)</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>yardsperrec</th>\n",
       "      <th>tds_rec</th>\n",
       "      <th>firstdowns</th>\n",
       "      <th>longgain_rec</th>\n",
       "      <th>yardspertarget</th>\n",
       "      <th>fumbles</th>\n",
       "      <th>team_adjusted_line_yards</th>\n",
       "      <th>team_running_back_yards</th>\n",
       "      <th>team_stuffed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>27.457912</td>\n",
       "      <td>62.659933</td>\n",
       "      <td>4.323232</td>\n",
       "      <td>37.451178</td>\n",
       "      <td>4.091919</td>\n",
       "      <td>2.585167</td>\n",
       "      <td>12.582492</td>\n",
       "      <td>7.858586</td>\n",
       "      <td>7.759933</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>9.696970</td>\n",
       "      <td>28.629630</td>\n",
       "      <td>5.773064</td>\n",
       "      <td>1.686869</td>\n",
       "      <td>16.932660</td>\n",
       "      <td>17.340067</td>\n",
       "      <td>16.104377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.443776</td>\n",
       "      <td>70.662565</td>\n",
       "      <td>4.129234</td>\n",
       "      <td>20.634000</td>\n",
       "      <td>0.900789</td>\n",
       "      <td>2.301601</td>\n",
       "      <td>3.859102</td>\n",
       "      <td>5.713326</td>\n",
       "      <td>2.242731</td>\n",
       "      <td>1.247848</td>\n",
       "      <td>7.107459</td>\n",
       "      <td>15.392309</td>\n",
       "      <td>1.758190</td>\n",
       "      <td>1.561659</td>\n",
       "      <td>9.245279</td>\n",
       "      <td>9.176323</td>\n",
       "      <td>9.157733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.100644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0.829187</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.915871</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.531786</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.300813</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age   draft_pos     tds_run  longgain_run  yardsperatt  \\\n",
       "count  297.000000  297.000000  297.000000    297.000000   297.000000   \n",
       "mean    27.457912   62.659933    4.323232     37.451178     4.091919   \n",
       "std      2.443776   70.662565    4.129234     20.634000     0.900789   \n",
       "min     22.000000   -1.000000    0.000000      3.000000    -0.300000   \n",
       "25%     26.000000    5.000000    1.000000     20.000000     3.600000   \n",
       "50%     27.000000   48.000000    3.000000     34.000000     4.100000   \n",
       "75%     29.000000   77.000000    6.000000     51.000000     4.600000   \n",
       "max     37.000000  250.000000   28.000000     97.000000     7.700000   \n",
       "\n",
       "       Percenthit (%)           g          gs  yardsperrec     tds_rec  \\\n",
       "count      297.000000  297.000000  297.000000   297.000000  297.000000   \n",
       "mean         2.585167   12.582492    7.858586     7.759933    0.939394   \n",
       "std          2.301601    3.859102    5.713326     2.242731    1.247848   \n",
       "min          0.100644    1.000000    0.000000    -0.500000    0.000000   \n",
       "25%          0.829187   10.000000    2.000000     6.500000    0.000000   \n",
       "50%          1.915871   14.000000    7.000000     7.700000    1.000000   \n",
       "75%          3.531786   16.000000   14.000000     8.700000    1.000000   \n",
       "max         11.300813   16.000000   16.000000    19.000000    7.000000   \n",
       "\n",
       "       firstdowns  longgain_rec  yardspertarget     fumbles  \\\n",
       "count  297.000000    297.000000      297.000000  297.000000   \n",
       "mean     9.696970     28.629630        5.773064    1.686869   \n",
       "std      7.107459     15.392309        1.758190    1.561659   \n",
       "min      0.000000      3.000000       -0.400000    0.000000   \n",
       "25%      4.000000     18.000000        4.700000    0.000000   \n",
       "50%      8.000000     25.000000        5.800000    1.000000   \n",
       "75%     14.000000     35.000000        6.500000    3.000000   \n",
       "max     32.000000     80.000000       12.200000    7.000000   \n",
       "\n",
       "       team_adjusted_line_yards  team_running_back_yards  team_stuffed_rate  \n",
       "count                297.000000               297.000000         297.000000  \n",
       "mean                  16.932660                17.340067          16.104377  \n",
       "std                    9.245279                 9.176323           9.157733  \n",
       "min                    1.000000                 1.000000           1.000000  \n",
       "25%                    9.000000                10.000000           8.000000  \n",
       "50%                   17.000000                18.000000          17.000000  \n",
       "75%                   25.000000                25.000000          24.000000  \n",
       "max                   32.000000                32.000000          32.000000  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('year',axis=1)\n",
    "df = df.drop('playername',axis=1)\n",
    "df = df.drop('team',axis=1)\n",
    "df = df.drop('basesalarycap (10^8)',axis=1)\n",
    "df = df.drop('cashspent (M)',axis=1)\n",
    "df = df.drop('caphit (M)',axis=1)\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df = df.drop('Unnamed: 0.1',axis=1)\n",
    "df = df.drop('catchpercent',axis=1)\n",
    "df = df.drop('draft_yr',axis=1)\n",
    "\n",
    "# df = df.drop('yardspergame_run',axis=1)\n",
    "# df = df.drop('yardsperatt',axis=1)\n",
    "# df = df.drop('yardspertarget',axis=1)\n",
    "# df = df.drop('yardsperrec',axis=1)\n",
    "# df = df.drop('recpergame',axis=1)\n",
    "# df = df.drop('yardspergame_rec',axis=1)\n",
    "\n",
    "df = df.drop('yards_run',axis=1)\n",
    "df = df.drop('yards_rec',axis=1)\n",
    "df = df.drop('attempts',axis=1)\n",
    "df = df.drop('rec',axis=1)\n",
    "df = df.drop('recpergame',axis=1)\n",
    "df = df.drop('yardspergame_rec',axis=1)\n",
    "df = df.drop('yardspergame_run',axis=1)\n",
    "df = df.drop('tgt',axis=1)\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Percenthit (%)',axis=1).values\n",
    "y = df['Percenthit (%)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 10.9743 - val_loss: 7.2531\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.5945 - val_loss: 4.5664\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9776 - val_loss: 4.3597\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6243 - val_loss: 4.3136\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5588 - val_loss: 4.0322\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2481 - val_loss: 3.9482\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0921 - val_loss: 4.3910\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0020 - val_loss: 3.8692\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1317 - val_loss: 4.7274\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0147 - val_loss: 3.9115\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9578 - val_loss: 4.4887\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8704 - val_loss: 3.9703\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7408 - val_loss: 3.8484\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8027 - val_loss: 3.7453\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8023 - val_loss: 3.7182\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6707 - val_loss: 4.0514\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8210 - val_loss: 4.1230\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8410 - val_loss: 5.8111\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7583 - val_loss: 3.7984\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6514 - val_loss: 3.8186\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.526 - 0s 4ms/step - loss: 3.6195 - val_loss: 3.6530\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8267 - val_loss: 3.6435\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5927 - val_loss: 3.7971\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5829 - val_loss: 4.1932\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5484 - val_loss: 3.8382\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5910 - val_loss: 3.8295\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5358 - val_loss: 3.8420\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7240 - val_loss: 4.8761\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7742 - val_loss: 3.4624\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6230 - val_loss: 4.2716\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7331 - val_loss: 5.7014\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0866 - val_loss: 3.5808\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5155 - val_loss: 3.5281\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4647 - val_loss: 4.9105\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4021 - val_loss: 4.4576\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5373 - val_loss: 7.3100\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1024 - val_loss: 3.4807\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4195 - val_loss: 3.6642\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6656 - val_loss: 5.0010\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6102 - val_loss: 3.5412\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3716 - val_loss: 8.1634\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0222 - val_loss: 3.3268\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4395 - val_loss: 3.4715\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3096 - val_loss: 3.9224\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7655 - val_loss: 3.3996\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4340 - val_loss: 3.3005\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5384 - val_loss: 5.6726\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6551 - val_loss: 5.4922\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5411 - val_loss: 6.7334\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5237 - val_loss: 3.2202\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34CE38C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.30832720254901724\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4797 - val_loss: 4.1113\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5350 - val_loss: 4.1454\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4125 - val_loss: 4.3448\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3011 - val_loss: 4.1545\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2101 - val_loss: 4.2895\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1530 - val_loss: 5.0840\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3054 - val_loss: 3.9989\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1596 - val_loss: 3.6949\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0029 - val_loss: 3.9108\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9936 - val_loss: 3.5434\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8461 - val_loss: 4.0153\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8839 - val_loss: 3.4888\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7425 - val_loss: 5.7144\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0887 - val_loss: 3.3672\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9394 - val_loss: 4.4991\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8504 - val_loss: 3.3049\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0448 - val_loss: 3.2969\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7499 - val_loss: 3.5287\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5742 - val_loss: 3.1440\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6069 - val_loss: 3.2535\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8044 - val_loss: 3.1493\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8295 - val_loss: 3.0769\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6868 - val_loss: 3.1952\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5414 - val_loss: 5.8283\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8424 - val_loss: 3.3563\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5607 - val_loss: 3.0474\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 3.6209 - val_loss: 3.0478\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6113 - val_loss: 2.9861\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4758 - val_loss: 3.0084\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6539 - val_loss: 2.9315\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4748 - val_loss: 3.5585\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8040 - val_loss: 3.9345\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7113 - val_loss: 3.2245\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3500 - val_loss: 3.9885\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5778 - val_loss: 3.7673\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5488 - val_loss: 3.0383\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7009 - val_loss: 5.4542\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6704 - val_loss: 5.2388\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7661 - val_loss: 3.4668\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1632 - val_loss: 3.0159\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2502 - val_loss: 5.1783\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.913 - 0s 3ms/step - loss: 3.5401 - val_loss: 2.9008\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4030 - val_loss: 2.9391\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4813 - val_loss: 5.9122\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3682 - val_loss: 2.7159\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0468 - val_loss: 2.7371\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6644 - val_loss: 3.1309\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1735 - val_loss: 2.8971\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0628 - val_loss: 6.4453\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5877 - val_loss: 3.1232\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35CE45A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3570542753924917\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.1815 - val_loss: 4.7639\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8358 - val_loss: 4.1033\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5766 - val_loss: 3.8980\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6897 - val_loss: 4.6838\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4628 - val_loss: 4.0458\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3400 - val_loss: 3.7694\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2370 - val_loss: 3.8906\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1738 - val_loss: 3.5375\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9933 - val_loss: 3.5395\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2084 - val_loss: 3.8791\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2889 - val_loss: 4.0531\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0803 - val_loss: 3.3911\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1891 - val_loss: 3.3353\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9568 - val_loss: 3.4509\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9786 - val_loss: 7.3173\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3084 - val_loss: 3.2846\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3046 - val_loss: 3.4523\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9393 - val_loss: 3.3012\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9432 - val_loss: 3.5673\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9611 - val_loss: 3.4516\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7174 - val_loss: 3.2407\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9646 - val_loss: 3.2272\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7910 - val_loss: 3.2681\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0462 - val_loss: 3.2243\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7078 - val_loss: 3.1893\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6776 - val_loss: 3.6992\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7645 - val_loss: 5.8843\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8837 - val_loss: 3.9092\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7279 - val_loss: 3.3002\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6785 - val_loss: 3.1261\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8394 - val_loss: 3.3054\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7050 - val_loss: 3.0708\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6411 - val_loss: 3.0690\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8249 - val_loss: 3.5980\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4125 - val_loss: 17.7645\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.5482 - val_loss: 3.2434\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7399 - val_loss: 3.1920\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5433 - val_loss: 3.2231\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6773 - val_loss: 3.4668\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7442 - val_loss: 3.4780\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5481 - val_loss: 3.5387\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5360 - val_loss: 4.0919\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7790 - val_loss: 3.0340\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6499 - val_loss: 4.8058\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3292 - val_loss: 2.9688\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4858 - val_loss: 3.0613\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3670 - val_loss: 5.1262\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7821 - val_loss: 8.0731\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5607 - val_loss: 3.7837\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5163 - val_loss: 3.1900\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34C2DC9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.3483136048270008\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.4148 - val_loss: 5.6542\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.0988 - val_loss: 4.0647\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9649 - val_loss: 3.9293\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8100 - val_loss: 3.8754\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6342 - val_loss: 3.7399\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5130 - val_loss: 3.7249\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3397 - val_loss: 4.2543\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1311 - val_loss: 5.0398\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2914 - val_loss: 3.6271\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0280 - val_loss: 3.6151\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9306 - val_loss: 7.0011\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0924 - val_loss: 5.5435\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8375 - val_loss: 3.4829\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1956 - val_loss: 6.7521\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0012 - val_loss: 4.5320\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6840 - val_loss: 4.0833\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9689 - val_loss: 4.4835\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7771 - val_loss: 3.4929\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6836 - val_loss: 5.2912\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7267 - val_loss: 3.2896\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7197 - val_loss: 4.9376\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6250 - val_loss: 3.5784\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4209 - val_loss: 3.2353\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5169 - val_loss: 4.3863\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5859 - val_loss: 5.9598\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5200 - val_loss: 3.3243\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6865 - val_loss: 3.5104\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6533 - val_loss: 7.0518\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5531 - val_loss: 4.1285\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9055 - val_loss: 5.9357\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5833 - val_loss: 4.6067\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8026 - val_loss: 9.0437\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9248 - val_loss: 3.1253\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3036 - val_loss: 10.6330\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4722 - val_loss: 4.1007\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3587 - val_loss: 3.5016\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5760 - val_loss: 8.1189\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8285 - val_loss: 4.4582\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2213 - val_loss: 3.4543\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2510 - val_loss: 6.0315\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6941 - val_loss: 3.4890\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3708 - val_loss: 3.5458\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2961 - val_loss: 6.5647\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5184 - val_loss: 4.7196\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3330 - val_loss: 8.7456\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9237 - val_loss: 6.1131\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4567 - val_loss: 4.7527\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1658 - val_loss: 2.9337\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2747 - val_loss: 4.4004\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3246 - val_loss: 5.9143\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35A2991F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.0661558300232481\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.9561 - val_loss: 4.2479\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0123 - val_loss: 4.0157\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7465 - val_loss: 4.0139\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6037 - val_loss: 3.8774\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5034 - val_loss: 3.8020\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5636 - val_loss: 4.9315\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4018 - val_loss: 4.3329\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2311 - val_loss: 3.6252\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2367 - val_loss: 4.1082\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0466 - val_loss: 3.5636\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0966 - val_loss: 3.7075\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2546 - val_loss: 3.5515\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8212 - val_loss: 3.6742\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1302 - val_loss: 3.3010\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9533 - val_loss: 3.4412\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8677 - val_loss: 3.3157\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8428 - val_loss: 3.2323\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8068 - val_loss: 3.4844\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7437 - val_loss: 3.3282\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7458 - val_loss: 3.4393\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8864 - val_loss: 3.1286\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7465 - val_loss: 4.4085\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7122 - val_loss: 3.2263\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2199 - val_loss: 3.1267\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9719 - val_loss: 3.2239\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6179 - val_loss: 3.2182\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6957 - val_loss: 3.9222\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6493 - val_loss: 3.6697\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8019 - val_loss: 3.2934\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6493 - val_loss: 3.7898\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4746 - val_loss: 3.0655\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5319 - val_loss: 4.4498\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6361 - val_loss: 3.2145\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5181 - val_loss: 4.2195\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4003 - val_loss: 3.2236\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5020 - val_loss: 2.9637\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4014 - val_loss: 3.3819\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8664 - val_loss: 3.0537\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3478 - val_loss: 2.9554\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3674 - val_loss: 3.5070\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7774 - val_loss: 3.1275\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4623 - val_loss: 3.1697\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6289 - val_loss: 6.4828\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8665 - val_loss: 10.4173\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.1919 - val_loss: 5.2696\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1947 - val_loss: 3.0364\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4064 - val_loss: 3.0116\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4282 - val_loss: 5.6700\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5095 - val_loss: 3.6119\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4685 - val_loss: 4.3575\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F347689948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.2569544599949345\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.4444 - val_loss: 5.7239\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.8056 - val_loss: 4.4644\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9690 - val_loss: 4.6458\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7394 - val_loss: 4.3296\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6622 - val_loss: 4.2392\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5830 - val_loss: 4.1359\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4314 - val_loss: 4.2486\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2865 - val_loss: 4.1743\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1463 - val_loss: 3.9277\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0839 - val_loss: 4.2046\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1156 - val_loss: 3.9123\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9674 - val_loss: 3.7914\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0069 - val_loss: 3.7321\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8988 - val_loss: 6.8783\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8972 - val_loss: 3.8340\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7325 - val_loss: 3.4441\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7992 - val_loss: 4.1883\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0198 - val_loss: 3.6082\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6881 - val_loss: 3.4671\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8770 - val_loss: 4.4542\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.9197 - val_loss: 5.4618\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.7592 - val_loss: 3.6262\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4599 - val_loss: 3.5455\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.9529 - val_loss: 3.9968\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.7694 - val_loss: 3.5386\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9360 - val_loss: 3.3338\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7314 - val_loss: 3.8813\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4755 - val_loss: 3.6937\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6959 - val_loss: 3.5084\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4034 - val_loss: 3.1712\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7391 - val_loss: 4.4238\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5373 - val_loss: 3.0480\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3916 - val_loss: 4.4761\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6735 - val_loss: 3.0691\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4224 - val_loss: 5.0145\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7117 - val_loss: 3.1283\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2970 - val_loss: 2.9856\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1262 - val_loss: 4.8735\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5406 - val_loss: 3.5910\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8377 - val_loss: 3.1838\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3875 - val_loss: 3.3941\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3249 - val_loss: 3.0277\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4136 - val_loss: 3.2263\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3307 - val_loss: 2.9913\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9475 - val_loss: 3.3584\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4355 - val_loss: 2.8787\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3939 - val_loss: 4.2770\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3096 - val_loss: 3.4971\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3128 - val_loss: 3.6120\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1275 - val_loss: 4.4402\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3521FD048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.2114796724621495\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.2019 - val_loss: 5.4108\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.6434 - val_loss: 4.1252\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8441 - val_loss: 4.0844\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7015 - val_loss: 5.2056\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3527 - val_loss: 3.7081\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2671 - val_loss: 3.6773\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3636 - val_loss: 3.5927\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0493 - val_loss: 4.1929\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9449 - val_loss: 4.9441\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9667 - val_loss: 3.6610\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9746 - val_loss: 4.2070\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9989 - val_loss: 3.5095\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9316 - val_loss: 4.2201\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0683 - val_loss: 3.8478\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9273 - val_loss: 3.4572\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9331 - val_loss: 3.5637\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0812 - val_loss: 3.4252\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8916 - val_loss: 3.3036\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7455 - val_loss: 3.5159\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1724 - val_loss: 3.5115\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9255 - val_loss: 3.2020\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8876 - val_loss: 3.1991\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7526 - val_loss: 3.2819\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7852 - val_loss: 3.7233\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6674 - val_loss: 3.6034\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6722 - val_loss: 3.4156\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6655 - val_loss: 3.1216\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6710 - val_loss: 5.2128\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2286 - val_loss: 3.1117\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9036 - val_loss: 3.0427\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6092 - val_loss: 3.0105\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5726 - val_loss: 6.7100\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9662 - val_loss: 3.1214\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4774 - val_loss: 3.0476\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4442 - val_loss: 2.9662\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5061 - val_loss: 4.2040\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8847 - val_loss: 3.6503\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8418 - val_loss: 3.1131\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6623 - val_loss: 2.9576\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5293 - val_loss: 2.9804\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5491 - val_loss: 2.8994\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4736 - val_loss: 3.1451\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5214 - val_loss: 4.3124\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4838 - val_loss: 3.4420\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4314 - val_loss: 3.2124\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6492 - val_loss: 3.8802\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4579 - val_loss: 2.8865\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3473 - val_loss: 3.4591\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8849 - val_loss: 3.1770\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4540 - val_loss: 3.1401\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35CE45DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.367787121464758\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4257 - val_loss: 4.3891\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9381 - val_loss: 5.1767\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8708 - val_loss: 4.2259\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7540 - val_loss: 4.1614\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5311 - val_loss: 5.0581\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5246 - val_loss: 4.0614\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3428 - val_loss: 4.0607\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2965 - val_loss: 4.0016\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0624 - val_loss: 4.3860\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2715 - val_loss: 3.7296\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0945 - val_loss: 3.6734\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0727 - val_loss: 6.0518\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1895 - val_loss: 4.2143\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9167 - val_loss: 3.8996\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0153 - val_loss: 5.9437\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9769 - val_loss: 6.0863\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7984 - val_loss: 4.4403\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8266 - val_loss: 4.2466\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7760 - val_loss: 3.4173\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7632 - val_loss: 6.8061\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1925 - val_loss: 5.0531\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8218 - val_loss: 3.4216\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6718 - val_loss: 3.4554\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0030 - val_loss: 7.7960\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0467 - val_loss: 4.5824\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7213 - val_loss: 3.7699\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3585 - val_loss: 3.7785\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6380 - val_loss: 3.7737\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4161 - val_loss: 3.3608\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7285 - val_loss: 3.8797\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6100 - val_loss: 3.5230\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5397 - val_loss: 7.8711\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6221 - val_loss: 3.2915\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3568 - val_loss: 3.6674\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6638 - val_loss: 3.9107\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6911 - val_loss: 3.4273\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2412 - val_loss: 7.6700\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3154 - val_loss: 5.4434\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4099 - val_loss: 3.2965\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1980 - val_loss: 3.4319\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9000 - val_loss: 4.7546\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6392 - val_loss: 3.3934\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2927 - val_loss: 5.0634\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3876 - val_loss: 8.6666\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4338 - val_loss: 7.0641\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4264 - val_loss: 4.7738\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2972 - val_loss: 4.1344\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0955 - val_loss: 3.3404\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7002 - val_loss: 3.1369\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1612 - val_loss: 3.9040\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3509EB8B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.21437188671170293\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.9401 - val_loss: 3.8289\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4409 - val_loss: 3.7104\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3679 - val_loss: 5.0454\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3480 - val_loss: 3.6132\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1591 - val_loss: 3.7332\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9825 - val_loss: 4.6787\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0311 - val_loss: 3.7241\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9176 - val_loss: 4.1636\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9996 - val_loss: 3.5814\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9888 - val_loss: 3.8261\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8326 - val_loss: 3.9820\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9920 - val_loss: 3.6249\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7366 - val_loss: 3.4619\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7489 - val_loss: 4.1448\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7636 - val_loss: 3.5584\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7598 - val_loss: 4.1030\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6843 - val_loss: 3.3642\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7965 - val_loss: 3.4008\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6353 - val_loss: 3.9661\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5831 - val_loss: 3.4331\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8257 - val_loss: 3.7211\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5182 - val_loss: 3.2585\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5584 - val_loss: 5.5421\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8377 - val_loss: 3.7186\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5658 - val_loss: 3.6783\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5350 - val_loss: 3.4278\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6642 - val_loss: 4.4588\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6126 - val_loss: 3.2269\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4561 - val_loss: 3.1447\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4979 - val_loss: 3.5893\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5542 - val_loss: 5.1856\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8249 - val_loss: 4.3388\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4516 - val_loss: 3.8742\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4117 - val_loss: 3.3533\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5313 - val_loss: 3.1737\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4751 - val_loss: 3.3318\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4026 - val_loss: 4.9128\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6203 - val_loss: 3.0921\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6675 - val_loss: 3.0792\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3287 - val_loss: 3.0365\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4129 - val_loss: 3.7008\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3333 - val_loss: 3.0171\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2691 - val_loss: 7.9022\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0091 - val_loss: 3.0648\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3228 - val_loss: 3.4537\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4148 - val_loss: 3.0953\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4986 - val_loss: 5.4766\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8084 - val_loss: 6.0593\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5380 - val_loss: 3.7221\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6072 - val_loss: 5.0848\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3460E2828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.2021170073339007\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 11.0073 - val_loss: 7.0311\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.5805 - val_loss: 4.6620\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.3464 - val_loss: 4.0336\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7532 - val_loss: 4.0584\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5147 - val_loss: 4.4226\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4068 - val_loss: 4.1249\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2441 - val_loss: 3.8689\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1057 - val_loss: 4.8207\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0601 - val_loss: 3.7137\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0552 - val_loss: 3.5219\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0972 - val_loss: 3.6550\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2195 - val_loss: 5.0416\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9287 - val_loss: 3.7993\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8444 - val_loss: 4.8051\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0138 - val_loss: 3.6682\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7046 - val_loss: 4.5893\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0903 - val_loss: 3.4875\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8585 - val_loss: 3.3015\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7700 - val_loss: 4.5786\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7048 - val_loss: 6.8374\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1866 - val_loss: 3.4199\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7641 - val_loss: 4.1985\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2609 - val_loss: 3.0784\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7343 - val_loss: 3.7254\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6300 - val_loss: 3.2422\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5579 - val_loss: 3.9630\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6355 - val_loss: 3.0603\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7493 - val_loss: 13.5406\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1519 - val_loss: 3.4458\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5815 - val_loss: 3.8913\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5452 - val_loss: 3.2674\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5148 - val_loss: 3.5367\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3476 - val_loss: 3.1237\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5213 - val_loss: 7.0195\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7653 - val_loss: 2.9877\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3934 - val_loss: 2.9740\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4156 - val_loss: 3.2469\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3254 - val_loss: 5.5176\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3580 - val_loss: 2.9652\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3537 - val_loss: 3.0863\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4232 - val_loss: 2.9005\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2103 - val_loss: 3.3061\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3455 - val_loss: 2.9624\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3030 - val_loss: 3.7597\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1642 - val_loss: 2.9066\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2463 - val_loss: 2.7733\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2953 - val_loss: 2.7332\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1006 - val_loss: 2.7430\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3828 - val_loss: 2.8123\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0406 - val_loss: 12.0828\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F357B5D708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: -0.228463296488695\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 9.5349 - val_loss: 4.6065\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.1945 - val_loss: 3.9784\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7588 - val_loss: 3.7188\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5827 - val_loss: 4.0639\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5102 - val_loss: 3.5930\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3476 - val_loss: 3.7220\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2517 - val_loss: 3.5387\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.2860 - val_loss: 3.5665\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.3099 - val_loss: 3.4428\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.1720 - val_loss: 3.4208\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.2524 - val_loss: 3.3889\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.0603 - val_loss: 3.5124\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.0240 - val_loss: 3.3503\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.9675 - val_loss: 3.5029\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.8614 - val_loss: 4.9409\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0141 - val_loss: 4.0981\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8849 - val_loss: 3.2942\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7315 - val_loss: 3.2097\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6655 - val_loss: 3.3139\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8652 - val_loss: 3.4915\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6511 - val_loss: 3.4146\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8363 - val_loss: 3.1016\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.0644 - val_loss: 3.0722\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.8231 - val_loss: 3.1933\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6225 - val_loss: 3.2529\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6344 - val_loss: 3.2892\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 3.7135 - val_loss: 3.7980\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5369 - val_loss: 3.2327\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5093 - val_loss: 3.2304\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7543 - val_loss: 3.4437\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7622 - val_loss: 3.2949\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4617 - val_loss: 3.0930\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4938 - val_loss: 6.1860\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7389 - val_loss: 3.2221\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3826 - val_loss: 3.2328\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4506 - val_loss: 3.5732\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7937 - val_loss: 3.9102\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4375 - val_loss: 3.0503\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3270 - val_loss: 3.1292\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4185 - val_loss: 4.2902\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6716 - val_loss: 3.3217\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6317 - val_loss: 4.5416\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3812 - val_loss: 4.1749\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5935 - val_loss: 3.0151\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2888 - val_loss: 3.0719\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4037 - val_loss: 3.1604\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3290 - val_loss: 3.5632\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3576 - val_loss: 3.1375\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4998 - val_loss: 3.2060\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4325 - val_loss: 4.8454\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35CAAADC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.2934892411885578\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 10.2873 - val_loss: 5.5899\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7742 - val_loss: 3.7767\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7859 - val_loss: 4.0584\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6923 - val_loss: 3.6283\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4526 - val_loss: 3.9263\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2658 - val_loss: 4.3632\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1400 - val_loss: 3.3667\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0028 - val_loss: 3.4592\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9980 - val_loss: 3.3430\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9544 - val_loss: 3.2025\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8108 - val_loss: 3.3743\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7907 - val_loss: 4.7751\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7479 - val_loss: 3.1389\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8421 - val_loss: 3.5108\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7107 - val_loss: 3.1799\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7197 - val_loss: 4.0562\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1036 - val_loss: 3.5256\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6443 - val_loss: 3.8797\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5893 - val_loss: 6.1812\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0356 - val_loss: 2.9600\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9572 - val_loss: 2.9138\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6162 - val_loss: 3.0508\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6658 - val_loss: 3.2725\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6595 - val_loss: 3.0085\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4603 - val_loss: 2.8493\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5616 - val_loss: 2.9195\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6085 - val_loss: 3.4610\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4460 - val_loss: 2.8492\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5756 - val_loss: 3.1983\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4123 - val_loss: 3.8266\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6693 - val_loss: 2.7863\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3658 - val_loss: 2.8713\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6467 - val_loss: 2.7882\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7568 - val_loss: 7.4717\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5432 - val_loss: 3.0418\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2286 - val_loss: 2.9607\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2603 - val_loss: 2.9005\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3718 - val_loss: 2.8243\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3117 - val_loss: 5.3441\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6433 - val_loss: 2.8516\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1784 - val_loss: 4.6118\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3195 - val_loss: 2.8405\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3177 - val_loss: 3.1840\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4262 - val_loss: 3.3145\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1099 - val_loss: 3.0262\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0112 - val_loss: 2.8798\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1998 - val_loss: 3.8623\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0528 - val_loss: 2.9381\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9226 - val_loss: 4.0454\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4667 - val_loss: 3.0962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34609EF78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.3660642111138269\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.6268 - val_loss: 3.9600\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5481 - val_loss: 3.9117\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4420 - val_loss: 3.6799\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1642 - val_loss: 3.6623\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1297 - val_loss: 3.7439\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9694 - val_loss: 3.9800\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0025 - val_loss: 3.5340\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1254 - val_loss: 3.5322\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0510 - val_loss: 4.4786\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9781 - val_loss: 3.5289\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9510 - val_loss: 5.9051\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0878 - val_loss: 4.3329\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8156 - val_loss: 3.9701\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7754 - val_loss: 3.4505\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7870 - val_loss: 3.9006\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6466 - val_loss: 4.0576\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7863 - val_loss: 5.5097\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6629 - val_loss: 3.6729\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0278 - val_loss: 3.5863\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6761 - val_loss: 3.6149\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8277 - val_loss: 3.8764\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5222 - val_loss: 3.2935\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6046 - val_loss: 3.3348\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8259 - val_loss: 4.6635\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5634 - val_loss: 3.2256\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.6744 - val_loss: 3.4448\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5848 - val_loss: 3.3533\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5659 - val_loss: 5.0074\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5023 - val_loss: 3.5881\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4540 - val_loss: 6.2246\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5898 - val_loss: 3.2157\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5729 - val_loss: 3.2088\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5852 - val_loss: 3.0574\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5012 - val_loss: 3.3324\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5257 - val_loss: 4.9008\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4666 - val_loss: 3.7055\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2489 - val_loss: 2.8877\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4458 - val_loss: 5.4880\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5202 - val_loss: 3.1278\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8784 - val_loss: 3.8573\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2603 - val_loss: 3.5209\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1935 - val_loss: 3.4633\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8484 - val_loss: 3.7492\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2332 - val_loss: 3.0458\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4387 - val_loss: 2.9336\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0344 - val_loss: 3.0105\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4032 - val_loss: 3.6376\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5472 - val_loss: 3.7015\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0688 - val_loss: 3.0550\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9969 - val_loss: 3.2476\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35CC379D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.36532007969121916\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.1913 - val_loss: 5.1430\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7022 - val_loss: 4.4764\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0031 - val_loss: 4.1242\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0210 - val_loss: 4.4176\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7021 - val_loss: 4.1894\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5617 - val_loss: 4.2288\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4646 - val_loss: 4.3109\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2892 - val_loss: 3.7853\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2438 - val_loss: 3.7226\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1152 - val_loss: 3.7195\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1141 - val_loss: 3.8054\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1256 - val_loss: 5.5670\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0327 - val_loss: 3.8407\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9118 - val_loss: 3.6596\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0606 - val_loss: 3.4916\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8563 - val_loss: 3.5300\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9199 - val_loss: 4.4565\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0239 - val_loss: 3.4437\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7954 - val_loss: 3.3712\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0432 - val_loss: 3.9995\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7658 - val_loss: 4.7258\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7299 - val_loss: 3.4130\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6246 - val_loss: 8.3787\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8201 - val_loss: 3.7123\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6712 - val_loss: 9.3877\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8117 - val_loss: 3.4183\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6259 - val_loss: 3.4345\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6587 - val_loss: 3.3494\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8003 - val_loss: 3.2514\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6437 - val_loss: 3.4104\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9341 - val_loss: 3.2293\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6035 - val_loss: 4.7236\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8047 - val_loss: 3.2525\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3834 - val_loss: 6.2957\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4779 - val_loss: 6.9441\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5064 - val_loss: 3.4992\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6723 - val_loss: 4.4365\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5774 - val_loss: 3.2814\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4720 - val_loss: 6.0683\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3744 - val_loss: 6.1138\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2891 - val_loss: 3.6123\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3151 - val_loss: 5.2491\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5432 - val_loss: 5.1479\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2670 - val_loss: 3.5079\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7430 - val_loss: 5.4126\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3511 - val_loss: 5.9108\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5496 - val_loss: 5.2624\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5961 - val_loss: 4.9305\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3841 - val_loss: 5.8845\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0958 - val_loss: 4.7851\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35B72F798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.23969339841409898\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 10.1207 - val_loss: 5.2753\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4172 - val_loss: 4.1423\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5291 - val_loss: 4.6344\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3316 - val_loss: 4.0325\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3916 - val_loss: 4.6255\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2196 - val_loss: 4.6853\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2775 - val_loss: 4.6013\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3463 - val_loss: 4.7242\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1490 - val_loss: 4.0142\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1649 - val_loss: 3.9199\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1608 - val_loss: 3.8682\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0803 - val_loss: 4.1805\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1160 - val_loss: 3.9136\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0904 - val_loss: 5.2667\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0750 - val_loss: 3.7689\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9854 - val_loss: 5.0340\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9168 - val_loss: 3.6431\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8282 - val_loss: 3.5968\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9399 - val_loss: 11.7455\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1383 - val_loss: 3.4774\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8885 - val_loss: 3.9388\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7242 - val_loss: 5.4205\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6911 - val_loss: 3.5842\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7294 - val_loss: 4.0834\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9289 - val_loss: 3.5286\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6933 - val_loss: 3.2884\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6481 - val_loss: 3.2750\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6769 - val_loss: 3.1914\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8279 - val_loss: 3.2596\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5820 - val_loss: 5.4557\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7870 - val_loss: 3.5510\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5893 - val_loss: 3.3803\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5896 - val_loss: 5.3572\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6550 - val_loss: 5.6115\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6686 - val_loss: 3.2216\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5069 - val_loss: 3.0586\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6413 - val_loss: 4.2821\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5075 - val_loss: 3.4607\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4032 - val_loss: 5.4673\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5181 - val_loss: 3.5935\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3677 - val_loss: 5.5221\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7211 - val_loss: 3.3328\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5872 - val_loss: 3.5131\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3388 - val_loss: 6.7193\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5244 - val_loss: 3.1609\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4428 - val_loss: 3.0216\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3441 - val_loss: 2.9308\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3999 - val_loss: 3.9962\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4650 - val_loss: 3.8018\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4942 - val_loss: 5.5505\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F342083F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.18876270733733636\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.6668 - val_loss: 5.8240\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2110 - val_loss: 4.1210\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0083 - val_loss: 3.9512\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7205 - val_loss: 4.3509\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6371 - val_loss: 3.8066\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4889 - val_loss: 3.8679\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5763 - val_loss: 6.3991\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4001 - val_loss: 4.2740\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2436 - val_loss: 3.6556\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0390 - val_loss: 4.1647\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9796 - val_loss: 4.4373\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0091 - val_loss: 3.6097\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0127 - val_loss: 4.2400\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8822 - val_loss: 5.0382\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8906 - val_loss: 3.6220\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0086 - val_loss: 3.4962\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0033 - val_loss: 3.7482\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0878 - val_loss: 3.5297\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9660 - val_loss: 5.5978\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0197 - val_loss: 4.1821\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.8628 - val_loss: 4.0453\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6669 - val_loss: 3.3927\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7803 - val_loss: 4.6651\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6939 - val_loss: 4.8133\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7036 - val_loss: 3.3877\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6535 - val_loss: 3.4487\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7493 - val_loss: 5.1555\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7007 - val_loss: 4.6511\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7185 - val_loss: 3.5218\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9398 - val_loss: 4.3879\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7599 - val_loss: 4.0458\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6589 - val_loss: 3.3371\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6850 - val_loss: 3.5230\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7803 - val_loss: 8.6664\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1111 - val_loss: 4.8265\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5461 - val_loss: 4.0875\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4654 - val_loss: 5.6785\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6789 - val_loss: 3.1860\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6039 - val_loss: 3.2505\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5263 - val_loss: 3.4735\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4169 - val_loss: 3.5662\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7516 - val_loss: 3.2286\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4579 - val_loss: 5.0731\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5559 - val_loss: 3.0546\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4696 - val_loss: 6.6463\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5083 - val_loss: 10.4427\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1177 - val_loss: 3.6070\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5821 - val_loss: 5.6451\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5269 - val_loss: 2.9506\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4440 - val_loss: 5.3459\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34F667F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.14706901413989704\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4508 - val_loss: 4.1364\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9166 - val_loss: 3.9746\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7325 - val_loss: 3.9101\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3945 - val_loss: 3.8868\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5054 - val_loss: 4.3474\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3319 - val_loss: 4.2741\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1687 - val_loss: 8.3633\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5613 - val_loss: 4.2640\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0715 - val_loss: 4.2619\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1066 - val_loss: 4.0224\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1604 - val_loss: 5.7214\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1143 - val_loss: 3.6952\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2898 - val_loss: 4.2894\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0909 - val_loss: 4.2303\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.808 - 0s 4ms/step - loss: 3.9899 - val_loss: 3.9755\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8011 - val_loss: 8.8015\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4257 - val_loss: 4.5865\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9922 - val_loss: 3.7223\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7901 - val_loss: 6.1935\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8003 - val_loss: 3.8006\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7745 - val_loss: 3.5486\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6943 - val_loss: 3.5676\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9010 - val_loss: 3.4598\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7777 - val_loss: 4.0291\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9225 - val_loss: 3.5905\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6589 - val_loss: 3.4128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7738 - val_loss: 3.4547\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7427 - val_loss: 4.6063\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6901 - val_loss: 5.9083\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7113 - val_loss: 4.2177\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5136 - val_loss: 4.2616\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6185 - val_loss: 3.2908\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7449 - val_loss: 4.0822\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7688 - val_loss: 3.3478\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6761 - val_loss: 3.7107\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8428 - val_loss: 4.2856\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7868 - val_loss: 3.2492\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6034 - val_loss: 3.5276\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4248 - val_loss: 3.2318\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.6622 - val_loss: 3.8657\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4890 - val_loss: 3.1385\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3503 - val_loss: 3.5647\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3737 - val_loss: 3.8844\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9860 - val_loss: 3.3950\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6999 - val_loss: 3.1475\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4326 - val_loss: 5.0949\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5410 - val_loss: 3.5032\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6572 - val_loss: 5.9333\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4956 - val_loss: 3.1193\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4419 - val_loss: 3.2507\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3409FC948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3059626496577408\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.7873 - val_loss: 4.4971\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6515 - val_loss: 3.8810\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4075 - val_loss: 3.9860\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6330 - val_loss: 3.8636\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3214 - val_loss: 3.8222\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4610 - val_loss: 3.7602\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1975 - val_loss: 4.1296\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0835 - val_loss: 3.6921\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2176 - val_loss: 5.3153\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2773 - val_loss: 4.5991\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0097 - val_loss: 4.2175\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9684 - val_loss: 3.5543\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0100 - val_loss: 3.6470\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9462 - val_loss: 4.0837\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9429 - val_loss: 3.5690\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1385 - val_loss: 3.4856\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0730 - val_loss: 3.9086\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0798 - val_loss: 4.5498\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9384 - val_loss: 3.4714\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9476 - val_loss: 3.4779\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9095 - val_loss: 3.3950\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8140 - val_loss: 3.8056\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7716 - val_loss: 3.3798\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8664 - val_loss: 3.8400\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0769 - val_loss: 3.3250\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7543 - val_loss: 4.4073\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8227 - val_loss: 4.7773\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7918 - val_loss: 3.3117\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6663 - val_loss: 5.1086\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9855 - val_loss: 4.0685\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9003 - val_loss: 4.5898\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8946 - val_loss: 4.0138\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7027 - val_loss: 3.2969\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6809 - val_loss: 3.2491\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1125 - val_loss: 3.2319\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7314 - val_loss: 3.9147\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5702 - val_loss: 3.8655\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9241 - val_loss: 3.2212\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5575 - val_loss: 3.2448\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5810 - val_loss: 3.1614\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4939 - val_loss: 4.1188\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7313 - val_loss: 4.6599\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5974 - val_loss: 3.2636\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5737 - val_loss: 3.0629\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7452 - val_loss: 3.5593\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6134 - val_loss: 3.1231\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4378 - val_loss: 3.0982\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4505 - val_loss: 3.8370\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3612 - val_loss: 4.0849\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4952 - val_loss: 4.5400\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34CB30EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.20150003061361188\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.5079 - val_loss: 5.9833\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3658 - val_loss: 4.2184\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0796 - val_loss: 4.0758\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8402 - val_loss: 4.5140\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6567 - val_loss: 3.8932\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.4667 - val_loss: 3.8804\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3718 - val_loss: 3.7525\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2763 - val_loss: 3.9872\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3869 - val_loss: 3.8303\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1646 - val_loss: 4.0471\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1469 - val_loss: 3.5932\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0844 - val_loss: 3.5047\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4331 - val_loss: 5.3632\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1723 - val_loss: 3.7667\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8048 - val_loss: 3.4856\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9858 - val_loss: 3.4371\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9193 - val_loss: 3.4091\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2688 - val_loss: 3.4229\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9133 - val_loss: 3.6156\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9679 - val_loss: 3.2460\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8430 - val_loss: 3.5675\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6448 - val_loss: 3.2806\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8840 - val_loss: 4.9478\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8226 - val_loss: 3.2820\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8290 - val_loss: 3.2896\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7596 - val_loss: 3.3976\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6069 - val_loss: 3.8063\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0214 - val_loss: 3.1136\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8187 - val_loss: 3.6568\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0623 - val_loss: 7.7345\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8745 - val_loss: 3.0497\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6154 - val_loss: 5.5170\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6597 - val_loss: 3.3786\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6760 - val_loss: 3.9597\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5546 - val_loss: 2.9768\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4245 - val_loss: 3.1008\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5055 - val_loss: 3.1139\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7296 - val_loss: 2.9301\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5270 - val_loss: 12.6352\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8082 - val_loss: 4.0376\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4211 - val_loss: 9.9739\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7376 - val_loss: 2.9926\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4783 - val_loss: 3.1301\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4107 - val_loss: 3.4852\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1447 - val_loss: 2.9222\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8670 - val_loss: 6.2610\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4665 - val_loss: 3.0039\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3899 - val_loss: 7.1941\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2237 - val_loss: 4.4490\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3226 - val_loss: 2.7709\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35E4698B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3951410240803743\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21.9683WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.7039 - val_loss: 6.3265\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.4249 - val_loss: 4.2577\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8806 - val_loss: 4.0994\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5588 - val_loss: 3.9661\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3708 - val_loss: 3.9094\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2479 - val_loss: 3.8035\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1163 - val_loss: 4.0124\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9461 - val_loss: 3.9188\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3682 - val_loss: 3.6655\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8579 - val_loss: 3.6117\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0222 - val_loss: 3.5324\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8709 - val_loss: 3.5805\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8879 - val_loss: 4.5672\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5005 - val_loss: 3.7181\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8032 - val_loss: 3.4830\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8369 - val_loss: 3.7142\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7882 - val_loss: 3.7318\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7855 - val_loss: 3.7130\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8041 - val_loss: 6.2963\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8004 - val_loss: 3.8432\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0432 - val_loss: 3.6183\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6820 - val_loss: 3.5613\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9028 - val_loss: 3.7296\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5902 - val_loss: 3.3587\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7101 - val_loss: 3.5917\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6193 - val_loss: 3.3859\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7018 - val_loss: 3.4911\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8275 - val_loss: 3.3373\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6322 - val_loss: 3.3475\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6365 - val_loss: 3.4194\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8890 - val_loss: 4.3301\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4731 - val_loss: 6.3624\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8104 - val_loss: 4.5258\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5999 - val_loss: 3.8134\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4631 - val_loss: 3.9648\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4932 - val_loss: 6.3805\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5022 - val_loss: 3.3481\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4278 - val_loss: 3.9832\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5125 - val_loss: 3.3355\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0304 - val_loss: 3.3741\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6297 - val_loss: 3.7134\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3853 - val_loss: 3.9358\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2447 - val_loss: 4.0334\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3878 - val_loss: 3.7437\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5203 - val_loss: 3.4140\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1706 - val_loss: 3.2221\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1289 - val_loss: 3.5816\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4083 - val_loss: 3.2613\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2482 - val_loss: 3.2558\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3768 - val_loss: 7.4923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35FA98678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.07976008591583095\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.3026 - val_loss: 5.7589\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1891 - val_loss: 4.2812\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1291 - val_loss: 4.2219\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9766 - val_loss: 4.1913\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8320 - val_loss: 4.3174\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7615 - val_loss: 4.1574\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6660 - val_loss: 4.3383\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5988 - val_loss: 3.9535\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3113 - val_loss: 3.8485\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2889 - val_loss: 8.1349\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6297 - val_loss: 4.1600\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1930 - val_loss: 3.6529\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1043 - val_loss: 3.6610\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0670 - val_loss: 3.5198\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9192 - val_loss: 3.6447\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9187 - val_loss: 3.4158\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7731 - val_loss: 4.8095\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8521 - val_loss: 3.9200\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8598 - val_loss: 3.4773\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7467 - val_loss: 3.7015\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9050 - val_loss: 3.2814\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7856 - val_loss: 7.1986\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0294 - val_loss: 3.1994\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7502 - val_loss: 3.1916\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7199 - val_loss: 3.3237\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7134 - val_loss: 3.1745\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7414 - val_loss: 4.0455\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7473 - val_loss: 3.4380\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7835 - val_loss: 3.6972\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8141 - val_loss: 3.2383\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.6161 - val_loss: 3.2005\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7515 - val_loss: 3.0535\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5750 - val_loss: 3.1632\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6956 - val_loss: 3.0968\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5233 - val_loss: 7.0894\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7855 - val_loss: 3.0882\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6778 - val_loss: 3.8647\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6083 - val_loss: 6.7717\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3592 - val_loss: 2.9282\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4520 - val_loss: 3.0225\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7322 - val_loss: 2.9191\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7115 - val_loss: 3.2272\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4158 - val_loss: 4.6584\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4601 - val_loss: 2.8850\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3265 - val_loss: 4.9919\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5214 - val_loss: 5.0267\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5316 - val_loss: 2.8968\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7916 - val_loss: 2.8130\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2329 - val_loss: 2.8674\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5528 - val_loss: 2.9517\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3622F7438> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3798570531243458\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.5655 - val_loss: 5.0046\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4385 - val_loss: 4.3888\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9321 - val_loss: 4.2882\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7947 - val_loss: 4.1668\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6914 - val_loss: 4.1915\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5521 - val_loss: 4.3418\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4595 - val_loss: 4.0780\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3071 - val_loss: 5.2077\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1724 - val_loss: 4.1115\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2754 - val_loss: 4.1615\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1636 - val_loss: 4.7925\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3394 - val_loss: 3.9801\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1276 - val_loss: 4.2059\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3372 - val_loss: 3.8588\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9003 - val_loss: 5.3053\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0617 - val_loss: 3.8475\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4483 - val_loss: 3.7762\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0054 - val_loss: 4.0044\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9229 - val_loss: 3.8102\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8148 - val_loss: 3.7503\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9698 - val_loss: 4.0981\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0368 - val_loss: 4.8048\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1812 - val_loss: 3.6923\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8026 - val_loss: 4.1431\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0454 - val_loss: 3.6193\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8280 - val_loss: 4.9953\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2714 - val_loss: 3.9406\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7104 - val_loss: 4.2562\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0462 - val_loss: 3.4963\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7263 - val_loss: 3.5115\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5904 - val_loss: 5.4403\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0598 - val_loss: 3.4873\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6598 - val_loss: 3.6507\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9474 - val_loss: 4.3690\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6938 - val_loss: 3.4204\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9693 - val_loss: 3.9349\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6721 - val_loss: 5.3421\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7019 - val_loss: 6.2339\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6139 - val_loss: 3.3587\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3156 - val_loss: 3.3283\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6563 - val_loss: 3.2303\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5028 - val_loss: 3.2827\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5180 - val_loss: 3.6226\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4387 - val_loss: 3.6958\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7283 - val_loss: 9.0083\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8155 - val_loss: 3.1372\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3758 - val_loss: 3.6150\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3317 - val_loss: 3.8246\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2175 - val_loss: 3.1431\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4764 - val_loss: 3.3181\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3623209D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3153611084517244\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.9084 - val_loss: 4.1868\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0762 - val_loss: 4.2499\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0448 - val_loss: 4.0424\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7105 - val_loss: 4.7367\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5545 - val_loss: 3.7714\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.4272 - val_loss: 4.4122\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.574 - 0s 3ms/step - loss: 4.1506 - val_loss: 10.1449\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9669 - val_loss: 3.7472\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2345 - val_loss: 3.5984\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1707 - val_loss: 3.7087\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9596 - val_loss: 3.9836\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2044 - val_loss: 3.5354\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8709 - val_loss: 5.2112\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1531 - val_loss: 3.6200\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7610 - val_loss: 3.3531\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0272 - val_loss: 4.3702\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8763 - val_loss: 4.0360\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0932 - val_loss: 3.3927\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8742 - val_loss: 4.3804\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9481 - val_loss: 3.3285\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9879 - val_loss: 3.3332\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6576 - val_loss: 5.5441\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0863 - val_loss: 3.2337\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5598 - val_loss: 4.3126\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9563 - val_loss: 3.2342\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5882 - val_loss: 3.5470\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5617 - val_loss: 3.4874\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5108 - val_loss: 3.0995\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4722 - val_loss: 3.1511\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7629 - val_loss: 3.2705\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4149 - val_loss: 5.8299\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7080 - val_loss: 5.5787\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5654 - val_loss: 3.0702\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6001 - val_loss: 3.5638\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5368 - val_loss: 3.6122\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3180 - val_loss: 8.8124\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4055 - val_loss: 3.2579\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4280 - val_loss: 4.0120\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7493 - val_loss: 3.1539\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4720 - val_loss: 3.1086\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5325 - val_loss: 3.1439\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3541 - val_loss: 3.3754\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5977 - val_loss: 13.9372\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6488 - val_loss: 3.2748\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4032 - val_loss: 3.2440\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2815 - val_loss: 3.0125\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4936 - val_loss: 5.0289\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7548 - val_loss: 4.0398\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2486 - val_loss: 3.6777\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3880 - val_loss: 3.4817\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F362588C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.2855573608555422\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 11.2802 - val_loss: 7.5613\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0989 - val_loss: 4.8218\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2747 - val_loss: 4.0666\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8399 - val_loss: 4.5240\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7754 - val_loss: 4.0186\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6831 - val_loss: 3.9718\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6264 - val_loss: 3.9041\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5602 - val_loss: 4.6316\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5766 - val_loss: 4.0133\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4107 - val_loss: 3.9514\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3795 - val_loss: 3.7839\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3883 - val_loss: 3.6987\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2454 - val_loss: 3.7112\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3088 - val_loss: 3.5893\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1698 - val_loss: 3.8363\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5110 - val_loss: 3.7017\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1882 - val_loss: 4.9682\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1989 - val_loss: 3.7866\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1517 - val_loss: 4.2919\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1197 - val_loss: 3.5967\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1379 - val_loss: 3.6951\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1379 - val_loss: 5.3354\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.4478 - val_loss: 3.2847\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9630 - val_loss: 3.2827\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8701 - val_loss: 4.0231\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9620 - val_loss: 3.2129\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8707 - val_loss: 3.3287\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8642 - val_loss: 3.2612\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8918 - val_loss: 3.1722\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7882 - val_loss: 3.1538\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8522 - val_loss: 3.4076\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8420 - val_loss: 3.1241\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8572 - val_loss: 3.0381\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8223 - val_loss: 3.2326\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6883 - val_loss: 3.0294\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7231 - val_loss: 6.1750\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1459 - val_loss: 2.9758\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7511 - val_loss: 2.9586\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7375 - val_loss: 2.9409\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0596 - val_loss: 2.9067\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.381 - 0s 4ms/step - loss: 3.7781 - val_loss: 2.8932\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7900 - val_loss: 2.9046\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6156 - val_loss: 3.0284\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6270 - val_loss: 2.9426\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6566 - val_loss: 2.9608\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5601 - val_loss: 2.8008\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8380 - val_loss: 2.9278\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7350 - val_loss: 2.8018\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5143 - val_loss: 2.7790\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5804 - val_loss: 2.7461\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3535B7C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.39874949011875294\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.5356 - val_loss: 6.1848\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.6125 - val_loss: 4.4387\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.2069 - val_loss: 5.3319\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1274 - val_loss: 4.3078\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9303 - val_loss: 4.4790\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8216 - val_loss: 4.3077\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6038 - val_loss: 4.0288\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5431 - val_loss: 4.2634\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2885 - val_loss: 4.0022\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2845 - val_loss: 6.4878\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1905 - val_loss: 4.0617\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9909 - val_loss: 3.7406\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9349 - val_loss: 4.0621\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0989 - val_loss: 3.5324\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0544 - val_loss: 3.3995\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7021 - val_loss: 3.2184\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8761 - val_loss: 3.2833\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7074 - val_loss: 3.9927\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5667 - val_loss: 3.0929\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5778 - val_loss: 3.7772\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4909 - val_loss: 4.9397\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5251 - val_loss: 4.8962\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6759 - val_loss: 5.1188\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8988 - val_loss: 6.2999\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4596 - val_loss: 3.0780\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7986 - val_loss: 3.0454\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9796 - val_loss: 3.7380\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6741 - val_loss: 3.0724\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4459 - val_loss: 4.3638\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3218 - val_loss: 14.4385\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.0968 - val_loss: 5.0030\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4031 - val_loss: 4.0774\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3751 - val_loss: 7.3538\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7032 - val_loss: 3.3365\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4100 - val_loss: 7.2053\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0264 - val_loss: 3.5328\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2233 - val_loss: 4.5613\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2443 - val_loss: 3.8259\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1503 - val_loss: 3.4379\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9994 - val_loss: 3.2071\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2424 - val_loss: 3.2137\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2463 - val_loss: 6.7179\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1968 - val_loss: 3.0384\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1119 - val_loss: 3.4076\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0712 - val_loss: 6.2871\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8915 - val_loss: 3.0646\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1795 - val_loss: 3.1084\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1149 - val_loss: 2.9340\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1580 - val_loss: 4.1214\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4936 - val_loss: 3.2645\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F358EDFCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.2852854165378752\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.3743 - val_loss: 5.8764\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.9089 - val_loss: 3.8883\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7085 - val_loss: 3.9177\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6123 - val_loss: 3.9595\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5103 - val_loss: 3.5405\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2724 - val_loss: 3.7491\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2479 - val_loss: 3.7574\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1534 - val_loss: 3.3407\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1412 - val_loss: 3.6245\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0173 - val_loss: 3.3584\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1100 - val_loss: 3.6835\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0013 - val_loss: 3.7144\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8870 - val_loss: 3.4085\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1985 - val_loss: 3.2402\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8067 - val_loss: 3.3736\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8162 - val_loss: 3.3402\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7680 - val_loss: 3.4336\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7452 - val_loss: 5.9261\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9959 - val_loss: 3.5385\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8612 - val_loss: 3.2888\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8288 - val_loss: 4.0023\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7364 - val_loss: 3.1523\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8763 - val_loss: 3.6642\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6164 - val_loss: 3.2420\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6950 - val_loss: 3.4828\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6532 - val_loss: 3.3996\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6552 - val_loss: 5.4536\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1191 - val_loss: 3.2219\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6558 - val_loss: 3.4737\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6467 - val_loss: 3.0212\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7873 - val_loss: 3.8038\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5620 - val_loss: 3.0549\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4858 - val_loss: 5.6898\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5760 - val_loss: 4.0073\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0507 - val_loss: 2.9508\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3905 - val_loss: 4.4158\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9059 - val_loss: 3.7285\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4393 - val_loss: 3.0914\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5089 - val_loss: 2.9589\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4573 - val_loss: 2.9726\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6114 - val_loss: 3.1708\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6791 - val_loss: 2.8980\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6015 - val_loss: 2.8940\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3513 - val_loss: 3.3077\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2472 - val_loss: 2.9392\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5560 - val_loss: 3.0332\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3910 - val_loss: 3.0382\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3344 - val_loss: 5.8831\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5842 - val_loss: 3.9059\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3148 - val_loss: 2.8554\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35B8EC798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.37851977773623635\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.2015 - val_loss: 4.3432\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9557 - val_loss: 3.7851\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5355 - val_loss: 3.8405\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3843 - val_loss: 3.7480\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5018 - val_loss: 3.4478\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2232 - val_loss: 3.7170\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0559 - val_loss: 3.4415\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9158 - val_loss: 3.2562\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8755 - val_loss: 3.2875\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8034 - val_loss: 5.2045\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7324 - val_loss: 3.4978\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8439 - val_loss: 3.0784\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6876 - val_loss: 3.2919\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8938 - val_loss: 3.7202\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9123 - val_loss: 3.0303\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7702 - val_loss: 4.1199\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6815 - val_loss: 5.1705\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5909 - val_loss: 3.2082\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6555 - val_loss: 2.9750\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8581 - val_loss: 3.9510\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4668 - val_loss: 3.6128\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5798 - val_loss: 6.3141\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6976 - val_loss: 2.9017\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6593 - val_loss: 3.2387\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4525 - val_loss: 3.5242\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4723 - val_loss: 5.0923\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7260 - val_loss: 3.0688\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7735 - val_loss: 2.9720\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4683 - val_loss: 3.9812\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5533 - val_loss: 4.4040\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5881 - val_loss: 3.6342\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1618 - val_loss: 5.5423\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2643 - val_loss: 6.3309\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3558 - val_loss: 6.4970\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6318 - val_loss: 3.0037\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2345 - val_loss: 3.9094\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2322 - val_loss: 3.5679\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7806 - val_loss: 2.8464\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1529 - val_loss: 6.3116\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1892 - val_loss: 2.8788\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4072 - val_loss: 3.5056\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0108 - val_loss: 2.9504\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1438 - val_loss: 4.3229\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8061 - val_loss: 3.8327\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1919 - val_loss: 2.8961\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6962 - val_loss: 2.9658\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0851 - val_loss: 2.9916\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5185 - val_loss: 5.7032\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6163 - val_loss: 2.9066\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4375 - val_loss: 3.6855\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F349BE54C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.335264046513591\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 14.5222WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.6570 - val_loss: 4.4657\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9049 - val_loss: 4.0605\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5151 - val_loss: 4.3918\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4029 - val_loss: 3.9308\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2615 - val_loss: 4.1409\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2772 - val_loss: 3.8358\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1867 - val_loss: 4.1992\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1334 - val_loss: 4.1656\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0377 - val_loss: 4.3979\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1774 - val_loss: 4.2296\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1325 - val_loss: 3.6251\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0231 - val_loss: 3.7740\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0207 - val_loss: 5.8412\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9578 - val_loss: 3.8220\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9705 - val_loss: 3.5908\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8961 - val_loss: 3.5095\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8046 - val_loss: 3.6536\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7969 - val_loss: 3.5425\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0221 - val_loss: 3.4023\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7097 - val_loss: 3.5294\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7229 - val_loss: 3.4487\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7824 - val_loss: 3.4194\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6745 - val_loss: 3.2579\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6684 - val_loss: 3.2596\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7358 - val_loss: 3.2810\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7768 - val_loss: 5.2313\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9701 - val_loss: 3.4941\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7272 - val_loss: 4.2826\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6300 - val_loss: 3.4235\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5375 - val_loss: 3.3415\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7425 - val_loss: 3.5146\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6220 - val_loss: 3.7399\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8688 - val_loss: 3.2775\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5623 - val_loss: 3.3694\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6942 - val_loss: 4.1173\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4580 - val_loss: 3.7762\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5535 - val_loss: 3.6923\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4250 - val_loss: 3.2681\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7732 - val_loss: 5.0286\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0583 - val_loss: 3.3410\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7057 - val_loss: 3.4006\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4390 - val_loss: 2.9503\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7620 - val_loss: 3.0178\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9815 - val_loss: 4.4960\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5829 - val_loss: 5.2876\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4420 - val_loss: 3.1421\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3013 - val_loss: 4.4500\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3296 - val_loss: 3.5569\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3457 - val_loss: 3.4130\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5946 - val_loss: 3.2782\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F36255FB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.33837072602561946\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.4223 - val_loss: 4.5631\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3581 - val_loss: 4.6344\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.1358 - val_loss: 4.6779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0424 - val_loss: 4.1315\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8016 - val_loss: 4.1894\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5933 - val_loss: 3.8437\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4346 - val_loss: 4.3623\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2820 - val_loss: 4.2480\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2882 - val_loss: 3.5762\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1465 - val_loss: 3.5149\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0645 - val_loss: 3.4083\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9451 - val_loss: 3.5744\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8874 - val_loss: 3.4391\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9855 - val_loss: 3.2945\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9107 - val_loss: 3.2620\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1238 - val_loss: 3.3669\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9387 - val_loss: 4.9608\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2551 - val_loss: 3.3589\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9901 - val_loss: 3.6116\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7459 - val_loss: 4.0869\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7272 - val_loss: 4.2934\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7952 - val_loss: 3.7571\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8151 - val_loss: 3.1582\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5726 - val_loss: 3.1092\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1066 - val_loss: 2.9296\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7668 - val_loss: 3.7307\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8217 - val_loss: 3.3165\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5186 - val_loss: 11.8939\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4882 - val_loss: 4.0356\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8067 - val_loss: 3.3525\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8673 - val_loss: 3.7960\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4573 - val_loss: 3.1349\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8609 - val_loss: 2.9672\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4909 - val_loss: 3.1109\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6806 - val_loss: 3.0020\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6239 - val_loss: 3.3284\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7285 - val_loss: 5.8996\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0694 - val_loss: 3.4271\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3814 - val_loss: 2.9611\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4243 - val_loss: 3.2267\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2531 - val_loss: 9.1595\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2392 - val_loss: 3.9467\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5642 - val_loss: 4.9261\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4597 - val_loss: 2.8560\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5701 - val_loss: 3.1226\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3208 - val_loss: 2.9379\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4718 - val_loss: 3.3689\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1973 - val_loss: 3.1055\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2954 - val_loss: 2.8097\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3144 - val_loss: 3.0837\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35FA988B8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3741536500712018\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 11.3582 - val_loss: 7.2917\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.8635 - val_loss: 4.7093\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4825 - val_loss: 4.2133\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0465 - val_loss: 4.1350\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8421 - val_loss: 3.9912\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7557 - val_loss: 3.8785\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.6390 - val_loss: 3.7957\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4502 - val_loss: 3.6907\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3299 - val_loss: 3.6287\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2876 - val_loss: 3.5419\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1584 - val_loss: 3.6483\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1801 - val_loss: 3.4649\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2053 - val_loss: 3.4508\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9785 - val_loss: 3.7248\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0422 - val_loss: 3.7020\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0086 - val_loss: 3.4363\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0228 - val_loss: 3.7344\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0573 - val_loss: 3.4001\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8092 - val_loss: 4.0784\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3324 - val_loss: 3.2478\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8589 - val_loss: 3.5528\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9759 - val_loss: 4.2550\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9970 - val_loss: 3.7701\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0492 - val_loss: 3.1850\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7779 - val_loss: 3.3527\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7741 - val_loss: 3.2418\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7946 - val_loss: 3.1224\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9964 - val_loss: 3.5998\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5962 - val_loss: 3.1341\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5956 - val_loss: 3.2379\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6603 - val_loss: 3.1128\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1409 - val_loss: 3.1190\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6851 - val_loss: 3.5089\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6914 - val_loss: 3.0748\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6501 - val_loss: 3.0643\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9292 - val_loss: 4.4620\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8461 - val_loss: 3.0386\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7212 - val_loss: 3.7254\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6266 - val_loss: 3.1647\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4957 - val_loss: 3.1032\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6006 - val_loss: 3.0820\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1613 - val_loss: 3.2127\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5460 - val_loss: 3.1757\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5573 - val_loss: 4.1444\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5267 - val_loss: 3.1943\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3114 - val_loss: 3.1464\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3945 - val_loss: 3.7295\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5310 - val_loss: 3.8493\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4039 - val_loss: 3.0203\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3866 - val_loss: 3.0434\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35F899F78> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.33403275124457443\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.0778 - val_loss: 4.1963\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7404 - val_loss: 3.9147\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5442 - val_loss: 3.8442\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5121 - val_loss: 4.3799\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2967 - val_loss: 4.6864\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3088 - val_loss: 3.7685\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3053 - val_loss: 4.3366\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0604 - val_loss: 3.8523\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0255 - val_loss: 4.3212\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0322 - val_loss: 3.6897\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1592 - val_loss: 3.6499\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9103 - val_loss: 3.6484\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0784 - val_loss: 3.6320\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0204 - val_loss: 3.8529\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8776 - val_loss: 3.5599\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8353 - val_loss: 3.5686\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8819 - val_loss: 6.8528\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8735 - val_loss: 3.5942\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0151 - val_loss: 3.5419\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8015 - val_loss: 7.2955\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8554 - val_loss: 3.4826\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7570 - val_loss: 3.8954\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9701 - val_loss: 3.4584\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8464 - val_loss: 3.7271\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7435 - val_loss: 3.4077\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8973 - val_loss: 3.4449\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6669 - val_loss: 3.3869\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9366 - val_loss: 3.3127\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8023 - val_loss: 4.2323\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8058 - val_loss: 3.7680\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8117 - val_loss: 3.9227\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5617 - val_loss: 3.5233\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5153 - val_loss: 3.4686\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4663 - val_loss: 3.1408\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5755 - val_loss: 3.8510\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4045 - val_loss: 4.1974\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4861 - val_loss: 3.1307\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6094 - val_loss: 3.0558\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4993 - val_loss: 3.6523\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3567 - val_loss: 3.1528\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5441 - val_loss: 3.0836\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4319 - val_loss: 3.9527\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5689 - val_loss: 3.6123\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3340 - val_loss: 5.7702\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7873 - val_loss: 3.8754\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8699 - val_loss: 2.9875\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2613 - val_loss: 2.9792\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4300 - val_loss: 4.2085\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9601 - val_loss: 9.9043\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9559 - val_loss: 3.3583\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F356209318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.29793903387964704\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 6.6559WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.0383 - val_loss: 4.1553\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1251 - val_loss: 4.2301\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9669 - val_loss: 3.8423\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7823 - val_loss: 3.7366\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7091 - val_loss: 3.7949\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6948 - val_loss: 4.1920\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3735 - val_loss: 3.4859\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3072 - val_loss: 5.9348\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2553 - val_loss: 3.2946\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9747 - val_loss: 4.4457\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0037 - val_loss: 3.5454\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9078 - val_loss: 3.2849\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9742 - val_loss: 3.2030\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8514 - val_loss: 3.1593\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8585 - val_loss: 6.1315\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0873 - val_loss: 4.1346\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7322 - val_loss: 3.2322\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6903 - val_loss: 3.1527\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6818 - val_loss: 4.1573\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5756 - val_loss: 3.0914\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5775 - val_loss: 3.4376\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5747 - val_loss: 3.0618\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8834 - val_loss: 4.8102\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7297 - val_loss: 2.9985\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6898 - val_loss: 2.9795\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5524 - val_loss: 3.0805\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0887 - val_loss: 2.9343\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7205 - val_loss: 3.0010\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5437 - val_loss: 3.4232\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5172 - val_loss: 3.2224\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7717 - val_loss: 3.5159\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5217 - val_loss: 2.9158\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5872 - val_loss: 10.0473\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9962 - val_loss: 2.9337\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5367 - val_loss: 3.1184\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3399 - val_loss: 4.0536\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4489 - val_loss: 4.9650\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3226 - val_loss: 3.3304\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2686 - val_loss: 3.5309\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3596 - val_loss: 2.8849\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2857 - val_loss: 3.0936\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4890 - val_loss: 3.0968\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2796 - val_loss: 6.5143\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7400 - val_loss: 2.8993\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2423 - val_loss: 11.3905\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1834 - val_loss: 3.3813\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2768 - val_loss: 3.2128\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4667 - val_loss: 2.8634\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7547 - val_loss: 2.7581\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4712 - val_loss: 6.3231\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F358C7E4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.18214844743506142\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.4543 - val_loss: 3.7914\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5575 - val_loss: 4.3134\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5049 - val_loss: 3.6444\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4467 - val_loss: 3.8271\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3297 - val_loss: 4.5081\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1875 - val_loss: 3.7329\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0485 - val_loss: 3.6577\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0484 - val_loss: 5.1159\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0800 - val_loss: 3.7985\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0773 - val_loss: 3.5309\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0288 - val_loss: 3.7352\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0061 - val_loss: 3.5322\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9124 - val_loss: 3.9390\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9303 - val_loss: 3.8299\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0147 - val_loss: 6.6871\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8461 - val_loss: 5.4906\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1640 - val_loss: 4.0008\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7843 - val_loss: 3.6602\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8203 - val_loss: 3.4157\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1979 - val_loss: 4.1596\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8386 - val_loss: 4.0816\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6501 - val_loss: 4.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8837 - val_loss: 3.3844\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8198 - val_loss: 8.7710\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7351 - val_loss: 3.4757\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6889 - val_loss: 3.3290\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1368 - val_loss: 3.3105\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6286 - val_loss: 3.5895\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6592 - val_loss: 3.2970\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6629 - val_loss: 3.3610\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7215 - val_loss: 3.5451\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5418 - val_loss: 3.3978\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6995 - val_loss: 3.3054\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5032 - val_loss: 4.9733\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9742 - val_loss: 3.1654\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5073 - val_loss: 6.8764\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9736 - val_loss: 3.2664\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5666 - val_loss: 4.1358\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8805 - val_loss: 3.0712\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4111 - val_loss: 4.9359\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7211 - val_loss: 3.9497\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3863 - val_loss: 3.8260\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5024 - val_loss: 3.1315\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3556 - val_loss: 3.1310\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4484 - val_loss: 3.0536\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6894 - val_loss: 3.6144\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5208 - val_loss: 3.0219\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3436 - val_loss: 10.5105\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2397 - val_loss: 3.0089\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7180 - val_loss: 3.1456\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35D16B168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.336235518950325\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.7771 - val_loss: 4.2624\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0113 - val_loss: 3.9243\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5133 - val_loss: 3.5095\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2997 - val_loss: 3.7528\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3053 - val_loss: 3.6747\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0288 - val_loss: 3.4237\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.9833 - val_loss: 3.4363\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8657 - val_loss: 3.4271\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8142 - val_loss: 3.5460\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8216 - val_loss: 3.2432\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1024 - val_loss: 3.4953\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9164 - val_loss: 3.3225\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7226 - val_loss: 3.3577\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6831 - val_loss: 3.3563\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7917 - val_loss: 3.3737\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7344 - val_loss: 3.6331\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2494 - val_loss: 3.2940\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6587 - val_loss: 3.7138\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7431 - val_loss: 3.4584\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7122 - val_loss: 3.4341\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5203 - val_loss: 3.6068\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8997 - val_loss: 3.3771\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5112 - val_loss: 3.3246\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9303 - val_loss: 5.0725\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6810 - val_loss: 4.3338\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8557 - val_loss: 3.0860\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3083 - val_loss: 3.0955\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5899 - val_loss: 4.8410\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9255 - val_loss: 5.4237\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7311 - val_loss: 4.2081\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7327 - val_loss: 4.9427\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8303 - val_loss: 3.3747\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4739 - val_loss: 2.9687\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2202 - val_loss: 5.4593\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4395 - val_loss: 3.0394\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1946 - val_loss: 3.1029\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0807 - val_loss: 6.6619\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5367 - val_loss: 5.1407\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3669 - val_loss: 3.0230\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1561 - val_loss: 4.3869\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1253 - val_loss: 2.7751\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5026 - val_loss: 3.0898\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9847 - val_loss: 2.9915\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1239 - val_loss: 3.3566\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2136 - val_loss: 3.8442\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2895 - val_loss: 5.1507\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0082 - val_loss: 3.3015\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5530 - val_loss: 2.9018\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0389 - val_loss: 5.9698\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9573 - val_loss: 2.9891\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35239CCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.34740948734038846\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.0223 - val_loss: 4.3742\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9687 - val_loss: 4.1773\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8110 - val_loss: 3.9629\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5349 - val_loss: 3.8813\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3627 - val_loss: 3.9119\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3068 - val_loss: 3.6768\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3354 - val_loss: 3.5800\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2275 - val_loss: 3.5409\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1964 - val_loss: 3.5370\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9887 - val_loss: 3.8518\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0531 - val_loss: 6.6503\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7859 - val_loss: 3.2519\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8896 - val_loss: 3.4900\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7805 - val_loss: 3.2592\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8772 - val_loss: 3.3567\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7540 - val_loss: 3.0893\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1508 - val_loss: 3.1603\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9693 - val_loss: 3.0874\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7267 - val_loss: 3.2465\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8471 - val_loss: 3.0475\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5916 - val_loss: 2.9582\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8170 - val_loss: 4.1572\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8701 - val_loss: 2.9604\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5962 - val_loss: 2.9735\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6989 - val_loss: 2.9139\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7247 - val_loss: 7.9393\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4709 - val_loss: 2.9449\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5840 - val_loss: 2.8853\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4194 - val_loss: 2.9963\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6543 - val_loss: 3.5447\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6493 - val_loss: 3.4591\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8130 - val_loss: 3.6067\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4907 - val_loss: 2.8408\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4386 - val_loss: 2.9266\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1608 - val_loss: 2.8923\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3616 - val_loss: 2.8202\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3648 - val_loss: 4.0376\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5821 - val_loss: 8.1425\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.8189 - val_loss: 3.3352\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2107 - val_loss: 2.8510\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3323 - val_loss: 4.1061\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4454 - val_loss: 3.4482\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2725 - val_loss: 2.8585\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4496 - val_loss: 4.4170\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3871 - val_loss: 3.9674\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2222 - val_loss: 7.1638\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0455 - val_loss: 2.8194\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3220 - val_loss: 2.7485\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2675 - val_loss: 4.3559\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1979 - val_loss: 4.2000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35A16C828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.29086591137411477\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.8462 - val_loss: 6.7112\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.2228 - val_loss: 4.2545\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0822 - val_loss: 3.9970\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7145 - val_loss: 3.8424\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5680 - val_loss: 3.9765\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3366 - val_loss: 3.5218\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1764 - val_loss: 3.3684\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1688 - val_loss: 3.5199\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9879 - val_loss: 3.3102\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9464 - val_loss: 3.2223\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9542 - val_loss: 3.1507\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1545 - val_loss: 3.1499\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7898 - val_loss: 3.7330\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7874 - val_loss: 9.2177\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0578 - val_loss: 3.3016\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6711 - val_loss: 3.4725\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8467 - val_loss: 3.3176\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9904 - val_loss: 4.2644\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6565 - val_loss: 5.9608\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9381 - val_loss: 2.9653\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6121 - val_loss: 3.4311\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5630 - val_loss: 3.8932\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7838 - val_loss: 3.5595\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5608 - val_loss: 3.2707\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8082 - val_loss: 5.8379\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9396 - val_loss: 3.3073\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5733 - val_loss: 2.8698\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5426 - val_loss: 2.8743\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6404 - val_loss: 3.5891\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4639 - val_loss: 2.9704\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4358 - val_loss: 3.1915\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5103 - val_loss: 2.9294\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4361 - val_loss: 3.3146\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3591 - val_loss: 3.2488\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4682 - val_loss: 2.7826\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3366 - val_loss: 3.5025\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5599 - val_loss: 2.8563\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6500 - val_loss: 2.9456\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2878 - val_loss: 3.0822\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4203 - val_loss: 5.7575\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8782 - val_loss: 3.4652\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4380 - val_loss: 2.7554\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9233 - val_loss: 3.8787\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6788 - val_loss: 2.8111\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7731 - val_loss: 2.7520\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4363 - val_loss: 2.9113\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6697 - val_loss: 3.3985\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3689 - val_loss: 3.8358\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5716 - val_loss: 2.7849\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5983 - val_loss: 5.5719\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34B0AB9D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.2393018001605013\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.1992 - val_loss: 4.2953\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8917 - val_loss: 4.1646\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9196 - val_loss: 4.7329\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4978 - val_loss: 4.2743\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3651 - val_loss: 4.3154\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1571 - val_loss: 4.1616\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0463 - val_loss: 3.8588\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0332 - val_loss: 3.6606\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9441 - val_loss: 3.8882\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9471 - val_loss: 5.2410\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3909 - val_loss: 3.6496\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0987 - val_loss: 3.6037\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7888 - val_loss: 3.5114\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8226 - val_loss: 3.5553\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6225 - val_loss: 3.4974\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5919 - val_loss: 3.6229\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5949 - val_loss: 3.7311\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8659 - val_loss: 3.7048\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6118 - val_loss: 6.8702\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7624 - val_loss: 3.3358\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6080 - val_loss: 4.2824\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4519 - val_loss: 3.3346\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3274 - val_loss: 3.1650\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6558 - val_loss: 3.0540\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4770 - val_loss: 3.1413\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1212 - val_loss: 3.2210\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5904 - val_loss: 3.2831\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4795 - val_loss: 9.5959\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6352 - val_loss: 3.5501\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2064 - val_loss: 3.0530\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2991 - val_loss: 3.1060\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5827 - val_loss: 3.3377\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2858 - val_loss: 3.2623\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9416 - val_loss: 3.3363\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5202 - val_loss: 3.2512\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6703 - val_loss: 2.9782\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2270 - val_loss: 7.1685\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1373 - val_loss: 3.7160\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9991 - val_loss: 3.4616\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7840 - val_loss: 5.5052\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8872 - val_loss: 3.7793\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5045 - val_loss: 2.7930\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8770 - val_loss: 4.5842\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0470 - val_loss: 7.7370\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1996 - val_loss: 4.7668\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1162 - val_loss: 3.1156\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9159 - val_loss: 4.7849\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5363 - val_loss: 7.1517\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7091 - val_loss: 3.2804\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9934 - val_loss: 3.1027\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3509EB828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3245684670727397\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.3557 - val_loss: 4.3976\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1444 - val_loss: 3.9115\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6492 - val_loss: 4.4273\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4646 - val_loss: 3.6400\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3110 - val_loss: 4.4311\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1905 - val_loss: 3.6885\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3824 - val_loss: 3.6579\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0337 - val_loss: 3.5406\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8388 - val_loss: 3.3663\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8919 - val_loss: 4.4141\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8860 - val_loss: 3.8784\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2298 - val_loss: 5.4545\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9330 - val_loss: 3.5547\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7075 - val_loss: 3.2098\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6762 - val_loss: 3.2999\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7612 - val_loss: 3.7909\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7681 - val_loss: 3.1836\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6395 - val_loss: 3.2229\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7294 - val_loss: 4.3504\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9143 - val_loss: 3.3541\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0424 - val_loss: 3.4033\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5541 - val_loss: 3.6802\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6072 - val_loss: 3.2974\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7792 - val_loss: 3.8871\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5236 - val_loss: 4.0399\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0306 - val_loss: 3.3333\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7197 - val_loss: 3.3765\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6905 - val_loss: 3.1189\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4608 - val_loss: 2.9278\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7256 - val_loss: 2.9464\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5045 - val_loss: 6.6083\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6392 - val_loss: 3.0551\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7266 - val_loss: 7.1983\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3425 - val_loss: 2.9291\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6086 - val_loss: 3.0631\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4306 - val_loss: 5.3569\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5203 - val_loss: 3.5745\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6681 - val_loss: 4.0030\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2418 - val_loss: 3.2160\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2924 - val_loss: 3.9365\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3255 - val_loss: 2.9194\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4409 - val_loss: 2.9806\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2501 - val_loss: 3.1172\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2326 - val_loss: 3.0522\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5188 - val_loss: 9.4646\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8476 - val_loss: 3.7591\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4021 - val_loss: 3.5346\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4579 - val_loss: 3.1607\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1280 - val_loss: 2.7385\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2378 - val_loss: 3.1948\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34C6F8CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3784971979586289\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.1535 - val_loss: 5.3196\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3958 - val_loss: 4.4464\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7292 - val_loss: 4.6814\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8578 - val_loss: 4.1581\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4260 - val_loss: 5.2273\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7662 - val_loss: 3.9816\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3848 - val_loss: 4.7899\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2533 - val_loss: 5.6423\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2927 - val_loss: 3.9207\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1765 - val_loss: 4.2988\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2373 - val_loss: 3.8111\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0653 - val_loss: 4.1620\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5008 - val_loss: 4.0916\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0777 - val_loss: 4.2060\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2042 - val_loss: 3.7392\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0951 - val_loss: 3.6573\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9265 - val_loss: 4.5992\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9512 - val_loss: 3.7046\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7915 - val_loss: 4.0504\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8358 - val_loss: 3.6568\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9182 - val_loss: 4.2289\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9080 - val_loss: 4.0038\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0256 - val_loss: 3.6646\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7014 - val_loss: 4.1639\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7514 - val_loss: 3.5589\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7028 - val_loss: 3.3620\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5349 - val_loss: 5.1768\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7654 - val_loss: 3.3287\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5624 - val_loss: 3.5003\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7720 - val_loss: 3.5298\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7127 - val_loss: 3.2184\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6059 - val_loss: 3.1982\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7853 - val_loss: 5.0247\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6081 - val_loss: 3.3978\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5638 - val_loss: 3.1717\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8294 - val_loss: 3.4369\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7851 - val_loss: 3.4450\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5416 - val_loss: 3.8744\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6371 - val_loss: 3.8323\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7686 - val_loss: 4.2817\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5435 - val_loss: 3.3667\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3237 - val_loss: 3.0767\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6185 - val_loss: 3.0862\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2892 - val_loss: 3.1567\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3649 - val_loss: 3.1207\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8491 - val_loss: 4.3005\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5011 - val_loss: 4.2490\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8685 - val_loss: 3.2769\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3516 - val_loss: 5.6173\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9081 - val_loss: 3.7750\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3521FD5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.29016531406017754\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.9846 - val_loss: 4.0556\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2626 - val_loss: 4.1609\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8220 - val_loss: 4.0814\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5399 - val_loss: 3.7104\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3219 - val_loss: 3.7493\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1075 - val_loss: 5.6095\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3188 - val_loss: 3.7471\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9745 - val_loss: 3.9658\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0254 - val_loss: 4.2597\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2259 - val_loss: 3.9043\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8225 - val_loss: 4.1705\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7163 - val_loss: 3.6059\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7422 - val_loss: 3.5207\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7341 - val_loss: 3.5672\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6545 - val_loss: 3.5373\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9559 - val_loss: 3.5223\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6308 - val_loss: 4.7521\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6241 - val_loss: 5.0146\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7627 - val_loss: 3.4770\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5544 - val_loss: 4.0338\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5740 - val_loss: 3.7906\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5675 - val_loss: 3.8399\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4209 - val_loss: 3.9821\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4303 - val_loss: 3.8010\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6972 - val_loss: 4.2240\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3066 - val_loss: 3.9563\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4059 - val_loss: 7.7472\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7125 - val_loss: 5.0103\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3667 - val_loss: 3.5174\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4619 - val_loss: 8.9447\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7204 - val_loss: 4.1395\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3874 - val_loss: 3.3172\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4867 - val_loss: 3.6734\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2428 - val_loss: 7.3727\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5599 - val_loss: 3.5121\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1817 - val_loss: 3.3433\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1626 - val_loss: 6.2256\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8507 - val_loss: 3.3074\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1512 - val_loss: 3.2201\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5053 - val_loss: 4.0837\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1904 - val_loss: 6.8142\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3227 - val_loss: 3.4128\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1566 - val_loss: 3.9365\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5053 - val_loss: 3.1971\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3470 - val_loss: 3.2194\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0625 - val_loss: 6.2968\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5356 - val_loss: 4.8373\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3466 - val_loss: 3.5424\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2094 - val_loss: 3.2842\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0307 - val_loss: 3.2743\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35A0D9558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3244940575473124\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 8.0834 - val_loss: 3.7379\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4555 - val_loss: 3.9467\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3134 - val_loss: 4.4871\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0794 - val_loss: 3.6373\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0831 - val_loss: 3.4404\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0723 - val_loss: 3.5362\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3177 - val_loss: 3.5917\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9429 - val_loss: 3.5561\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9090 - val_loss: 3.3141\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7971 - val_loss: 3.2365\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8784 - val_loss: 3.3919\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1764 - val_loss: 3.2682\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6418 - val_loss: 3.1826\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8265 - val_loss: 3.3832\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0179 - val_loss: 3.1653\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8340 - val_loss: 3.4504\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9678 - val_loss: 3.5974\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6076 - val_loss: 3.0496\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7071 - val_loss: 3.8883\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9127 - val_loss: 3.5946\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6514 - val_loss: 3.0572\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6122 - val_loss: 2.9768\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5006 - val_loss: 3.0985\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8214 - val_loss: 2.9906\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6258 - val_loss: 3.4130\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4764 - val_loss: 4.3075\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4183 - val_loss: 2.9630\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5628 - val_loss: 4.7525\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4372 - val_loss: 2.8985\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6161 - val_loss: 2.8110\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6482 - val_loss: 2.8662\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5446 - val_loss: 2.8356\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3171 - val_loss: 3.1366\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2992 - val_loss: 3.0215\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5120 - val_loss: 3.2085\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3222 - val_loss: 3.0626\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4800 - val_loss: 3.0640\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7026 - val_loss: 2.7478\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4423 - val_loss: 7.8828\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0258 - val_loss: 2.8668\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2329 - val_loss: 3.1023\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2863 - val_loss: 2.8062\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5263 - val_loss: 2.8697\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4915 - val_loss: 3.4080\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1736 - val_loss: 2.7550\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5605 - val_loss: 3.3312\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2372 - val_loss: 3.9625\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5474 - val_loss: 2.7418\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7035 - val_loss: 2.8930\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9017 - val_loss: 2.7874\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F34C2DCAF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3897242625530074\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.4409 - val_loss: 4.7906\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4785 - val_loss: 4.7868\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9802 - val_loss: 4.5161\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8110 - val_loss: 4.7906\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6893 - val_loss: 4.1876\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5032 - val_loss: 4.9184\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.4649 - val_loss: 4.8836\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2903 - val_loss: 4.1308\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2467 - val_loss: 3.9512\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2333 - val_loss: 3.8869\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1716 - val_loss: 3.8159\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0439 - val_loss: 3.7453\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2332 - val_loss: 3.7745\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0058 - val_loss: 3.6969\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1176 - val_loss: 5.9848\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2023 - val_loss: 4.0851\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8985 - val_loss: 3.5973\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0079 - val_loss: 3.5572\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1419 - val_loss: 3.5848\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0158 - val_loss: 3.5279\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8035 - val_loss: 7.3736\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4942 - val_loss: 3.8797\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7917 - val_loss: 3.3847\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7259 - val_loss: 3.7392\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7380 - val_loss: 3.4566\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0139 - val_loss: 3.5171\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8383 - val_loss: 3.6073\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7736 - val_loss: 3.4855\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8377 - val_loss: 3.5971\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6490 - val_loss: 3.4814\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6544 - val_loss: 3.2801\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7065 - val_loss: 3.5531\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9664 - val_loss: 3.3006\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7973 - val_loss: 3.2732\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5693 - val_loss: 3.2596\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6105 - val_loss: 4.0331\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5846 - val_loss: 3.4877\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9165 - val_loss: 3.2432\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6140 - val_loss: 3.1469\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9427 - val_loss: 3.1996\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4989 - val_loss: 3.1118\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3637 - val_loss: 4.9638\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6858 - val_loss: 3.7726\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8389 - val_loss: 3.1884\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5007 - val_loss: 5.9143\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2623 - val_loss: 3.3361\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4318 - val_loss: 5.1006\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4949 - val_loss: 4.6378\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5969 - val_loss: 3.0555\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7450 - val_loss: 2.9845\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35CA10318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3467471390786019\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.2181 - val_loss: 4.9312\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5007 - val_loss: 3.8648\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7922 - val_loss: 4.4121\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6486 - val_loss: 3.6932\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4671 - val_loss: 3.5926\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.3494 - val_loss: 3.7466\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3044 - val_loss: 4.2144\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3588 - val_loss: 3.4299\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4860 - val_loss: 3.4584\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0722 - val_loss: 3.8410\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9597 - val_loss: 4.9004\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9476 - val_loss: 3.5886\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8804 - val_loss: 5.4882\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5906 - val_loss: 3.5167\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7890 - val_loss: 3.5126\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7088 - val_loss: 3.3063\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8120 - val_loss: 3.2118\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7776 - val_loss: 3.2183\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8639 - val_loss: 3.5291\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6871 - val_loss: 3.9897\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8863 - val_loss: 3.1336\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8021 - val_loss: 3.7904\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6661 - val_loss: 3.1385\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9783 - val_loss: 3.3046\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6046 - val_loss: 3.0964\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6062 - val_loss: 3.0055\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5954 - val_loss: 3.2685\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3932 - val_loss: 3.1827\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5060 - val_loss: 4.3840\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8851 - val_loss: 3.1022\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6053 - val_loss: 2.8593\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2928 - val_loss: 3.1802\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2954 - val_loss: 2.9915\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9663 - val_loss: 2.9029\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.616 - 0s 3ms/step - loss: 3.6074 - val_loss: 2.8802\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4971 - val_loss: 3.4235\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2246 - val_loss: 3.3379\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3603 - val_loss: 3.0161\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1930 - val_loss: 2.8891\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2417 - val_loss: 2.9533\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3128 - val_loss: 3.0531\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0539 - val_loss: 3.4102\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0444 - val_loss: 4.3107\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9578 - val_loss: 11.6965\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0264 - val_loss: 4.0284\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2664 - val_loss: 2.7313\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3373 - val_loss: 4.5027\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1145 - val_loss: 3.5056\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9455 - val_loss: 2.6210\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4700 - val_loss: 3.1772\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35CCC8CA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.39200695673122143\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 13.0841WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 9.6864 - val_loss: 4.6419\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2000 - val_loss: 4.7611\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8542 - val_loss: 4.0007\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8273 - val_loss: 4.7235\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6157 - val_loss: 4.1827\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5664 - val_loss: 3.8897\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5446 - val_loss: 3.9329\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3819 - val_loss: 3.9520\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3664 - val_loss: 4.4521\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2434 - val_loss: 3.7103\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3915 - val_loss: 3.6488\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0950 - val_loss: 4.6553\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1371 - val_loss: 3.5577\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0947 - val_loss: 3.9477\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9464 - val_loss: 4.9633\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1723 - val_loss: 3.8907\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9006 - val_loss: 4.1700\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8153 - val_loss: 3.4020\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8328 - val_loss: 3.4703\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1185 - val_loss: 3.8892\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7232 - val_loss: 3.3202\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8340 - val_loss: 4.9123\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7759 - val_loss: 3.5181\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7522 - val_loss: 3.2574\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8106 - val_loss: 3.2201\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7266 - val_loss: 3.3545\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0238 - val_loss: 3.0953\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7792 - val_loss: 3.1787\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8326 - val_loss: 3.5544\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6563 - val_loss: 3.9917\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5013 - val_loss: 4.1205\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5435 - val_loss: 7.2892\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5951 - val_loss: 6.1567\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9149 - val_loss: 3.4799\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4407 - val_loss: 6.0121\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4006 - val_loss: 3.2876\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3799 - val_loss: 5.0084\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9233 - val_loss: 2.9185\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2048 - val_loss: 3.2618\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3442 - val_loss: 13.1865\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1862 - val_loss: 5.5000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4418 - val_loss: 4.7401\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0131 - val_loss: 3.5337\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3320 - val_loss: 3.3517\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1051 - val_loss: 2.8289\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4814 - val_loss: 4.5229\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1283 - val_loss: 3.2113\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5169 - val_loss: 3.0812\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5841 - val_loss: 4.1935\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0833 - val_loss: 12.6428\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F344B13678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: -0.1932410429913094\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 7.3090 - val_loss: 4.4391\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8157 - val_loss: 4.3540\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7031 - val_loss: 5.9837\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5417 - val_loss: 4.1988\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.4193 - val_loss: 4.5176\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2199 - val_loss: 4.2620\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2552 - val_loss: 4.0676\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1269 - val_loss: 4.7652\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3198 - val_loss: 5.4536\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0933 - val_loss: 3.8645\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9579 - val_loss: 4.5057\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9013 - val_loss: 3.7933\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9857 - val_loss: 4.3130\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3246 - val_loss: 4.5188\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8056 - val_loss: 3.9192\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7828 - val_loss: 3.6265\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9095 - val_loss: 4.0833\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0856 - val_loss: 3.5668\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8511 - val_loss: 3.7259\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9295 - val_loss: 3.7062\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9249 - val_loss: 3.7760\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7273 - val_loss: 4.3366\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1124 - val_loss: 3.4561\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7130 - val_loss: 3.4865\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6549 - val_loss: 3.4508\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8234 - val_loss: 3.6519\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9874 - val_loss: 3.4169\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0008 - val_loss: 3.4263\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5732 - val_loss: 4.7598\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7846 - val_loss: 9.5769\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8886 - val_loss: 4.6059\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5749 - val_loss: 4.1593\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8769 - val_loss: 3.2693\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8097 - val_loss: 10.1747\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.5125 - val_loss: 3.3838\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6566 - val_loss: 3.8043\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5316 - val_loss: 3.2301\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5690 - val_loss: 3.1980\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4300 - val_loss: 3.4589\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8857 - val_loss: 3.3335\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6414 - val_loss: 3.7586\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3738 - val_loss: 5.3908\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7249 - val_loss: 3.1130\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5706 - val_loss: 3.2782\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3237 - val_loss: 3.3932\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3347 - val_loss: 4.9311\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2527 - val_loss: 3.5683\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7274 - val_loss: 7.0315\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5477 - val_loss: 4.4388\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3453 - val_loss: 3.4866\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F33907D1F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.30196374552008887\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.5460 - val_loss: 5.7036\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.4973 - val_loss: 4.4124\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5605 - val_loss: 4.7292\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4148 - val_loss: 4.0564\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4123 - val_loss: 3.8930\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4591 - val_loss: 4.1648\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1523 - val_loss: 4.4181\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1857 - val_loss: 4.0998\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0358 - val_loss: 3.6662\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0213 - val_loss: 3.5790\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1699 - val_loss: 3.5311\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0758 - val_loss: 9.1427\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9734 - val_loss: 4.0860\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8658 - val_loss: 4.1462\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8807 - val_loss: 3.3788\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6858 - val_loss: 6.4103\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0439 - val_loss: 8.8626\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5169 - val_loss: 4.2928\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9134 - val_loss: 3.3302\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.0493 - val_loss: 3.3760\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6975 - val_loss: 6.0948\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7623 - val_loss: 5.2034\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6622 - val_loss: 3.2520\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.7339 - val_loss: 3.2179\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6489 - val_loss: 4.0689\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9246 - val_loss: 4.4830\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8946 - val_loss: 3.5416\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0973 - val_loss: 6.1799\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8524 - val_loss: 3.1588\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5047 - val_loss: 4.4440\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5656 - val_loss: 3.1766\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6204 - val_loss: 3.3950\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6657 - val_loss: 3.2789\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5540 - val_loss: 5.8688\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8750 - val_loss: 3.1571\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4072 - val_loss: 4.6875\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4844 - val_loss: 3.2500\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3693 - val_loss: 3.0967\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2737 - val_loss: 3.3762\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1691 - val_loss: 6.0467\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6022 - val_loss: 4.5502\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2134 - val_loss: 4.1485\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6674 - val_loss: 2.9564\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5613 - val_loss: 3.3547\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2997 - val_loss: 3.4214\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6412 - val_loss: 2.9582\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6008 - val_loss: 2.9713\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1809 - val_loss: 3.1814\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1304 - val_loss: 3.6767\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1386 - val_loss: 4.8365\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F350C07318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.18589578512318772\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.7007 - val_loss: 4.7585\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0691 - val_loss: 4.4004\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6495 - val_loss: 3.9493\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5263 - val_loss: 4.1451\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5117 - val_loss: 4.0625\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4168 - val_loss: 3.9230\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2359 - val_loss: 4.0651\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2407 - val_loss: 3.9206\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2126 - val_loss: 3.7056\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3486 - val_loss: 3.8379\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1113 - val_loss: 3.9413\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0374 - val_loss: 3.9980\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.9315 - val_loss: 3.6511\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9338 - val_loss: 4.0797\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0093 - val_loss: 3.8973\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8253 - val_loss: 3.6902\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9270 - val_loss: 3.5048\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8101 - val_loss: 4.1414\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8076 - val_loss: 3.7767\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7576 - val_loss: 4.0331\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7486 - val_loss: 3.3342\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8625 - val_loss: 3.3839\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7229 - val_loss: 3.4186\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6899 - val_loss: 3.8967\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8048 - val_loss: 3.9034\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7409 - val_loss: 3.4059\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8914 - val_loss: 3.3414\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6247 - val_loss: 3.2863\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5701 - val_loss: 3.5987\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6254 - val_loss: 3.3673\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7652 - val_loss: 3.2759\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7188 - val_loss: 4.4303\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7877 - val_loss: 3.2234\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7358 - val_loss: 3.3699\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5331 - val_loss: 3.7642\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5830 - val_loss: 3.1551\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4560 - val_loss: 3.5767\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5548 - val_loss: 4.2531\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4960 - val_loss: 3.8933\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6695 - val_loss: 3.3041\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8595 - val_loss: 3.1436\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6258 - val_loss: 3.0758\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3927 - val_loss: 3.6935\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5662 - val_loss: 3.7258\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4618 - val_loss: 3.2292\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6522 - val_loss: 4.8849\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0084 - val_loss: 3.4764\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4256 - val_loss: 3.1056\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4972 - val_loss: 4.3366\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4386 - val_loss: 3.0425\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F352126DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.33396980307226365\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.6492 - val_loss: 6.1960\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.4279 - val_loss: 4.1059\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8892 - val_loss: 4.1543\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8325 - val_loss: 3.9446\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6400 - val_loss: 3.8162\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3658 - val_loss: 3.6015\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3580 - val_loss: 3.8786\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1599 - val_loss: 3.5599\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0454 - val_loss: 3.4217\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0624 - val_loss: 3.3154\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0180 - val_loss: 3.3399\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8137 - val_loss: 3.1571\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7002 - val_loss: 3.5630\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0831 - val_loss: 3.2624\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8500 - val_loss: 3.1615\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7736 - val_loss: 3.3304\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9449 - val_loss: 3.3253\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8873 - val_loss: 3.0178\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7273 - val_loss: 4.7360\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.2119 - val_loss: 3.0796\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7304 - val_loss: 3.2206\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6530 - val_loss: 3.2755\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6025 - val_loss: 4.0751\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6394 - val_loss: 2.9867\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1384 - val_loss: 2.9521\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6615 - val_loss: 2.8802\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6589 - val_loss: 2.9466\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4448 - val_loss: 2.7773\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6144 - val_loss: 2.8531\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6951 - val_loss: 3.7455\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5774 - val_loss: 3.7676\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5255 - val_loss: 3.4372\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5668 - val_loss: 2.9120\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4389 - val_loss: 4.3486\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6758 - val_loss: 3.0096\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4558 - val_loss: 2.9252\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3044 - val_loss: 3.8645\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6564 - val_loss: 2.9604\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.9422 - val_loss: 2.9703\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6878 - val_loss: 2.7981\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4516 - val_loss: 3.4081\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3200 - val_loss: 2.8484\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3307 - val_loss: 3.7782\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1199 - val_loss: 2.8902\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1608 - val_loss: 2.8763\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4966 - val_loss: 2.8228\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0862 - val_loss: 6.3105\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5854 - val_loss: 3.2179\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3406 - val_loss: 3.1147\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4989 - val_loss: 2.6851\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F35C9FFB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.4176406023973702\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 9.3752 - val_loss: 4.4183\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6247 - val_loss: 4.2631\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4140 - val_loss: 5.3926\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4425 - val_loss: 4.0923\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3381 - val_loss: 4.1105\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2758 - val_loss: 4.1699\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1500 - val_loss: 4.4478\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2464 - val_loss: 4.3085\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0621 - val_loss: 3.8922\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1179 - val_loss: 4.9823\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0900 - val_loss: 4.0630\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9911 - val_loss: 3.8284\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0650 - val_loss: 4.5646\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0409 - val_loss: 4.0580\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9402 - val_loss: 4.3638\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9167 - val_loss: 4.0601\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7768 - val_loss: 5.4552\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8538 - val_loss: 4.0077\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7809 - val_loss: 3.7570\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8323 - val_loss: 3.4867\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8286 - val_loss: 3.5165\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8299 - val_loss: 3.5103\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8707 - val_loss: 3.4131\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7759 - val_loss: 3.5751\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6799 - val_loss: 3.3478\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7109 - val_loss: 4.8719\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6434 - val_loss: 3.4585\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6774 - val_loss: 3.6653\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6050 - val_loss: 3.3687\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7529 - val_loss: 3.9229\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7585 - val_loss: 3.3247\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5600 - val_loss: 3.2419\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5296 - val_loss: 3.3386\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9137 - val_loss: 3.1857\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3888 - val_loss: 3.0687\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5727 - val_loss: 7.1517\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9526 - val_loss: 3.1889\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5034 - val_loss: 3.3641\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5606 - val_loss: 3.1495\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6652 - val_loss: 3.1548\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6275 - val_loss: 2.9953\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4274 - val_loss: 3.1290\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6221 - val_loss: 2.8640\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4256 - val_loss: 3.5318\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3533 - val_loss: 2.9817\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3632 - val_loss: 3.1480\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2827 - val_loss: 2.9455\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2647 - val_loss: 2.9190\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7032 - val_loss: 2.9723\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2798 - val_loss: 2.9260\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F360C983A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.3596003385237935\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 6.8122 - val_loss: 3.9878\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6987 - val_loss: 4.2825\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3969 - val_loss: 5.2437\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4825 - val_loss: 4.4750\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3646 - val_loss: 3.5689\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5475 - val_loss: 3.8096\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0637 - val_loss: 3.5226\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9772 - val_loss: 3.6300\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9314 - val_loss: 3.5731\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2174 - val_loss: 7.1373\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4843 - val_loss: 3.5211\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8810 - val_loss: 3.1776\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9796 - val_loss: 3.7778\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8043 - val_loss: 5.6243\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8160 - val_loss: 3.2311\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8984 - val_loss: 4.2353\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7562 - val_loss: 3.7522\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0122 - val_loss: 3.3489\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9866 - val_loss: 3.2454\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5747 - val_loss: 3.8594\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6534 - val_loss: 2.9928\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6786 - val_loss: 5.3403\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.7544 - val_loss: 3.5071\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5904 - val_loss: 3.1509\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4506 - val_loss: 2.9048\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4062 - val_loss: 3.5882\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4815 - val_loss: 4.1139\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3531 - val_loss: 3.3086\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3228 - val_loss: 4.7732\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8229 - val_loss: 3.1007\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1515 - val_loss: 4.3624\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4580 - val_loss: 3.0357\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4879 - val_loss: 2.9307\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4265 - val_loss: 7.6058\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8434 - val_loss: 3.9320\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2143 - val_loss: 2.8004\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3131 - val_loss: 2.9869\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4662 - val_loss: 3.8688\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1759 - val_loss: 3.8474\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8994 - val_loss: 3.6429\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3454 - val_loss: 3.3284\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3616 - val_loss: 2.9352\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2571 - val_loss: 3.7613\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3909 - val_loss: 2.8633\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0548 - val_loss: 3.5613\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1913 - val_loss: 4.2728\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2553 - val_loss: 10.0582\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6206 - val_loss: 3.1470\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2938 - val_loss: 2.8194\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1828 - val_loss: 9.1575\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3622D24C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: -0.16291513144459602\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MAX: 0.4176406023973702\n",
      "AVG: 0.2699005856288998\n",
      "\n",
      "\n",
      "[0.4176406023973702, 0.39874949011875294, 0.3951410240803743, 0.39200695673122143, 0.3897242625530074, 0.3798570531243458, 0.37851977773623635, 0.3784971979586289, 0.3741536500712018, 0.367787121464758, 0.3660642111138269, 0.36532007969121916, 0.3596003385237935, 0.3570542753924917, 0.3483136048270008, 0.34740948734038846, 0.3467471390786019, 0.33837072602561946, 0.336235518950325, 0.335264046513591, 0.33403275124457443, 0.33396980307226365, 0.3245684670727397, 0.3244940575473124, 0.3153611084517244, 0.30832720254901724, 0.3059626496577408, 0.30196374552008887, 0.29793903387964704, 0.2934892411885578, 0.29086591137411477, 0.29016531406017754, 0.2855573608555422, 0.2852854165378752, 0.2569544599949345, 0.23969339841409898, 0.2393018001605013, 0.21437188671170293, 0.2114796724621495, 0.2021170073339007, 0.20150003061361188, 0.18876270733733636, 0.18589578512318772, 0.18214844743506142, 0.14706901413989704, 0.07976008591583095, 0.0661558300232481, -0.16291513144459602, -0.1932410429913094, -0.228463296488695]\n"
     ]
    }
   ],
   "source": [
    "esv = []\n",
    "# while True: \n",
    "for i in range(50):\n",
    "    \n",
    "    X_train.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    \n",
    "#     model.add(Dense(36, activation=\"relu\"))\n",
    "#     model.add(Dense(36, activation=\"relu\"))\n",
    "#     model.add(Dense(36, activation=\"relu\"))\n",
    "    \n",
    "    model.add(Dense(random.randint(30,40), activation=\"relu\"))\n",
    "    model.add(Dense(random.randint(30,40), activation=\"relu\"))\n",
    "    model.add(Dense(random.randint(30,40), activation=\"relu\"))\n",
    "    \n",
    "#     model.add(Dense(random.randint(30,40), activation=\"relu\"))\n",
    "    \n",
    "#     model.add(Dense(random.randint(30,40), activation=\"relu\"))\n",
    "    \n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
    "    model.fit(x=X_train, y= y_train, validation_data=(X_test,y_test),batch_size=32,epochs=50)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    esv.append(explained_variance_score(y_test,predictions))\n",
    "    print('\\n'+'\\n'+\"ESV: \" + str(explained_variance_score(y_test,predictions))+ '\\n'+'\\n'+'\\n')\n",
    "    if(explained_variance_score(y_test,predictions) > .45):\n",
    "        winsound.Beep(1047, 62)\n",
    "        break\n",
    "#     winsound.Beep(1397,250)\n",
    "\n",
    "esv.sort(reverse=True)\n",
    "print(\"\\n\")\n",
    "print(\"MAX: \" + str(max(esv)))\n",
    "print(\"AVG: \" + str(sum(esv)/len(esv)))\n",
    "print('\\n')\n",
    "print(esv)\n",
    "winsound.Beep(784, 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.3393155533477126\n",
      "RMSE:  1.8273794223826951\n",
      "MAE:  1.3071420583024833\n",
      "ESV:  0.4099647629304337\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \",mean_squared_error(y_test,predictions) )\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)) )\n",
    "print(\"MAE: \",mean_absolute_error(y_test,predictions) )\n",
    "print(\"ESV: \", explained_variance_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'real')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_scl = scaler.fit_transform(X)\n",
    "predTotal = model.predict(X_scl)\n",
    "plt.scatter(predTotal,y)\n",
    "plt.xlabel(\"PredTotal\")\n",
    "plt.ylabel('real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaron Jones\n",
      "[  27  182  201 1104    9   77   14   14   63   47  355    2   15   30\n",
      "    2    5    3    1]\n",
      "[[1.8760607]]\n",
      "Kenyan Drake\n",
      "[ 27  73 239 955  10  69  15  13  31  25 137   0   5  18   3  30  19  25]\n",
      "[[3.0334983]]\n",
      "Gus Edwards\n",
      "[ 26  -1 144 723   6  36  16   6  13   9 129   0   4  34   1   8   1   5]\n",
      "[[0.64211255]]\n",
      "James Conner\n",
      "[ 26 205 169 721   6  59  13  11  43  35 215   0  10  18   2  32  32  28]\n",
      "[[0.1710788]]\n",
      "Todd Gurley\n",
      "[ 27  10 195 678   9  35  15  15  35  25 164   0   7  26   2  24  28  27]\n",
      "[[2.6247954]]\n",
      "Frank Gore\n",
      "[ 38  65 187 653   2  17  15  14  19  16  89   0   3   9   1  31  31  25]\n",
      "[[1.3391302]]\n",
      "Chris Carson\n",
      "[ 27 249 141 681   5  29  12  12  46  37 287   4  14  29   1  10  15  17]\n",
      "[[0.7113606]]\n"
     ]
    }
   ],
   "source": [
    "rbs =pd.read_csv(\"../../data/rbs_to_predict.csv\")\n",
    "names = rbs['playername'].values\n",
    "rbs = rbs.drop('tm',axis=1)\n",
    "rbs = rbs.drop('playername',axis=1)\n",
    "for i in range(len(names)):\n",
    "    print(names[i])\n",
    "    print(rbs.iloc[i].to_numpy())\n",
    "    print(model.predict(scaler.transform(rbs.iloc[i].to_numpy().reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./savedmodels/April22-norookie-esv41\\assets\n"
     ]
    }
   ],
   "source": [
    "# model.save('./savedmodels/April22-norookie-esv41')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
