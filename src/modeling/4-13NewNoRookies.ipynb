{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../../data/processed/oline_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.year >= df.draft_yr+4]\n",
    "df =df[df.year != 2020]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('year',axis=1)\n",
    "df = df.drop('playername',axis=1)\n",
    "df = df.drop('team',axis=1)\n",
    "df = df.drop('basesalarycap (10^8)',axis=1)\n",
    "df = df.drop('cashspent (M)',axis=1)\n",
    "df = df.drop('caphit (M)',axis=1)\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df = df.drop('Unnamed: 0.1',axis=1)\n",
    "df = df.drop('catchpercent',axis=1)\n",
    "df = df.drop('draft_yr',axis=1)\n",
    "\n",
    "df = df.drop('yardspergame_run',axis=1)\n",
    "df = df.drop('yardsperatt',axis=1)\n",
    "df = df.drop('yardspertarget',axis=1)\n",
    "df = df.drop('yardsperrec',axis=1)\n",
    "df = df.drop('recpergame',axis=1)\n",
    "df = df.drop('yardspergame_rec',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>draft_pos</th>\n",
       "      <th>attempts</th>\n",
       "      <th>yards_run</th>\n",
       "      <th>tds_run</th>\n",
       "      <th>longgain_run</th>\n",
       "      <th>Percenthit (%)</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>tgt</th>\n",
       "      <th>rec</th>\n",
       "      <th>yards_rec</th>\n",
       "      <th>tds_rec</th>\n",
       "      <th>firstdowns</th>\n",
       "      <th>longgain_rec</th>\n",
       "      <th>fumbles</th>\n",
       "      <th>team_adjusted_line_yards</th>\n",
       "      <th>team_running_back_yards</th>\n",
       "      <th>team_stuffed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>211</td>\n",
       "      <td>898</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.945802</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>251</td>\n",
       "      <td>1042</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7.728473</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>327</td>\n",
       "      <td>1485</td>\n",
       "      <td>11</td>\n",
       "      <td>80</td>\n",
       "      <td>10.748185</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9.268023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>30</td>\n",
       "      <td>-1</td>\n",
       "      <td>133</td>\n",
       "      <td>548</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.540993</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.216154</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "      <td>857</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>4.888417</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.195122</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>138</td>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.398135</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  draft_pos  attempts  yards_run  tds_run  longgain_run  \\\n",
       "5     34          7       211        898        5            32   \n",
       "6     33          7       251       1042        7            90   \n",
       "7     31          7        37         72        0            13   \n",
       "8     30          7       327       1485       11            80   \n",
       "9     29          7        21         75        0            17   \n",
       "..   ...        ...       ...        ...      ...           ...   \n",
       "559   30         -1       133        548        4            30   \n",
       "560   29         -1        96        375        4            26   \n",
       "562   25         10       223        857       12            25   \n",
       "575   32         -1        11         23        0             6   \n",
       "584   32         23       138        377        2            16   \n",
       "\n",
       "     Percenthit (%)   g  gs  tgt  rec  yards_rec  tds_rec  firstdowns  \\\n",
       "5          0.945802  15  15   23   17        142        0           7   \n",
       "6          0.355530  16  16   26   20        208        1           9   \n",
       "7          7.728473   3   3    6    3          8        0           0   \n",
       "8         10.748185  16  16   36   30        222        0           9   \n",
       "9          9.268023   1   1    3    2         18        0           1   \n",
       "..              ...  ..  ..  ...  ...        ...      ...         ...   \n",
       "559        0.540993  16   1   26   22        200        1          11   \n",
       "560        0.216154   8   3   13   12        129        0           7   \n",
       "562        4.888417  15  15   49   31        207        2           8   \n",
       "575        1.195122  16   7   20   11         47        1           3   \n",
       "584        0.398135  12   6   11    8         20        0           0   \n",
       "\n",
       "     longgain_rec  fumbles  team_adjusted_line_yards  team_running_back_yards  \\\n",
       "5              22        3                      18.0                     15.0   \n",
       "6              52        3                      26.0                     23.0   \n",
       "7               7        1                      30.0                     32.0   \n",
       "8              49        7                      10.0                      4.0   \n",
       "9               9        0                      13.0                     15.0   \n",
       "..            ...      ...                       ...                      ...   \n",
       "559            50        0                       1.0                      9.0   \n",
       "560            27        0                      13.0                     18.0   \n",
       "562            23        3                      19.0                     26.0   \n",
       "575            12        1                      32.0                     32.0   \n",
       "584             9        1                      18.0                     29.0   \n",
       "\n",
       "     team_stuffed_rate  \n",
       "5                 17.0  \n",
       "6                 28.0  \n",
       "7                 26.0  \n",
       "8                 12.0  \n",
       "9                  2.0  \n",
       "..                 ...  \n",
       "559                2.0  \n",
       "560               14.0  \n",
       "562               26.0  \n",
       "575               32.0  \n",
       "584               18.0  \n",
       "\n",
       "[201 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Percenthit (%)',axis=1).values\n",
    "y = df['Percenthit (%)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.1185 - val_loss: 13.5943\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14.8102 - val_loss: 13.3852\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.6238 - val_loss: 13.2547\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.4992 - val_loss: 13.1375\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.3900 - val_loss: 13.0129\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2490 - val_loss: 12.8601\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 14.0778 - val_loss: 12.6788\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.8879 - val_loss: 12.4598\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.6548 - val_loss: 12.1948\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.3624 - val_loss: 11.8759\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 13.0416 - val_loss: 11.4880\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.6147 - val_loss: 11.0309\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.1317 - val_loss: 10.4870\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 11.5736 - val_loss: 9.8517\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.8870 - val_loss: 9.1343\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.1399 - val_loss: 8.3101\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 9.2625 - val_loss: 7.4402\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 8.3725 - val_loss: 6.5690\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 7.5212 - val_loss: 5.7749\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.6999 - val_loss: 5.1657\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.1115 - val_loss: 4.7902\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.7340 - val_loss: 4.6758\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.4933 - val_loss: 4.7459\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.4364 - val_loss: 4.8520\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.4199 - val_loss: 4.8950\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3910 - val_loss: 4.8767\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3449 - val_loss: 4.8134\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2856 - val_loss: 4.7690\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.2372 - val_loss: 4.7316\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.1970 - val_loss: 4.7170\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1607 - val_loss: 4.7064\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1232 - val_loss: 4.6867\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0921 - val_loss: 4.6982\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0487 - val_loss: 4.6952\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.0152 - val_loss: 4.6859\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.9758 - val_loss: 4.6970\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.9370 - val_loss: 4.7026\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8966 - val_loss: 4.7181\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8582 - val_loss: 4.7222\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8030 - val_loss: 4.7289\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.7498 - val_loss: 4.7154\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6863 - val_loss: 4.7068\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.6260 - val_loss: 4.6948\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.5763 - val_loss: 4.6549\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5179 - val_loss: 4.7086\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4529 - val_loss: 4.7451\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3705 - val_loss: 4.7215\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3100 - val_loss: 4.7394\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2473 - val_loss: 4.7947\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1824 - val_loss: 4.7933\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000134F924F678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.09191507023286583\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5349 - val_loss: 10.5497\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.6630 - val_loss: 9.5704\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.7065 - val_loss: 8.5817\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.7384 - val_loss: 7.5352\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.6962 - val_loss: 6.5270\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.5853 - val_loss: 5.6496\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.6230 - val_loss: 4.9924\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.7698 - val_loss: 4.6530\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2936 - val_loss: 4.6573\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.9876 - val_loss: 4.9373\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8797 - val_loss: 5.2492\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8872 - val_loss: 5.4274\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8544 - val_loss: 5.3599\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7869 - val_loss: 5.2090\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7095 - val_loss: 5.0971\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6549 - val_loss: 4.9904\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.6076 - val_loss: 4.9361\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5711 - val_loss: 4.9178\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5202 - val_loss: 4.9248\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4997 - val_loss: 5.0007\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4265 - val_loss: 4.9992\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3870 - val_loss: 5.0269\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3412 - val_loss: 4.9830\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2982 - val_loss: 4.9852\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2528 - val_loss: 5.0010\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2137 - val_loss: 5.0143\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 4.1743 - val_loss: 5.0361\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1683 - val_loss: 5.1703\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1195 - val_loss: 5.2155\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0712 - val_loss: 5.0880\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0366 - val_loss: 5.0141\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0022 - val_loss: 5.0284\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9782 - val_loss: 5.1003\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9411 - val_loss: 5.1054\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9137 - val_loss: 5.1019\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.9136 - val_loss: 5.2180\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.8636 - val_loss: 5.1336\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8343 - val_loss: 5.1062\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8134 - val_loss: 5.0991\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7940 - val_loss: 5.1494\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7721 - val_loss: 5.1938\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7492 - val_loss: 5.1201\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7297 - val_loss: 5.1308\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7116 - val_loss: 5.1302\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7010 - val_loss: 5.0701\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6741 - val_loss: 5.1584\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6519 - val_loss: 5.1779\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6378 - val_loss: 5.1567\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6238 - val_loss: 5.0637\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6026 - val_loss: 5.0604\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000134FA2CEB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.07506177991053742\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.1656 - val_loss: 9.2494\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10.9331 - val_loss: 7.9105\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5962 - val_loss: 6.6961\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.3490 - val_loss: 5.6621\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.2072 - val_loss: 4.9187\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.3165 - val_loss: 4.4720\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.6722 - val_loss: 4.3479\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3529 - val_loss: 4.4347\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.2218 - val_loss: 4.5906\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1055 - val_loss: 4.6501\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.0174 - val_loss: 4.5825\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.8844 - val_loss: 4.4711\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.7817 - val_loss: 4.3626\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.6745 - val_loss: 4.3007\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.5867 - val_loss: 4.2935\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.4989 - val_loss: 4.2782\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.4184 - val_loss: 4.2521\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3447 - val_loss: 4.2965\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.2833 - val_loss: 4.3434\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.2059 - val_loss: 4.3090\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.1430 - val_loss: 4.2996\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0989 - val_loss: 4.3243\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.0570 - val_loss: 4.3487\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0051 - val_loss: 4.2843\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9610 - val_loss: 4.2847\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9188 - val_loss: 4.2777\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8870 - val_loss: 4.3122\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8644 - val_loss: 4.3529\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8323 - val_loss: 4.3203\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.8102 - val_loss: 4.3513\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7870 - val_loss: 4.3576\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7622 - val_loss: 4.3173\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7425 - val_loss: 4.3447\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7308 - val_loss: 4.3719\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7095 - val_loss: 4.3100\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6953 - val_loss: 4.3291\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6812 - val_loss: 4.3420\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6643 - val_loss: 4.2846\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6444 - val_loss: 4.2790\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6287 - val_loss: 4.2964\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6267 - val_loss: 4.3341\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.6131 - val_loss: 4.2509\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5900 - val_loss: 4.2512\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5848 - val_loss: 4.2503\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5685 - val_loss: 4.2788\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5573 - val_loss: 4.2895\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5536 - val_loss: 4.2223\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.5386 - val_loss: 4.2459\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5355 - val_loss: 4.2557\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5197 - val_loss: 4.1932\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000134F127DB88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.18665901145143649\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 12.0823WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.1990 - val_loss: 9.1493\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.1206 - val_loss: 8.0965\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0610 - val_loss: 7.0860\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.9365 - val_loss: 6.1810\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.9761 - val_loss: 5.4284\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0702 - val_loss: 4.9159\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4034 - val_loss: 4.6934\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.9402 - val_loss: 4.7468\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7773 - val_loss: 4.9886\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6810 - val_loss: 5.1922\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6669 - val_loss: 5.2926\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6078 - val_loss: 5.2062\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5339 - val_loss: 5.1271\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4860 - val_loss: 4.9829\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4256 - val_loss: 4.9041\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3956 - val_loss: 4.8464\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3465 - val_loss: 4.8632\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3009 - val_loss: 4.8811\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2633 - val_loss: 4.8725\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2146 - val_loss: 4.9179\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1788 - val_loss: 4.9374\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1413 - val_loss: 4.9653\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1231 - val_loss: 5.0133\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0776 - val_loss: 5.0225\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0320 - val_loss: 4.9482\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0003 - val_loss: 4.9068\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9715 - val_loss: 4.9075\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9375 - val_loss: 4.8816\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9152 - val_loss: 4.8645\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.8829 - val_loss: 4.9469\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.8446 - val_loss: 4.9792\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.8202 - val_loss: 5.0102\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.8108 - val_loss: 5.0684\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7661 - val_loss: 4.9567\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.7345 - val_loss: 4.9149\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7097 - val_loss: 4.9691\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6894 - val_loss: 4.9915\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6576 - val_loss: 4.9528\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6313 - val_loss: 4.9260\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6084 - val_loss: 4.9595\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5900 - val_loss: 4.9932\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5623 - val_loss: 4.9589\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5488 - val_loss: 4.9254\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5218 - val_loss: 4.9564\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5007 - val_loss: 4.9928\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4854 - val_loss: 4.9870\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4686 - val_loss: 5.0159\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4468 - val_loss: 4.9802\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4375 - val_loss: 4.9489\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4115 - val_loss: 4.9444\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000134DED13798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.0589330255879863\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 19.6416WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.2780 - val_loss: 14.6446\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 15.3779 - val_loss: 13.7889\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.7123 - val_loss: 13.1513\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.2268 - val_loss: 12.6172\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.7324 - val_loss: 12.1193\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 13.2383 - val_loss: 11.5972\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.7165 - val_loss: 11.0243\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.1068 - val_loss: 10.3741\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.4039 - val_loss: 9.6478\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.5879 - val_loss: 8.8376\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.6604 - val_loss: 8.0070\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 8.7239 - val_loss: 7.1846\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 7.7406 - val_loss: 6.4572\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.9000 - val_loss: 5.8873\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 6.1481 - val_loss: 5.5633\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6602 - val_loss: 5.5165\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.2737 - val_loss: 5.6874\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1146 - val_loss: 5.9115\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.1026 - val_loss: 6.0956\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.0854 - val_loss: 6.1427\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.0491 - val_loss: 6.1113\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.9956 - val_loss: 5.9662\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.9472 - val_loss: 5.8294\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.8922 - val_loss: 5.7761\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8569 - val_loss: 5.7159\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.8211 - val_loss: 5.6749\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.7889 - val_loss: 5.6275\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.7490 - val_loss: 5.6601\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6955 - val_loss: 5.6500\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6584 - val_loss: 5.6884\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.6088 - val_loss: 5.6789\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5493 - val_loss: 5.6356\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4985 - val_loss: 5.5787\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4386 - val_loss: 5.5623\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.3969 - val_loss: 5.5182\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3492 - val_loss: 5.5589\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2912 - val_loss: 5.5672\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2248 - val_loss: 5.5115\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1778 - val_loss: 5.5063\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1196 - val_loss: 5.4878\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0777 - val_loss: 5.5046\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0270 - val_loss: 5.4692\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9768 - val_loss: 5.4935\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9417 - val_loss: 5.5057\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9026 - val_loss: 5.4829\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8674 - val_loss: 5.4799\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8328 - val_loss: 5.4172\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8045 - val_loss: 5.3586\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7591 - val_loss: 5.3558\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7286 - val_loss: 5.3584\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000134F508B948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: -0.0442912097995265\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MAX: 0.18665901145143649\n",
      "\n",
      "\n",
      "[0.18665901145143649, 0.09191507023286583, 0.07506177991053742, 0.0589330255879863, -0.0442912097995265]\n"
     ]
    }
   ],
   "source": [
    "esv = []\n",
    "# while True: \n",
    "for i in range(5):\n",
    "    \n",
    "    X_train.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(18, activation=\"relu\"))\n",
    "    model.add(Dense(13, activation=\"relu\"))\n",
    "    model.add(Dense(13, activation=\"relu\"))\n",
    "    \n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    model.fit(x=X_train, y= y_train, validation_data=(X_test,y_test),batch_size=32,epochs=50)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    esv.append(explained_variance_score(y_test,predictions))\n",
    "    print('\\n'+'\\n'+\"ESV: \" + str(explained_variance_score(y_test,predictions))+ '\\n'+'\\n'+'\\n')\n",
    "    if(explained_variance_score(y_test,predictions) > .30):\n",
    "        winsound.Beep(1047, 250)\n",
    "        winsound.Beep(1047, 250)\n",
    "        break\n",
    "#     winsound.Beep(1397,250)\n",
    "\n",
    "esv.sort(reverse=True)\n",
    "print(\"\\n\")\n",
    "print(\"MAX: \" + str(max(esv)))\n",
    "print(\"\\n\")\n",
    "print(esv)\n",
    "winsound.Beep(784, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./savedmodels/norookiednn\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('./savedmodels/norookiednn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.335409621457654\n",
      "RMSE:  1.8263103847532747\n",
      "MAE:  1.3321803925332953\n",
      "ESV:  0.4973884956852528\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('./savedmodels/norookiednn/')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \",mean_squared_error(y_test,predictions) )\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)) )\n",
    "print(\"MAE: \",mean_absolute_error(y_test,predictions) )\n",
    "print(\"ESV: \", explained_variance_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.26654578e-02]\n",
      " [1.64097915e-01]\n",
      " [1.81323663e-01]\n",
      " [1.00000000e+00]\n",
      " [7.25294651e-03]\n",
      " [6.89029918e-02]\n",
      " [1.17860381e-02]\n",
      " [1.17860381e-02]\n",
      " [5.62103354e-02]\n",
      " [4.17044424e-02]\n",
      " [3.20942883e-01]\n",
      " [9.06618314e-04]\n",
      " [1.26926564e-02]\n",
      " [2.62919311e-02]\n",
      " [9.06618314e-04]\n",
      " [3.62647325e-03]\n",
      " [1.81323663e-03]\n",
      " [0.00000000e+00]]\n",
      "[[1.2715582]]\n"
     ]
    }
   ],
   "source": [
    "Aaron_Jones2020 = np.array([26,182,201,1104,9,77,14,14,63,47,355,2,15,30,2,5,3,1])\n",
    "Aaron_Jones2020.shape\n",
    "X_transformed = scaler.fit_transform(Aaron_Jones2020[:, np.newaxis])\n",
    "print(X_transformed)\n",
    "print(loaded_model.predict(X_transformed.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.26654578e-02 1.64097915e-01 1.81323663e-01 1.00000000e+00\n",
      "  7.25294651e-03 6.89029918e-02 1.17860381e-02 1.17860381e-02\n",
      "  5.62103354e-02 4.17044424e-02 3.20942883e-01 9.06618314e-04\n",
      "  1.26926564e-02 2.62919311e-02 9.06618314e-04 3.62647325e-03\n",
      "  1.81323663e-03 0.00000000e+00]] \n",
      "\n",
      "[[1.2715582]]\n"
     ]
    }
   ],
   "source": [
    "Aaron_Jones2020 = np.array([26,182,201,1104,9,77,14,14,63,47,355,2,15,30,2,5,3,1])\n",
    "Aaron_Jones2020.shape\n",
    "X_transformed = scaler.transform(Aaron_Jones2020.reshape(1, -1))\n",
    "print(X_transformed, '\\n')\n",
    "print(loaded_model.predict(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02357208  0.06527652  0.21577516  0.86491387  0.00815956  0.06165005\n",
      "   0.01269266  0.01087942  0.02719855  0.02175884  0.12330009 -0.00090662\n",
      "   0.00362647  0.01541251  0.00181324  0.02629193  0.01631913  0.02175884]] \n",
      "\n",
      "[[1.5619557]]\n"
     ]
    }
   ],
   "source": [
    "KenyanDrake_2020 = np.array([27,73,239,955,10,69,15,13,31,25,137,0,5,18,3,30,19,25])\n",
    "KenyanDrake_2020.shape\n",
    "X_transformed = scaler.transform(KenyanDrake_2020.reshape(1, -1))\n",
    "print(X_transformed, '\\n')\n",
    "print(loaded_model.predict(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
