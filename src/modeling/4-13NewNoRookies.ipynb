{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import winsound\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../../data/processed/oline_merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.year >= df.draft_yr+4]\n",
    "df =df[df.year != 2020]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('year',axis=1)\n",
    "df = df.drop('playername',axis=1)\n",
    "df = df.drop('team',axis=1)\n",
    "df = df.drop('basesalarycap (10^8)',axis=1)\n",
    "df = df.drop('cashspent (M)',axis=1)\n",
    "df = df.drop('caphit (M)',axis=1)\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df = df.drop('Unnamed: 0.1',axis=1)\n",
    "df = df.drop('catchpercent',axis=1)\n",
    "df = df.drop('draft_yr',axis=1)\n",
    "\n",
    "df = df.drop('yardspergame_run',axis=1)\n",
    "df = df.drop('yardsperatt',axis=1)\n",
    "df = df.drop('yardspertarget',axis=1)\n",
    "df = df.drop('yardsperrec',axis=1)\n",
    "df = df.drop('recpergame',axis=1)\n",
    "df = df.drop('yardspergame_rec',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>draft_pos</th>\n",
       "      <th>attempts</th>\n",
       "      <th>yards_run</th>\n",
       "      <th>tds_run</th>\n",
       "      <th>longgain_run</th>\n",
       "      <th>Percenthit (%)</th>\n",
       "      <th>g</th>\n",
       "      <th>gs</th>\n",
       "      <th>tgt</th>\n",
       "      <th>rec</th>\n",
       "      <th>yards_rec</th>\n",
       "      <th>tds_rec</th>\n",
       "      <th>firstdowns</th>\n",
       "      <th>longgain_rec</th>\n",
       "      <th>fumbles</th>\n",
       "      <th>team_adjusted_line_yards</th>\n",
       "      <th>team_running_back_yards</th>\n",
       "      <th>team_stuffed_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>211</td>\n",
       "      <td>898</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.945802</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>251</td>\n",
       "      <td>1042</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7.728473</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>327</td>\n",
       "      <td>1485</td>\n",
       "      <td>11</td>\n",
       "      <td>80</td>\n",
       "      <td>10.748185</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9.268023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>559</td>\n",
       "      <td>30</td>\n",
       "      <td>257</td>\n",
       "      <td>133</td>\n",
       "      <td>548</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.540993</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>29</td>\n",
       "      <td>257</td>\n",
       "      <td>96</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.216154</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>562</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>223</td>\n",
       "      <td>857</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>4.888417</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>32</td>\n",
       "      <td>257</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.195122</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>138</td>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.398135</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  draft_pos  attempts  yards_run  tds_run  longgain_run  \\\n",
       "5     34          7       211        898        5            32   \n",
       "6     33          7       251       1042        7            90   \n",
       "7     31          7        37         72        0            13   \n",
       "8     30          7       327       1485       11            80   \n",
       "9     29          7        21         75        0            17   \n",
       "..   ...        ...       ...        ...      ...           ...   \n",
       "559   30        257       133        548        4            30   \n",
       "560   29        257        96        375        4            26   \n",
       "562   25         10       223        857       12            25   \n",
       "575   32        257        11         23        0             6   \n",
       "584   32         23       138        377        2            16   \n",
       "\n",
       "     Percenthit (%)   g  gs  tgt  rec  yards_rec  tds_rec  firstdowns  \\\n",
       "5          0.945802  15  15   23   17        142        0           7   \n",
       "6          0.355530  16  16   26   20        208        1           9   \n",
       "7          7.728473   3   3    6    3          8        0           0   \n",
       "8         10.748185  16  16   36   30        222        0           9   \n",
       "9          9.268023   1   1    3    2         18        0           1   \n",
       "..              ...  ..  ..  ...  ...        ...      ...         ...   \n",
       "559        0.540993  16   1   26   22        200        1          11   \n",
       "560        0.216154   8   3   13   12        129        0           7   \n",
       "562        4.888417  15  15   49   31        207        2           8   \n",
       "575        1.195122  16   7   20   11         47        1           3   \n",
       "584        0.398135  12   6   11    8         20        0           0   \n",
       "\n",
       "     longgain_rec  fumbles  team_adjusted_line_yards  team_running_back_yards  \\\n",
       "5              22        3                        18                       15   \n",
       "6              52        3                        26                       23   \n",
       "7               7        1                        30                       32   \n",
       "8              49        7                        10                        4   \n",
       "9               9        0                        13                       15   \n",
       "..            ...      ...                       ...                      ...   \n",
       "559            50        0                         1                        9   \n",
       "560            27        0                        13                       18   \n",
       "562            23        3                        19                       26   \n",
       "575            12        1                        32                       32   \n",
       "584             9        1                        18                       29   \n",
       "\n",
       "     team_stuffed_rate  \n",
       "5                   17  \n",
       "6                   28  \n",
       "7                   26  \n",
       "8                   12  \n",
       "9                    2  \n",
       "..                 ...  \n",
       "559                  2  \n",
       "560                 14  \n",
       "562                 26  \n",
       "575                 32  \n",
       "584                 18  \n",
       "\n",
       "[201 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Percenthit (%)',axis=1).values\n",
    "y = df['Percenthit (%)'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.9905 - val_loss: 13.0765\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 13.6399 - val_loss: 11.6248\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.2803 - val_loss: 10.1952\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 10.9432 - val_loss: 8.7502\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5128 - val_loss: 7.3842\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.1197 - val_loss: 6.2040\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.8922 - val_loss: 5.3786\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 6.0540 - val_loss: 5.0472\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4348 - val_loss: 5.2440\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2028 - val_loss: 5.6545\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1469 - val_loss: 5.8313\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0536 - val_loss: 5.7257\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.9090 - val_loss: 5.4513\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7367 - val_loss: 5.2708\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.5952 - val_loss: 5.1411\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.4537 - val_loss: 5.0861\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3146 - val_loss: 5.0736\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 4.1522 - val_loss: 5.1351\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1023 - val_loss: 5.3629\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.9067 - val_loss: 5.3615\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.8114 - val_loss: 5.4314\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6784 - val_loss: 5.4308\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6166 - val_loss: 5.5306\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5286 - val_loss: 5.5482\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4657 - val_loss: 5.6127\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.4250 - val_loss: 5.6860\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3616 - val_loss: 5.5564\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3125 - val_loss: 5.5523\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2859 - val_loss: 5.6141\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 3.2397 - val_loss: 5.5145\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2031 - val_loss: 5.5912\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.1579 - val_loss: 5.4963\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1350 - val_loss: 5.3844\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1146 - val_loss: 5.5676\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0738 - val_loss: 5.5864\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0525 - val_loss: 5.5593\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0243 - val_loss: 5.5773\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0032 - val_loss: 5.4934\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9803 - val_loss: 5.3958\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9469 - val_loss: 5.5245\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9402 - val_loss: 5.3940\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8879 - val_loss: 5.5469\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8801 - val_loss: 5.6816\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.8560 - val_loss: 5.5009\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8099 - val_loss: 5.2579\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8065 - val_loss: 5.2415\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 2.7695 - val_loss: 5.5239\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7296 - val_loss: 5.5293\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7048 - val_loss: 5.4336\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.6718 - val_loss: 5.3611\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002808C724AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.047555863893254724\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.4150 - val_loss: 11.5178\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.1481 - val_loss: 9.3208\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.1797 - val_loss: 7.5591\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.5798 - val_loss: 6.0821\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.1760 - val_loss: 5.0119\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0682 - val_loss: 4.4841\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.5303 - val_loss: 4.4976\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.2453 - val_loss: 4.8239\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2058 - val_loss: 5.0159\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.1832 - val_loss: 4.9723\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.0650 - val_loss: 4.7665\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.9476 - val_loss: 4.5863\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.8295 - val_loss: 4.5071\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7393 - val_loss: 4.4665\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6467 - val_loss: 4.4671\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5483 - val_loss: 4.4730\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.4575 - val_loss: 4.4821\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3717 - val_loss: 4.5101\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2729 - val_loss: 4.4870\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1914 - val_loss: 4.4975\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.1206 - val_loss: 4.5778\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9891 - val_loss: 4.5192\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.8986 - val_loss: 4.4669\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.8265 - val_loss: 4.5075\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.7393 - val_loss: 4.6089\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.6458 - val_loss: 4.6244\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5882 - val_loss: 4.6315\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5453 - val_loss: 4.8025\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4866 - val_loss: 4.8806\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.4291 - val_loss: 4.7620\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3885 - val_loss: 4.8140\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.3416 - val_loss: 4.8421\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3081 - val_loss: 4.9026\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2744 - val_loss: 4.9196\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2442 - val_loss: 4.9762\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2137 - val_loss: 4.9341\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2038 - val_loss: 4.9568\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1612 - val_loss: 4.9305\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1578 - val_loss: 4.8051\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1152 - val_loss: 4.9686\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0986 - val_loss: 4.9700\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0765 - val_loss: 4.9191\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0521 - val_loss: 5.0228\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0349 - val_loss: 5.0397\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0171 - val_loss: 4.9141\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9956 - val_loss: 4.9631\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9780 - val_loss: 4.9741\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9540 - val_loss: 4.9503\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9345 - val_loss: 5.0121\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9344 - val_loss: 5.0997\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002808EEFD5E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.055887181237368244\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.0312 - val_loss: 12.2066\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.1758 - val_loss: 11.2983\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 12.3405 - val_loss: 10.3057\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 11.3823 - val_loss: 9.1918\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.2631 - val_loss: 7.9737\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.0299 - val_loss: 6.7231\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.8450 - val_loss: 5.5348\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.5943 - val_loss: 4.5934\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6112 - val_loss: 4.0828\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9217 - val_loss: 4.1290\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.7194 - val_loss: 4.5027\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.6653 - val_loss: 4.7111\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.5917 - val_loss: 4.6639\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.4043 - val_loss: 4.4246\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2448 - val_loss: 4.2834\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.1213 - val_loss: 4.2109\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.0193 - val_loss: 4.2022\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.9001 - val_loss: 4.1871\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.7972 - val_loss: 4.1716\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.6892 - val_loss: 4.3481\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.5660 - val_loss: 4.4288\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4862 - val_loss: 4.4911\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.3999 - val_loss: 4.5867\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3211 - val_loss: 4.4990\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2696 - val_loss: 4.4063\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2376 - val_loss: 4.6291\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1555 - val_loss: 4.7343\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1356 - val_loss: 4.7457\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1015 - val_loss: 4.7200\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0582 - val_loss: 4.5392\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0519 - val_loss: 4.6316\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0235 - val_loss: 4.6775\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9965 - val_loss: 4.5803\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9705 - val_loss: 4.5945\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9502 - val_loss: 4.6629\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9297 - val_loss: 4.7511\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9092 - val_loss: 4.6358\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8798 - val_loss: 4.6696\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8637 - val_loss: 4.6188\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8549 - val_loss: 4.7654\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8256 - val_loss: 4.7957\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7868 - val_loss: 4.6461\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7676 - val_loss: 4.5585\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7435 - val_loss: 4.5567\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7026 - val_loss: 4.7387\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.6802 - val_loss: 4.8825\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6423 - val_loss: 4.7467\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6220 - val_loss: 4.6695\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5928 - val_loss: 4.7824\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.5632 - val_loss: 4.7236\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028091615318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ESV: 0.12394424736642917\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.6141 - val_loss: 11.7563\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 12.8227 - val_loss: 10.8084\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 11.9006 - val_loss: 9.6805\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 10.8216 - val_loss: 8.4140\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 9.5160 - val_loss: 7.1359\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 8.3581 - val_loss: 6.0120\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 7.2548 - val_loss: 5.3467\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.3847 - val_loss: 5.2808\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 6.0784 - val_loss: 5.6153\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.9389 - val_loss: 5.8091\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.6957 - val_loss: 5.6623\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.3716 - val_loss: 5.4260\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0270 - val_loss: 5.2390\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.7813 - val_loss: 5.1831\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.5397 - val_loss: 5.3122\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 4.3524 - val_loss: 5.4470\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.2193 - val_loss: 5.5952\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 4.0536 - val_loss: 5.5669\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.9361 - val_loss: 5.4944\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.8240 - val_loss: 5.4145\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.7459 - val_loss: 5.4634\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6608 - val_loss: 5.4365\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5804 - val_loss: 5.3331\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.5308 - val_loss: 5.3095\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4552 - val_loss: 5.2423\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.4155 - val_loss: 5.4102\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3516 - val_loss: 5.3490\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3175 - val_loss: 5.1529\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2673 - val_loss: 5.1459\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.2334 - val_loss: 5.2491\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1871 - val_loss: 5.2145\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.1523 - val_loss: 5.1646\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1230 - val_loss: 5.0228\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.1372 - val_loss: 4.8851\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0825 - val_loss: 5.1830\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0564 - val_loss: 5.2073\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0218 - val_loss: 5.0027\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9920 - val_loss: 4.9600\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9723 - val_loss: 5.0385\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9410 - val_loss: 5.0976\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.9213 - val_loss: 4.9967\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9119 - val_loss: 5.1629\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8830 - val_loss: 4.9420\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8578 - val_loss: 5.0502\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8334 - val_loss: 4.9774\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8103 - val_loss: 5.0532\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8108 - val_loss: 4.9631\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7789 - val_loss: 5.1111\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7540 - val_loss: 5.0033\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.7288 - val_loss: 4.9913\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002809178E318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.1008511384680012\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 14.4357 - val_loss: 12.2704\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 13.3478 - val_loss: 11.0210\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12.2205 - val_loss: 9.7075\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 10.9333 - val_loss: 8.2199\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9.5572 - val_loss: 6.6658\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.1285 - val_loss: 5.3559\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.8375 - val_loss: 4.6345\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.0483 - val_loss: 4.6737\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8864 - val_loss: 5.2055\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.8493 - val_loss: 5.4313\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.7713 - val_loss: 5.1522\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 5.5980 - val_loss: 4.8526\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.4652 - val_loss: 4.6334\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3922 - val_loss: 4.5152\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.3228 - val_loss: 4.4894\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.2385 - val_loss: 4.4759\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 5.1928 - val_loss: 4.5706\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 5.0804 - val_loss: 4.5881\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9922 - val_loss: 4.4989\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.9193 - val_loss: 4.5100\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.8288 - val_loss: 4.4267\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.7365 - val_loss: 4.3852\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.6682 - val_loss: 4.4020\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 4.5628 - val_loss: 4.3472\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.4662 - val_loss: 4.3654\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 4.3900 - val_loss: 4.4709\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 4.2722 - val_loss: 4.3938\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.1585 - val_loss: 4.1994\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.0427 - val_loss: 4.2094\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.9634 - val_loss: 4.4161\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.8294 - val_loss: 4.4562\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.7076 - val_loss: 4.2579\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.6124 - val_loss: 4.3510\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.4967 - val_loss: 4.3244\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3942 - val_loss: 4.3735\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.3065 - val_loss: 4.5100\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.2427 - val_loss: 4.8761\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.1762 - val_loss: 4.7193\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.1249 - val_loss: 4.9853\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 3.0516 - val_loss: 4.8674\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0439 - val_loss: 4.9628\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9810 - val_loss: 5.0832\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9699 - val_loss: 5.2360\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9212 - val_loss: 5.1032\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8962 - val_loss: 5.1367\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8750 - val_loss: 5.5014\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8468 - val_loss: 5.8881\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8087 - val_loss: 5.9295\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.8212 - val_loss: 5.2160\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.7839 - val_loss: 5.8557\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002808D9E1DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "\n",
      "ESV: 0.13083063374248705\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MAX: 0.13083063374248705\n",
      "\n",
      "\n",
      "[0.13083063374248705, 0.12394424736642917, 0.1008511384680012, 0.055887181237368244, 0.047555863893254724]\n"
     ]
    }
   ],
   "source": [
    "esv = []\n",
    "# while True: \n",
    "for i in range(5):\n",
    "    \n",
    "    X_train.shape\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(18, activation=\"relu\"))\n",
    "    model.add(Dense(40, activation=\"relu\"))\n",
    "    model.add(Dense(40, activation=\"relu\"))\n",
    "    \n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    model.fit(x=X_train, y= y_train, validation_data=(X_test,y_test),batch_size=32,epochs=50)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    esv.append(explained_variance_score(y_test,predictions))\n",
    "    print('\\n'+'\\n'+\"ESV: \" + str(explained_variance_score(y_test,predictions))+ '\\n'+'\\n'+'\\n')\n",
    "    if(explained_variance_score(y_test,predictions) > .30):\n",
    "        winsound.Beep(1047, 250)\n",
    "        winsound.Beep(1047, 250)\n",
    "        break\n",
    "#     winsound.Beep(1397,250)\n",
    "\n",
    "esv.sort(reverse=True)\n",
    "print(\"\\n\")\n",
    "print(\"MAX: \" + str(max(esv)))\n",
    "print(\"\\n\")\n",
    "print(esv)\n",
    "winsound.Beep(784, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./savedmodels/norookiednn\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('./savedmodels/norookiednn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  3.335409621457654\n",
      "RMSE:  1.8263103847532747\n",
      "MAE:  1.3321803925332953\n",
      "ESV:  0.4973884956852528\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('./savedmodels/norookiednn/')\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \",mean_squared_error(y_test,predictions) )\n",
    "print(\"RMSE: \",np.sqrt(mean_squared_error(y_test,predictions)) )\n",
    "print(\"MAE: \",mean_absolute_error(y_test,predictions) )\n",
    "print(\"ESV: \", explained_variance_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.26654578e-02]\n",
      " [1.64097915e-01]\n",
      " [1.81323663e-01]\n",
      " [1.00000000e+00]\n",
      " [7.25294651e-03]\n",
      " [6.89029918e-02]\n",
      " [1.17860381e-02]\n",
      " [1.17860381e-02]\n",
      " [5.62103354e-02]\n",
      " [4.17044424e-02]\n",
      " [3.20942883e-01]\n",
      " [9.06618314e-04]\n",
      " [1.26926564e-02]\n",
      " [2.62919311e-02]\n",
      " [9.06618314e-04]\n",
      " [3.62647325e-03]\n",
      " [1.81323663e-03]\n",
      " [0.00000000e+00]]\n",
      "[[1.2715582]]\n"
     ]
    }
   ],
   "source": [
    "Aaron_Jones2020 = np.array([26,182,201,1104,9,77,14,14,63,47,355,2,15,30,2,5,3,1])\n",
    "Aaron_Jones2020.shape\n",
    "X_transformed = scaler.fit_transform(Aaron_Jones2020[:, np.newaxis])\n",
    "print(X_transformed)\n",
    "print(loaded_model.predict(X_transformed.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.26654578e-02 1.64097915e-01 1.81323663e-01 1.00000000e+00\n",
      "  7.25294651e-03 6.89029918e-02 1.17860381e-02 1.17860381e-02\n",
      "  5.62103354e-02 4.17044424e-02 3.20942883e-01 9.06618314e-04\n",
      "  1.26926564e-02 2.62919311e-02 9.06618314e-04 3.62647325e-03\n",
      "  1.81323663e-03 0.00000000e+00]] \n",
      "\n",
      "[[1.2715582]]\n"
     ]
    }
   ],
   "source": [
    "Aaron_Jones2020 = np.array([26,182,201,1104,9,77,14,14,63,47,355,2,15,30,2,5,3,1])\n",
    "Aaron_Jones2020.shape\n",
    "X_transformed = scaler.transform(Aaron_Jones2020.reshape(1, -1))\n",
    "print(X_transformed, '\\n')\n",
    "print(loaded_model.predict(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02357208  0.06527652  0.21577516  0.86491387  0.00815956  0.06165005\n",
      "   0.01269266  0.01087942  0.02719855  0.02175884  0.12330009 -0.00090662\n",
      "   0.00362647  0.01541251  0.00181324  0.02629193  0.01631913  0.02175884]] \n",
      "\n",
      "[[1.5619557]]\n"
     ]
    }
   ],
   "source": [
    "KenyanDrake_2020 = np.array([27,73,239,955,10,69,15,13,31,25,137,0,5,18,3,30,19,25])\n",
    "KenyanDrake_2020.shape\n",
    "X_transformed = scaler.transform(KenyanDrake_2020.reshape(1, -1))\n",
    "print(X_transformed, '\\n')\n",
    "print(loaded_model.predict(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
